{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros(9)\n",
    "        self.legal_actions = [action for action in range(0, 9)]\n",
    "        self.finished = False\n",
    "        self.player = 1\n",
    "        \n",
    "    def __str__(self):\n",
    "        out = np.array(self.board).reshape((3, 3))\n",
    "        return(str(out))\n",
    "    \n",
    "    def step(self, action):\n",
    "        old_self = self.copy()\n",
    "        \n",
    "        self.board[action] = self.player\n",
    "        self.legal_actions = [move for move in self.legal_actions if move != action]\n",
    "        \n",
    "        reward = self.reward()\n",
    "        done = self.done()\n",
    "        \n",
    "        return old_self, action, reward, done\n",
    "        \n",
    "    def get_legal_actions(self):\n",
    "        return(self.legal_actions)\n",
    "        \n",
    "    def get_legal_boards(self):\n",
    "        boards = []\n",
    "        for action in self.legal_actions:\n",
    "            board = np.copy(self.board)\n",
    "            board[action] = 1\n",
    "            boards.append(board)\n",
    "            \n",
    "        return(boards, self.legal_actions)\n",
    "    \n",
    "    \n",
    "    def flip_board(self):    \n",
    "        self.board = -self.board\n",
    "    \n",
    "    def reward(self):\n",
    "        player = self.player\n",
    "        board = (self.board.reshape((3, 3)) == player) + 0\n",
    "        \n",
    "        if 3 in np.sum(board, axis = 0):\n",
    "            return 1\n",
    "        elif 3 in np.sum(board, axis = 1):\n",
    "            return 1\n",
    "        elif 3 is np.trace(board):\n",
    "            return 1\n",
    "        elif 3 is np.trace(board.T):\n",
    "            return 1\n",
    "        elif len(self.legal_actions) is 0:\n",
    "            return 0\n",
    "        return 0\n",
    "    \n",
    "    def done(self):\n",
    "        player = self.player\n",
    "        board = (self.board.reshape((3, 3)) == player) + 0\n",
    "        if 3 in np.sum(board, axis = 0):\n",
    "            return True\n",
    "        elif 3 in np.sum(board, axis = 1):\n",
    "            return True\n",
    "        elif np.trace(board) == 3:\n",
    "            return True\n",
    "        elif np.trace(board.T) == 3:\n",
    "            return True\n",
    "        elif len(self.legal_actions) == 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def reset(self):\n",
    "        self.board = np.zeros(9)\n",
    "        self.legal_actions = np.arange(0, 9)\n",
    "        self.finished = False\n",
    "        self.player = 1\n",
    "        \n",
    "    def __hash__(self):\n",
    "        base3 = np.matmul(np.power(3, range(0, 9)), self.board.T)\n",
    "        return int(base3)\n",
    "    \n",
    "    def copy(self):\n",
    "        return copy.copy(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session():\n",
    "    boards, actions, rewards = [], [], []\n",
    "    \n",
    "    board = TicTacToe()\n",
    "\n",
    "    s = tf.InteractiveSession()\n",
    "    s.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "    while True:\n",
    "\n",
    "        legal_boards, legal_actions = board.get_legal_boards()\n",
    "        probs = get_action_prob(legal_boards)\n",
    "        n_actions = probs.shape[0]\n",
    "        probs = probs.reshape(n_actions)\n",
    "        probs = probs / np.sum(probs)\n",
    "\n",
    "        action = np.random.choice(np.arange(0, n_actions), \n",
    "                             p = probs)\n",
    "\n",
    "        old_board, action, reward, done = board.step(legal_actions[action])\n",
    "\n",
    "        #record session history to train later\n",
    "        boards.append(board.board)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        board.flip_board()\n",
    "        if done: break\n",
    "\n",
    "    train_step(boards, actions, rewards)\n",
    "            \n",
    "    return sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_rewards(rewards, #rewards at each step\n",
    "                           gamma = 1 #discount for reward\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    take a list of immediate rewards r(s,a) for the whole session \n",
    "    compute cumulative rewards R(s,a) (a.k.a. G(s,a) in Sutton '16)\n",
    "    R_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
    "    \n",
    "    The simple way to compute cumulative rewards is to iterate from last to first time tick\n",
    "    and compute R_t = r_t + gamma*R_{t+1} recurrently\n",
    "    \n",
    "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
    "    \"\"\"\n",
    "    \n",
    "    rewards = np.array(rewards)\n",
    "    R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "    r = 0.\n",
    "    for i, reward in enumerate(reversed(rewards)):\n",
    "        r += reward\n",
    "        R[-(i + 1)] = r\n",
    "        r *= gamma\n",
    "        \n",
    "    return R\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(_states, _actions, _rewards):\n",
    "    \"\"\"given full session, trains agent with policy gradient\"\"\"\n",
    "    _cumulative_rewards = get_cumulative_rewards(_rewards)\n",
    "    update.run({states_t: _states, actions_t: _actions, cumulative_rewards_t: _cumulative_rewards})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_t  = tf.placeholder(\"float32\", (None, 9), name = \"states\")\n",
    "actions_t = tf.placeholder(\"int32\", name = \"action_ids\")\n",
    "cumulative_rewards_t = tf.placeholder(\"float32\", name = \"cumulative_rewards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.Dense(32, activation = \"relu\"))\n",
    "model.add(L.Dense(64, activation = \"relu\"))\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "logits = model(states_t)\n",
    "policy = tf.nn.softmax(logits)\n",
    "log_policy = tf.nn.log_softmax(logits)\n",
    "\n",
    "get_action_prob = lambda s: policy.eval({states_t: s})\n",
    "\n",
    "J = tf.reduce_mean(log_policy * cumulative_rewards_t)\n",
    "\n",
    "entropy = -tf.reduce_sum(tf.multiply(policy, log_policy), 1, name=\"entropy\")\n",
    "\n",
    "all_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "\n",
    "loss = - J - 0.1 * entropy\n",
    "\n",
    "update = tf.train.AdamOptimizer().minimize(loss,var_list=all_weights)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession()\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    rewards = [generate_session() for _ in range(10)] #generate new sessions\n",
    "    \n",
    "    print (\"mean reward:%.3f\"%(np.mean(rewards)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = TicTacToe()\n",
    "\n",
    "legal_boards, legal_actions = board.get_legal_boards()\n",
    "probs = get_action_prob(legal_boards)\n",
    "n_actions = probs.shape[0]\n",
    "probs = probs.reshape(n_actions)\n",
    "probs = probs / np.sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "       0.11111111, 0.11111111, 0.11111111, 0.11111111], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.08963951, -0.0606088 ,  0.33861616, -0.19178468,  0.03264686,\n",
       "          0.23321685,  0.21127781, -0.34392345, -0.09202439,  0.2920443 ,\n",
       "         -0.28044686,  0.25361857, -0.20223527,  0.18872556,  0.30765715,\n",
       "          0.35545877,  0.06304127, -0.12077245,  0.29229113, -0.18248522,\n",
       "         -0.34825292,  0.24809936,  0.35049787,  0.20960578,  0.05717409,\n",
       "          0.3232744 , -0.08902881,  0.17212132, -0.11147016,  0.01152691,\n",
       "         -0.22509323, -0.36065575],\n",
       "        [ 0.34798905, -0.21246557,  0.20837507,  0.22279641, -0.19324325,\n",
       "         -0.15179949, -0.3581029 ,  0.34362367,  0.03008276,  0.23124465,\n",
       "          0.15385911, -0.2628366 , -0.3174194 , -0.18199836, -0.08259496,\n",
       "         -0.3472356 ,  0.22558185,  0.36895844,  0.03776971, -0.1015037 ,\n",
       "          0.03571695, -0.2231832 ,  0.37499788,  0.23196152,  0.332307  ,\n",
       "         -0.3698685 , -0.29020005,  0.36946717, -0.15301818, -0.02606788,\n",
       "         -0.0940468 , -0.28661567],\n",
       "        [ 0.08382541, -0.17899385, -0.18014114,  0.29064384, -0.3451543 ,\n",
       "          0.29872134,  0.01475132, -0.08316663,  0.37003866,  0.36576054,\n",
       "          0.1663672 , -0.18256001,  0.32556775,  0.3022928 ,  0.1938971 ,\n",
       "          0.1319792 ,  0.0673846 , -0.2841313 ,  0.35299918,  0.07431865,\n",
       "         -0.12540555,  0.2066063 ,  0.3278379 , -0.11095566,  0.04397145,\n",
       "         -0.0404532 ,  0.27761754, -0.23235725, -0.28023323,  0.20588717,\n",
       "          0.30166528,  0.25560084],\n",
       "        [-0.22448398,  0.27394858,  0.0048942 , -0.27070138,  0.13279477,\n",
       "         -0.1822013 , -0.08604783,  0.13255903, -0.16616243,  0.05682376,\n",
       "          0.00086644, -0.11282238, -0.2855875 , -0.15760748,  0.37287024,\n",
       "         -0.20290682, -0.22730133, -0.17163417, -0.26367086,  0.03365952,\n",
       "         -0.37002024, -0.11963364, -0.11383659, -0.35128933,  0.28951046,\n",
       "          0.05571169, -0.24477158,  0.11861691, -0.167228  , -0.1978903 ,\n",
       "         -0.28618217, -0.16461858],\n",
       "        [-0.12237632, -0.11080983,  0.19613394, -0.3552478 , -0.10189718,\n",
       "         -0.21944138, -0.20163293, -0.00883934, -0.34720176,  0.08401757,\n",
       "          0.17585173,  0.2695932 ,  0.23500088,  0.35061744, -0.12920946,\n",
       "          0.28555706, -0.07344735, -0.02371576,  0.06198603, -0.30685613,\n",
       "         -0.27131128, -0.2885701 ,  0.34682998, -0.21386112, -0.21273582,\n",
       "         -0.36461246,  0.37350288, -0.18301722, -0.07481351,  0.0611254 ,\n",
       "          0.13365695, -0.2598598 ],\n",
       "        [-0.01677772, -0.13439381, -0.10303551,  0.1627889 ,  0.10152459,\n",
       "         -0.12666628, -0.00064465,  0.00888237, -0.23989344,  0.28477743,\n",
       "         -0.3525178 ,  0.31714764, -0.31647488, -0.29406747, -0.07411143,\n",
       "          0.36861148, -0.2592595 ,  0.11046964, -0.32166243,  0.20173189,\n",
       "          0.03753713,  0.13681439,  0.12257251,  0.3616105 ,  0.2432405 ,\n",
       "          0.19015828,  0.16717407, -0.19360316,  0.25857553, -0.00570768,\n",
       "         -0.3270331 , -0.09963554],\n",
       "        [ 0.15738824, -0.14405015,  0.2895845 , -0.02733865, -0.0963752 ,\n",
       "         -0.36138904,  0.08069348, -0.34769958,  0.3775538 ,  0.24518922,\n",
       "          0.16806743, -0.34214568,  0.21775845,  0.09641859, -0.22716443,\n",
       "         -0.15263192, -0.3301063 ,  0.3434486 , -0.15518734, -0.15517037,\n",
       "         -0.31956488,  0.32169053,  0.12286064,  0.21024099,  0.1148819 ,\n",
       "          0.1035915 ,  0.23647746,  0.28227106,  0.33117774,  0.01305205,\n",
       "          0.17055777, -0.31014374],\n",
       "        [-0.28227526, -0.0714213 ,  0.05433083, -0.20301425, -0.06335247,\n",
       "         -0.27540433, -0.0385105 ,  0.20603481, -0.35052222, -0.05061471,\n",
       "          0.34844127, -0.263938  ,  0.3385081 ,  0.37935135, -0.05486163,\n",
       "          0.11907157,  0.23809841, -0.01380369, -0.05350825, -0.2735296 ,\n",
       "         -0.19900255,  0.34526154, -0.13052046, -0.29266107,  0.02214155,\n",
       "         -0.21569052,  0.02226633, -0.05169123,  0.15592465,  0.28902122,\n",
       "         -0.26724494,  0.07958224],\n",
       "        [ 0.3808191 , -0.33658847,  0.37987033,  0.15713349, -0.11411962,\n",
       "          0.36872128,  0.1665406 , -0.14995639,  0.27855924, -0.07127663,\n",
       "          0.2411032 , -0.06427118, -0.21073367, -0.17841032,  0.26435253,\n",
       "          0.3656865 , -0.3806514 , -0.04894748, -0.11729658,  0.02139521,\n",
       "          0.18871066, -0.22871968,  0.08129078,  0.2887948 , -0.33484453,\n",
       "          0.24833408, -0.19949242, -0.14110155, -0.28179696, -0.12767941,\n",
       "          0.20500329,  0.01490599]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([[-0.12732649,  0.19844288, -0.18179458, ...,  0.16691357,\n",
       "         -0.16942352, -0.02660388],\n",
       "        [-0.24262643,  0.24754667,  0.08923006, ...,  0.12234664,\n",
       "         -0.16856372, -0.06053156],\n",
       "        [-0.10424078, -0.10787791,  0.14896935, ...,  0.24250579,\n",
       "          0.08645451, -0.21911597],\n",
       "        ...,\n",
       "        [ 0.24743646, -0.076379  , -0.23551846, ..., -0.05205202,\n",
       "         -0.24590641, -0.23303908],\n",
       "        [-0.08097219,  0.18231577, -0.01372474, ...,  0.13399023,\n",
       "         -0.14214182,  0.14997494],\n",
       "        [ 0.02381134, -0.06191635,  0.08854467, ..., -0.06664115,\n",
       "         -0.1219579 ,  0.00526679]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.20934498],\n",
       "        [ 0.2235781 ],\n",
       "        [ 0.25992018],\n",
       "        [ 0.11219332],\n",
       "        [ 0.18147561],\n",
       "        [-0.03170782],\n",
       "        [-0.1282803 ],\n",
       "        [-0.09923358],\n",
       "        [ 0.20972103],\n",
       "        [ 0.22811162],\n",
       "        [ 0.05560818],\n",
       "        [-0.02920476],\n",
       "        [ 0.2202354 ],\n",
       "        [ 0.03301203],\n",
       "        [ 0.2760625 ],\n",
       "        [ 0.12353712],\n",
       "        [ 0.20023042],\n",
       "        [ 0.05377439],\n",
       "        [ 0.04697075],\n",
       "        [-0.25059506],\n",
       "        [ 0.13534984],\n",
       "        [ 0.28504658],\n",
       "        [-0.2930291 ],\n",
       "        [ 0.06992906],\n",
       "        [-0.03751346],\n",
       "        [ 0.26033348],\n",
       "        [ 0.0670006 ],\n",
       "        [-0.0681556 ],\n",
       "        [ 0.12663656],\n",
       "        [-0.11420888],\n",
       "        [ 0.29408425],\n",
       "        [-0.09069155],\n",
       "        [ 0.20545906],\n",
       "        [-0.0775269 ],\n",
       "        [ 0.02047685],\n",
       "        [-0.17351358],\n",
       "        [ 0.12190855],\n",
       "        [-0.13320889],\n",
       "        [ 0.23236918],\n",
       "        [-0.1382696 ],\n",
       "        [ 0.17205319],\n",
       "        [ 0.26898676],\n",
       "        [ 0.10391504],\n",
       "        [-0.09875906],\n",
       "        [ 0.23221385],\n",
       "        [-0.25834498],\n",
       "        [ 0.17258132],\n",
       "        [-0.04885757],\n",
       "        [-0.00185996],\n",
       "        [ 0.09315395],\n",
       "        [ 0.14356902],\n",
       "        [ 0.09922779],\n",
       "        [-0.24533288],\n",
       "        [-0.20294216],\n",
       "        [ 0.00589156],\n",
       "        [-0.20510375],\n",
       "        [ 0.1007652 ],\n",
       "        [ 0.16508454],\n",
       "        [ 0.15695047],\n",
       "        [-0.29339373],\n",
       "        [-0.08358492],\n",
       "        [ 0.08235118],\n",
       "        [-0.2872963 ],\n",
       "        [-0.26948982]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.run(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
