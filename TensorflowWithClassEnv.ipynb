{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Backgammon as B\n",
    "import agent as A\n",
    "import flipped_agent as FA\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backgammon:\n",
    "    def __init__(self):\n",
    "        self.board = B.init_board()\n",
    "            \n",
    "    def reset(self):\n",
    "        self.board = B.init_board()\n",
    "        self.done = False\n",
    "    \n",
    "    def legal_moves(self, dice, player):\n",
    "        moves, boards = B.legal_moves(board = self.board, dice = dice, player = player)\n",
    "        if len(boards) == 0:\n",
    "            return [], []\n",
    "        boards = np.vstack(boards)\n",
    "        return moves, boards\n",
    "    \n",
    "    def swap_player(self):\n",
    "        self.board = FA.flip_board(board_copy=np.copy(self.board))\n",
    "    \n",
    "    # oppents random move\n",
    "    def make_move(self, dice):\n",
    "        moves, _ = self.legal_moves(dice, -1)\n",
    "        if len(moves) == 0:\n",
    "            return self.step([], -1)\n",
    "        move = moves[np.random.randint(len(moves))]\n",
    "        return self.step(move, -1)\n",
    "    \n",
    "    def step(self, move, player):\n",
    "        out_board = np.copy(self.board)\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                self.board = B.update_board(board = self.board, move = m, player = player)\n",
    "        reward = 0\n",
    "        self.done = False\n",
    "        if self.iswin():\n",
    "            reward = player\n",
    "            self.done = True\n",
    "        return out_board, reward, self.done\n",
    "    \n",
    "    def symbolic_step(self, move):\n",
    "        board = np.copy(self.board)\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                board = B.update_board(board = board, move = m, player = 1)\n",
    "        reward = 0\n",
    "        done = False\n",
    "        if B.game_over(board):\n",
    "            reward = 1\n",
    "            done = True\n",
    "        return board, reward, self.done\n",
    "        \n",
    "    def iswin(self):\n",
    "        return B.game_over(self.board)\n",
    "        \n",
    "    def render(self):\n",
    "        B.pretty_print(self.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, gamma = 0.99):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.network = keras.models.Sequential()\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(64))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(1))\n",
    "        \n",
    "        # Losses and logits\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = self.network(self._states)\n",
    "        self._afterstate_values = self.network(self._afterstates) * (1 - self._done)\n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values - self._state_values\n",
    "        \n",
    "    \n",
    "        self._target_state_values = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values)))\n",
    "        self._critic_optimizer = tf.train.AdamOptimizer()\n",
    "        self._critic_update = self._critic_optimizer.minimize(self._critic_loss)\n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.network(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        \n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_optimizer = tf.train.AdamOptimizer()\n",
    "        self._actor_update = self._actor_optimizer.minimize(self._actor_loss)\n",
    "        \n",
    "        self._s = tf.InteractiveSession()\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        \n",
    "        return np.random.choice(np.arange(len(probs)), p = probs)\n",
    "    \n",
    "    def update(self, boards, rewards, afterstates, done):\n",
    "        self._s.run([self._actor_update, self._critic_update], \n",
    "                    ({self._states: boards, \n",
    "                      self._afterstates: afterstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, gamma = 0.99):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.actor = keras.models.Sequential()\n",
    "        self.actor.add(L.Dense(32))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(64))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(32))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(1))\n",
    "        \n",
    "        # Critic\n",
    "        \n",
    "        self.critic = keras.models.Sequential()\n",
    "        self.critic.add(L.Dense(32))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(64))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(32))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(1))\n",
    "        \n",
    "        # Losses and logits\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = self.critic(self._states)\n",
    "        self._afterstate_values = self.critic(self._afterstates) * (1 - self._done)\n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values - self._state_values\n",
    "        \n",
    "    \n",
    "        self._target_state_values = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values)))\n",
    "        self._critic_optimizer = tf.train.AdamOptimizer()\n",
    "        self._critic_update = self._critic_optimizer.minimize(self._critic_loss)\n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.actor(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        \n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_optimizer = tf.train.AdamOptimizer()\n",
    "        self._actor_update = self._actor_optimizer.minimize(self._actor_loss)\n",
    "        \n",
    "        self._s = tf.InteractiveSession()\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        \n",
    "        return np.random.choice(np.arange(len(probs)), p = probs)\n",
    "    \n",
    "    def update(self, boards, rewards, afterstates, done):\n",
    "        self._s.run([self._actor_update, self._critic_update], \n",
    "                    ({self._states: boards, \n",
    "                      self._afterstates: afterstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage:  0.76\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl8VPW5+PHPk50lQAJhSUgI+w4BQlwAdwFRAZcq1Hq1taLttXa1V3/ttb14u+mt2lqvFa1aN0C9KlGpCG6IsgUIO4EQICskEEiA7Mnz+yNDO4aETMhk1uf9euXFzDnfc+bhZPLMme8qqooxxpjgEuLtAIwxxnieJX9jjAlClvyNMSYIWfI3xpggZMnfGGOCkCV/Y4wJQpb8jTEmCFnyN8aYIGTJ3xhjglCYtwNoqlevXpqcnOztMIwxxq9s2rTpqKrGuVre55J/cnIyGRkZ3g7DGGP8iogcakt5q/YxxpggZMnfGGOCkCV/Y4wJQpb8jTEmCFnyN8aYIORS8heRmSKSJSLZIvJgM/uTRORTEdkiIttEZJbTvoccx2WJyAx3Bm+MMeb8tNrVU0RCgaeBq4F8YKOIpKvqLqdivwTeUNVnRGQUsBxIdjyeB4wG4oFVIjJMVevd/R8xxhjjOlfu/NOAbFXNUdUaYAkwp0kZBbo5HncHCh2P5wBLVLVaVQ8A2Y7zGWOMV+WVVrBy1xFvh+E1riT/BCDP6Xm+Y5uzXwPfEpF8Gu/6f9CGYxGRBSKSISIZJSUlLoZujDHn5/jpGuY/t467X87g0LHT3g7HK1xJ/tLMtqarvs8HXlLV/sAs4BURCXHxWFR1kaqmqmpqXJzLo5ONMabN6huU+5dsobi8mhCBJRvzWj8oALmS/POBRKfn/flXtc4ZdwFvAKjqWiAK6OXiscYY4zF//CiLL/YdZeGc0Vwxog9vZuRTW9/g7bA8zpXkvxEYKiIDRSSCxgbc9CZlcoErAURkJI3Jv8RRbp6IRIrIQGAosMFdwRtjTFt8uKOI//1sP/PTkpiXlsT8tESOnqrm493BV/ffavJX1TrgPmAFsJvGXj07RWShiMx2FPspcLeIbAUWA3dqo500fiPYBXwI/Lv19DHGeMO+Iyf56RtbmZDUg1/PHgXApcPi6Nc9isUbgq/qx6VZPVV1OY0Nuc7bHnZ6vAuY0sKxvwF+044YjTGmXcqrarnnlU10igjlmdsmERkWCkBYaAjfSE3kqU/2kVdaQWJsZy9H6jk2wtcYE9AaGpSfLN1KbmkFT39zIn27R31t/y2p/QF4MyO47v4t+RtjAtpfPs1m1e4j/OLakVwwqOdZ+/vHdObSYXEszcijLogafi35G2MC1qd7inli1V5umJDAnRcnt1hu3uQkjpRX81lW8IwzsuRvjAlIB4+e5odLtjCybzd+e8NYRJobdtToypG9iYuOZPGGXA9G6F2W/I0xAaeipo57X91ESIjw7O2T6BQRes7y4aEhfGNSfz7NKqaorNJDUXqXJX9jTEBRVX7+1jb2HjnJU/MnuNyDZ97kJBoU3tiY38ER+gZL/saYgPL8Fwd4f1sRD8wYwbShrk8Xk9SzM1OH9OKNjDzqG86ahSbgWPI3xgSMr7KP8rt/7OaaMX2599JBbT5+floSBScqWb0v8Bt+LfkbYwJCwYlK7lu8hcFxXXnsG+PP2cDbkqtH9aFnlwiWBEHDryV/Y4zfq6qt595XNlFb18Czt0+ia6RLkxecJSIshJsm9efj3cUUl1e5OUrfYsnfGOPXVJVfvruD7QVlPH5rCoPiurbrfPMmJ1LXoLy5KbAbfi35G2P82qvrc3lrUz73XzmUq0f1aff5BsV15YKBsSzdmEdDADf8WvI3xvitTYdKWfjeTq4Y0ZsfXTnUbef95gVJ5JZW8NX+Y247p6+x5G+M8UvF5VXc++pmEnp04olbUwgJaXsDb0tmjO5Lj87hLN4YuA2/lvyNMX6npq6B7722mdPVdTx7eyrdO4W79fxR4aHcOKE/H+08zLFT1W49t6+w5G+M8TuPvL+LTYeO8+jN4xjeN7pDXmN+WiK19cr/bfZMw29lTb1HZxW15G+M8Ssf7TzMK+sOseCSQVw3Lr7DXmdon2gmDYhhyYY8VDu24VdV+dlbW/n2Sxs91shsyd8Y41de35BLQo9O/HzG8A5/rflpSeQcPc36A6Ud+jqLVufwwbYipgzp5da2i3Ox5G+M8RvHTlXzxb6jzE6JJyy049PXtWP7ER0V1qEjftfsO8ofPtzDtWP7cc8lbZ+S4ny5dPVEZKaIZIlItog82Mz+J0Qk0/GzV0ROOO2rd9qX7s7gjTHBZfn2IuoblLkpCR55vU4RodwwIYHlOw5zoqLG7efPP17BDxZvZkjvrjx687jzmpLifLWa/EUkFHgauAYYBcwXkVHOZVT1x6qaoqopwFPA2067K8/sU9XZbozdGBNk3s0sZETf6A5r5G3OvMlJ1NQ18PbmAreet6q2nntf3URdg/Ls7al0Oc8pKc6XK3f+aUC2quaoag2wBJhzjvLzgcXuCM4YTykqq6SsstbbYZhzyCutYNOh48xO6bhG3uaMiu/G+MQeLN6Q67aGX1XlF+/sYEdBOU/emsLAXl3cct62cCX5JwDOy9rnO7adRUQGAAOBT5w2R4lIhoisE5G5LRy3wFEmo6Qk8KdSNb7l2KlqZv3pC36yNNPboZhzSN9aCMD1HdjDpyXzJyeyr/gUm3OPu+V8r6w7xP9tzudHVw3lypHtn5LifLiS/JurhGrp428e8Jaq1jttS1LVVOCbwJMiMvisk6kuUtVUVU2Ni3N98QVj3OG/P9jN8YpaPskqpuBEcCzh54/SMwtJHRDj8spc7nT9+Hi6RITy+vq81gu3YuPBUha+t4srR/Tm/ivcNyVFW7mS/POBRKfn/YHCFsrOo0mVj6oWOv7NAT4DJrQ5SmM6yOq9JbyzpYCbJ/UH4I2N7f/jNu6353A5WUdOMsfDVT5ndIkMY3ZKAh9sL2xX9eCR8iq+/9pmEmM787ibp6RoK1eS/0ZgqIgMFJEIGhP8Wb12RGQ4EAOsddoWIyKRjse9gCnALncEbkx7VdbU84t3tzMorgv/PXcM04bGBc0Sfv5mWWYhoSHCrLH9vBbD/LREqmobWJZ5fg2/NXUNfO/VTY4pKSa5fUqKtmo1+atqHXAfsALYDbyhqjtFZKGIOPfemQ8s0a+3iIwEMkRkK/Ap8HtVteRvfMKTq/aSV1rJb28YS1R4KN9MS6SorIrP9xZ7OzTjpKFBSc8s5JKhvejZNdJrcYxN6M7o+G68vv78Gn7/672dbM49wWM3j2dYH8/1VmqJS32LVHU5sLzJtoebPP91M8d9BYxtR3zGdIgdBWU8v+YA8yYncuGgngBcObIPvbpG8vr6PK4Y4Z1GOHO2TbnHKThRyQMeGNF7LiLCvLQk/vPdHWzNLyMlsYfLx76xMY/X1udyz6WDuHac9769OLMRvibo1DcoD729nZjOETx0zch/bg8PDeEbqf35NKuYw2WBvYSfP1mWWUBUeIhbFmpprzkp8XQKD23TiN+teSf45bIdTB3Siweme/cDzJklfxN0XvzyANsLyvj17FF07/z1etd5kxOpb1DezLCGX19QW9/AB9uKuHpUX48PgmpOt6hwrhvXj/SthZyqrmu1/NFT1Xzv1U3EdY3kqfkTPDIlhat8JxJjPCCvtII/frSXK0b05tpmGg8H9OzClCE9WZoR2Ev4+Ys1+45yvKKWOeO908unOfMvSKKipp70zJY6PTaqq2/gvtc3c+x0Dc/ePomYLhEeitA1lvxN0FBV/nPZDkTgkbljWpxHZd7kJPKPV7Im+6iHIzRNLcssoEfncC4Z5jvjfyYk9mB4n2iWtLLK1+//sYd1OaX87saxjEno7qHoXGfJ3wSN97YV8VlWCT+bPpyEHp1aLDd9dB9iu0SwuANncjStq6ip46NdR5g1th8RYb6TqkSE+WmJbMsvY0dBWbNllmUW8PyaA9x5cTI3Tuzv4Qhd4ztX1JgOdKKihoXv7WRc/+7ccXHyOctGhoVy08QEVu46QsnJwFzCzx+s3HWEipp6n6ryOeOGCf2JDAtp9u5/d1E5//F/25icHMMvrh3ZzNG+wZK/CQq/W76H4xW1/P7GcYS6MKry1slJ1DUob23yzBJ+5mzpmYX06x7F5ORYb4dylu6dw5k1th/vbimkouZfDb8nKmq455VNdO8UztO3TSTchxp4m/LdyIxxk7X7j7E0I4+7pw1iVHw3l44Z0rsraQNjWbox1xp+veD46Ro+31vC7PHxXp0C4VzmpyVxqrqO97cVAY1diH+4JJOiskr+97ZJ9I6O8nKE52bJ3wS0qtp6/t8720mK7cwPr2zbJFrz0xI5eKyCdTnHOig605LlO4qoa1CPT9/cFpOTYxgc1+WfbUNPrNzL53tL+PXs0UwaEOPl6Fpnyd8EtKc/zebA0dP85oYxdIoIbdOx14zpR/dO4Sy2yd48bllmIUN6d2VUP9e+qXlDY8NvEltyT/DUx/v4y6fZ3JqayDfTkrwdmkss+ZuAlXX4JM98tp8bJyYwbWjbuwpGhTcu4bdix2FKT7t/CT/TvIITlWw4UMrclHiPLmt4Pm6c2J+I0BD+uHIv4/t357/mjPb5mM+w5G8CUkOD8uDb24iOCuOX145q/YAWzE9Loqa+gbc3W8Ovp7znWLRl9njPrNPbHrFdIpiTEk9cdCTPfGsSUeFt+3bpTd4fL21MB3ht/SG25J7g8VvGE9uOkZXD+0YzMalxCb+7pg70m7s6f7Yss5AJST1I6un5RVvOx+9uHEttvba5WtHb7M7fBJyiskr+8GEW04b24oYJ7b97nJ+WxP6S02w86J4l/EzL9h45ye6icp/s29+SsNAQv0v8YMnfBKBfLdtJXUMDv5k71i136teO60d0ZFibZnI05yc9s5AQgWu9sE5vsLHkbwLKhzsO89GuI/zoqmFuqzboHBHG3AkJfLC9iLKK81/Cz5ybqrJsawFThvQiLtp7i7YEC0v+JmCUV9Xy8LIdjOzXjbumDnTrueelJVJd18A7W6zht6Nszj1BXmklc1J8v6E3EFjyNwHj0Q/3cPRUNb+/cazbh9WPju/OuP7dWbwh77yW8DOtS88sIDIshBmjvb9oSzCw5G8CQsbBUl5dl8udFw9kfBuW12uL+WlJZB05yZa8Ex1y/mBWV9/A+9uKuGpkH6KjvLuwebBwKfmLyEwRyRKRbBF5sJn9T4hIpuNnr4iccNp3h4jsc/zc4c7gjQGorqvnobe3k9CjEz+dPqzDXuf68fF0jghl8Xpr+HW3L/cf49jpGp+eziHQtJr8RSQUeBq4BhgFzBeRr42aUdUfq2qKqqYATwFvO46NBX4FXACkAb8SEd+f9ML4lWc/z2Ff8SkemTu6Q5f66xoZxpyUeN7fVsTJKmv4dadlmQVER4Vx2XDfWbQl0Lly558GZKtqjqrWAEuAOecoPx9Y7Hg8A1ipqqWqehxYCcxsT8DGONtfcoq/fJLNdeP6ccWIjq8rnjc5icraepa1soRfewVTu0JVbT0rdhxm1ph+RIb5X395f+VK8k8AnGe2yndsO4uIDAAGAp+09Vhj2ur46RruX7yFqPAQHr7+/KdwaItx/bszql+3Dl3la9Oh41z8+09YllnQYa/hS1btPsLpmnrmWJWPR7mS/JsbJdPSbck84C1VrW/LsSKyQEQyRCSjpKTEhZBMsCsur+LWRWvZV3yKP82b4LG5088s4bezsJzt+c0v4dceX2Yf5fa/raeorIq/f3XQ7ef3RcsyC+nTLZILBvX0dihBxZXknw8kOj3vD7T0nXce/6rycflYVV2kqqmqmhoXZ3V+5tzySiv4xrNryT9eyUvfnszlI3p79PXnTEggKjyE1918979q1xG+/dJGEmM6c9fUgWzOPUHusQq3voavKauo5bOsYq4fF+/SCmvGfVxJ/huBoSIyUEQiaEzw6U0LichwIAZY67R5BTBdRGIcDb3THduMOS/7S05xy7NrOX66hle/ewEXD+7l8Ri6RYVz3bh40jMLOF1d1/oBLliWWcA9r25iZN9olt5zId+ekgxA+tbArvr5x44iauvVBnZ5QavJX1XrgPtoTNq7gTdUdaeILBSR2U5F5wNL1KmlSlVLgUdo/ADZCCx0bDOmzXYVlnPLX9dSW9/AkgUXMTHJex3H5qclcbqm/p/TD7fH4g25/GhpJqkDYnjt7gvp0TmC/jGdSUuO5d3MwoBu/F2WWcigXl0Yk+C7i7YEKpf6+avqclUdpqqDVfU3jm0Pq2q6U5lfq+pZYwBU9QVVHeL4edF9oZtgsjn3OPMWrSUiLISl91zk8lq8HWViUg+G9ena7lW+nv8ih4fe3s6lw+J46dtpdHXqqjo7JZ7s4lPsLjrZ3nB90uGyKtYdOMZsP1i0JRDZCF/j877KPsq3nl9PTJcI3rz3IgbHdfV2SIgI8yYnsTXvBLsKy9t8vKry5Kq9/PcHu5k1ti+Lbk89a1rgWWP7ERYiLAvQqp/3thaiilX5eIklf+PTPt59hDtf2kj/mE68ec9F9I/xnQU+bpyYQERYCEs2tq3hV1X5zQe7eXLVPm6e1J8/z5tARNjZf4qxXSK4ZFgc72UW0tAQeFU/y7YWML5/dwb26uLtUIKSJX/js97bWsg9r2xiRN9oli64iN7dPNOd01U9Okcwa0xf3tlSQGVNfesHAPUNyv97ZzvPrznAnRcn8+hN4wg7xyR0c1LiKSyrIuNQYC0kk118ih0F5cy2u36vseRvfNKSDbncv2QLE5NieO27FxDTjqUYO9L8tCROVtXxwfaiVsvW1jfw46WZLN6Qx32XD+FX148ipJXujVeN7EOn8FDeDbABX+lbCxGB68f183YoQcuSv/E5f1tzgAff3s4lQ+P4+3fSfHqWx7SBsQyK69LqKl9VtfV879VNpG8t5D9mjuBnM4a71MjZJTKM6aP7sHx7ETV1De4K26tUlfTMAi4e3NPnvs0FE0v+xmeoKn9atY9H3t/FNWP6sujfJvn82qgiwvzJSWQcOs7eI833yjldXcddf9/Iqt3FPDJnNN+7bHCbXmNOSjwnKmr5Yl9gjH7fll/GwWMVzBlvVT7eZMnf+ARV5Xf/2MMTq/Zy08T+PDV/gt9M8nXjxATCQ4UlG87u9llWWcvtf1vP2v3HePyW8dx+UXKbzz9taBwxncM7fDI5T3k3s4CI0BBmjOnr7VCCmiV/43WNjaA7WLQ6hzsuGsBjN5+7EdTX9OwayYzRfXl7Sz5Vtf9q+D16qpr5i9axvaCM/71tIjdO7H9e5w8PDWHW2H6s3HXEbSOKvaW+QXlvaxGXj4ijeyffrc4LBv7zF2YCUm19Az95I5PFG3L5/mWD+fXs0a02gvqi+WlJnKioZcXOwwAUlVVyy7NryTl6iufvmMzMMe1r2JyTkkBlbT2rdh9xR7hes3b/MY6eqmau9fLxOkv+xmuqauv5/mubWZZZyM9nDufnM0f47UjPiwb1ZEDPzry+PpdDx07zjb+upbi8mpe/cwGXDmv/ZIWpA2KI7x7l91U/yzILiI4M8/hkfOZsHbfskTHnUFFTx4KXN7Em+ygL54zm386jLtyXhIQIt05O5NEPs7jpma+ob1Bev/sCxvV3z3rCISHC7JQEnv8ih9LTNcR6uOtreVVtu3sb1dUrH+44zIwxfYkK94/2nEBmyd94xQNvbeOr/Uf5n2+M5+ZJ51cX7mtuntSfxz/ai4iw9J4LGdYn2q3nn5MSz18/388H24u4/cIBbj33uWw4UMq8RWtx1yBjW7TFN1jyNx63Ne8EH2wr4odXDg2YxA/QOzqKN+69iPjunejb3f3910f0jWZYn66kZxZ4LPk39sLaTe/oKP798rZ1UW1Ot07hTB3i+Wm4zdks+RuPe2xFFrFdIrj7kkHeDsXtOnKaaRFhTkoCj63IIv94hUfmOVq1u5gtuSf4/Y1jmZeW1OGvZzzHGnyNR32ZfZQ12Uf5/mWDvzZ9sXHN7PGNVSbvbW19Oon2qm9QHluxh0G9ugTUNzTTyJK/8RhV5dEVWcR3j+JbHqyzDiSJsZ2ZmNTDI4u7L8ssYO+RU/xk+jC/GndhXGO/UeMxK3YeYWveCX501TDr7dEOcycksOfwSbIOd9wiLzV1DTyxai9jEroxq51jFIxvsuRvPKK+QfnjR1kMjuvCjRNtgE97zBrbj9AQ6dC7/yUbc8krreSBGSP8ctCdaZ0lf+MR72wpYF/xKX46fbhVIbRTr66RTB3Si2UdtL5vRU0df/44mwsGxnLJUOuZE6hc+isUkZkikiUi2SJy1jq9jjK3iMguEdkpIq87ba8XkUzHT3pzx5rAVl1XzxMr9zI2oTvX2GRebjEnJZ6CE5VsznX/Ii8vfnmQo6eq/XrEtWldq90tRCQUeBq4GsgHNopIuqruciozFHgImKKqx0XEeex2paqmuDlu40deX59LwYlKfn/TWEsmbjJ9dF8iw7azLLOQSQNi3XbeExU1/PXz/Vw1sg+TBnRct1Xjfa7c+acB2aqao6o1wBJgTpMydwNPq+pxAFUtdm+Yxl+drq7jL59kc9Ggnja4x426RoZx1ag+fLCtiNp69y3y8szn+zlVXccDM4a77ZzGN7mS/BMA54nK8x3bnA0DhonIlyKyTkRmOu2LEpEMx/a57YzX+JkX1hzg2OkaHpjp2spVxnVzUxI4drqGNdlH3XK+I+VVvPTlQeamJDC8r3unpjC+x5Xk39xfbNNWpjBgKHAZMB94XkTOzGiVpKqpwDeBJ0XkrDHiIrLA8QGRUVISGKsVGTh+uoZFq3O4elSfDh35GqwuHdY4J366m2b6/PPH+6hvUH581TC3nM/4NleSfz6Q6PS8P9D03ZYPLFPVWlU9AGTR+GGAqhY6/s0BPgMmNH0BVV2kqqmqmhoX1/7pb41veObz/ZyqsSqEjhIRFsKssX1ZsfMwlTX1rR9wDgePnmbpxjy+eUESST07ftoI432uJP+NwFARGSgiEcA8oGmvnXeBywFEpBeN1UA5IhIjIpFO26cAuzAB73BZFX//6iA3TEhw++yW5l9mj0+goqb9i7w8vnIv4aEh3HfFEDdFZnxdq8lfVeuA+4AVwG7gDVXdKSILRWS2o9gK4JiI7AI+BR5Q1WPASCBDRLY6tv/euZeQCVx/+ngfDWpVCB0tbWAsfbu1b5GXXYXlpG8t5NtTkukd7f7ZSI1vcmlmLVVdDixvsu1hp8cK/MTx41zmK2Bs+8MMbuVVtXSL8p/1TnNKTvFGRh7fuiCJxFirQuhIoSHC9eP78dJXBzlRUUOPzm1f5OV/PsqiW1QY91zS/imbjf+woZY+7qUvDzD+vz7iV8t2cLKq1tvhuOTxlXuJDAvhviuGejuUoDAnJYHaemX59sNtPnbjwVI+2VPM9y4bQvfO/nODYdrPkr8Pyyut4A8fZtE/phMvrzvE1Y+v/ucC4b5qR0EZ728r4jtTBhIXHentcILC6PhuDI7r0ua5flSVRz/cQ+/oSO68OLljgjM+y5K/j1JV/nPZDkRgyYKLePt7F9Ojczj3vLKJBS9nUFRW6e0Qm/U/H2XRvVN4QC7U4qvOLPKy4WAphSdcf198llXCxoPH+cGVQ+kUYbOsBhtL/j7qvW1FfJZVws+mDyehRycmJMXw3g+m8uA1I1i9r4SrH1/Ny2sPUu+uhVXdYH3OMT7LKuF7lw2meyerQvCk2ePjUYX3t7nW8NvQ0Li2QlJsZ25NTWz9ABNwLPn7oBMVNSx8byfj+3fnDqev4+GhIdx76WA++tGlTEjqwcPLdnLTM1+xu6jce8E6nFmopU+3SO64KNnb4QSd5F5dGJ/Yw+VeP+9tK2R3UTk/nT6MiDBLA8HIfus+6LfLd3O8opbf3TiO0GbmUk/q2ZmXv5PGk7emkFtawfVPreEPH+6hqrZ9A33a45M9xWw6dJz7rQrBa+aMj2dnYTnZxede5KW2voHHV+5lRN9orh8X76HojK+x5O9jvtp/lDcy8rl72iBGxXdrsZyIMHdCAh//5FJumJDAM5/tZ8aTq1mzzz3zvLRFQ4Py2Iosknt25harQvCa68b3I0Ro9e7/jYw8Dh2r4IEZw22hliBmyd+HVNXW84t3dpAU25kfXulaN8mYLhE89o3xvH73BYSI8K2/recnSzM5dqq6g6P9l/Sthew5fJIfXz2McFuoxWt6R0cxpZVFXipr6vnTqn1MGhDDFSN6N1vGBAf7S/Uhf/kkmwNHT/PbG8a2uerk4sG9+McPp/GDK4bw3rZCrnr8c97alN8hKz05q6lrrEIY2a+bVSH4gNnj48ktrSAz70Sz+/++9iDFJ6v5D1uoJehZ8vcRWYdP8tfP93PjxASmnufSeVHhofx0+nA+uH8ag+K68rM3t3Lb8+s5cPS0m6P9l6UZeeSWVvBzq0LwCTPG9CUiLKTZqp+yylqe+Ww/lw2PI22g+xaAMf7Jkr8PaGhQHnx7G906hfPLa0e1+3zD+kTz5j0X8ZsbxrA9v4wZT67m6U+zqalz36If0FiF8OeP9zE5OYbLhttsrL6gW1Q4V47ozfvbiqhrssjLotX7Kaus5WfTbZZVY8nfJ7y2/hBbck/wn9eNJLZL2+dmaU5IiHDbBQNY9dNLuWpkbx5bkcWMJ1fzxMq97Cwsc0t10ItfHaDkpK316mvmpMRz9FQ1a3OO/XNb8ckqXlhzkOvG9WNMQncvRmd8hUsTu5mOU1RWyR8+zGLa0F7MTWm6QFr79ekWxf/eNolVu47w7Or9/PmTffzp430kxnZi+qi+zBjdl0kDYprtUnouZRW1/PWz/VwxojeTk60KwZdcNrw30VFhvLulkGlDG7+RPf1JNjX1DfzU7vqNgyV/L/vVsp3UNTTwm7kdu7j5VaP6cNWoPhw9Vc2qXUdYsfMwr6w9xN/WHKBnlwiuGtmHGWP6cPHgXkSFt97Y/Ozq/ZRX1VkVgg+KCg/lmjF9Wb79ML+pHUPJyWpe35DLLamJDOzVxdvhGR9hyd+LPtxxmI92HeGha0Z4bPWkXl0jmZeWxLy0JE5W1fJDrPYoAAATO0lEQVT53hJW7DzCB9uLWJqRR5eIUC4b3pvpo/tw+YjezU4lXVxexYtfHmT2+PhzjkUw3jMnJYE3MvL5ZE8xq3YdIUTE5e7DJjhY8veS8qpaHl62g1H9unHX1IFeiSE6KpzrxsVz3bh4quvqWbv/GCt2HmHlrsYPg/BQ4eLBvZg+ug9Xj+rzz4U+nvokm9r6Bn5ytS3U4qsuHNSTuOhI/vJJNrsPl3P3tEH07W4LtZh/seTvJY9+uIejp6p5/o5UwnxgYFRkWOMd/2XDe/Pfc8eQmXecFTsbq4d+8c4OfvnuDiYmxXDJ0DgWb8jllsmJJFsVgs8KDRGuHxfPC18eIDoyjO9dagu1mK+z5O8FGQdLeXVdLndNHci4/j28Hc5ZQkOESQNimTQgloeuGUHWkZN85PggeGLVXqLCQ7jfFmrxeTdMSOCFLw+w4JJBxLipF5kJHNLRI0DbKjU1VTMyMrwdRoeprqvnuj+voaKmno9+fAldIv3r8zevtILqugaG9O7q7VCMC3YUlDGyX7c29+Yy/kdENqlqqqvl/SvzBIBnP89hX/EpXrxzst8lfsDW5PUz1qfftMSlymYRmSkiWSKSLSIPtlDmFhHZJSI7ReR1p+13iMg+x88d7grcH+0vOcVfPsnm+vHxXG6TahljvKjVW08RCQWeBq4G8oGNIpKuqrucygwFHgKmqOpxEent2B4L/ApIBRTY5Dj2uPv/K76toUF56O3tRIWH8PB17Z/CwRhj2sOVO/80IFtVc1S1BlgCzGlS5m7g6TNJXVWLHdtnACtVtdSxbyUw0z2h+5c3MvLYcKCUX1w70hY2N8Z4nSvJPwHIc3qe79jmbBgwTES+FJF1IjKzDcciIgtEJENEMkpKSlyP3k8Un6zit8t3c+GgWFvsxBjjE1xJ/s11E2jaRSgMGApcBswHnheRHi4ei6ouUtVUVU2Niwu82SEXvreLqroGfntDx07hYIwxrnIl+ecDzrer/YGmk4XnA8tUtVZVDwBZNH4YuHJsQPtkzxHe31bEDy4fwqA46x5pjPENriT/jcBQERkoIhHAPCC9SZl3gcsBRKQXjdVAOcAKYLqIxIhIDDDdsS0onK6u45fv7GBYn67cYyMsjTE+pNXePqpaJyL30Zi0Q4EXVHWniCwEMlQ1nX8l+V1APfCAqh4DEJFHaPwAAVioqqUd8R/xRX/8aC9F5VW89c2LiQjz/hQOxhhzho3w7SC7Csu57qkvuO2CATwyd4y3wzHGBLi2jvC129EO8uzq/XSOCONnM2y+e2OM77Hk3wEKTlTy/rYi5qcl0r3T2fPhG2OMt1ny7wAvrjmAAN+e4p15+o0xpjWW/N2srLKWxRtyuW5cP+J7dPJ2OMYY0yxL/m62ZEMup2vq+e60Qd4OxRhjWmTJ341q6hp48cuDTBnS06bSNcb4NEv+bvTB9kIOl1fZXb8xxudZ8ncTVWXR6gMM7d2Vy4YF3vxExpjAYsnfTb7MPsbuonLuvmSQTd5mjPF5lvzdZNEXOcRFRzInJd7boRhjTKss+bvB7qJyVu8t4c6Lk4kMC/V2OMYY0ypL/m7w/BcH6BwRym0XJHk7FGOMcYkl/3Y6XFZF+tYCbklNpEfnCG+HY4wxLrHk304vfXWQ+gblrqk2lYMxxn9Y8m+HU9V1vLb+ENeM7UdibGdvh2OMMS6z5N8OSzfmcbKqjgU2qMsY42cs+Z+nuvoGXlhzgLSBsYxP7OHtcIwxpk0s+Z+n5TsOU3Ci0u76jTF+yZL/eVBVnludw6C4Llwxore3wzHGmDZzKfmLyEwRyRKRbBF5sJn9d4pIiYhkOn6+67Sv3ml7ujuD95b1B0rZXlDG3dMGERJiUzkYY/xPWGsFRCQUeBq4GsgHNopIuqrualJ0qare18wpKlU1pf2h+o7nVufQq2sEN0xI8HYoxhhzXly5808DslU1R1VrgCXAnI4Ny3dlF5/k4z3F3H5hMlHhNpWDMcY/uZL8E4A8p+f5jm1N3SQi20TkLRFJdNoeJSIZIrJOROY29wIissBRJqOkpMT16L3g+S8OEBkWwu0XDfB2KMYYc95cSf7NVWprk+fvAcmqOg5YBfzdaV+SqqYC3wSeFJHBZ51MdZGqpqpqalyc786FX3yyirc3F/CN1P7EdrGpHIwx/suV5J8PON/J9wcKnQuo6jFVrXY8fQ6Y5LSv0PFvDvAZMKEd8XrVK2sPUdvQwF1TrXunMca/uZL8NwJDRWSgiEQA84Cv9doRkX5OT2cDux3bY0Qk0vG4FzAFaNpQ7Bcqaup4Zd0hpo/qw8BeXbwdjjHGtEurvX1UtU5E7gNWAKHAC6q6U0QWAhmqmg7cLyKzgTqgFLjTcfhI4FkRaaDxg+b3zfQS8gtvbcrnREUtCy6xu35jjP8T1abV996VmpqqGRkZ3g7ja+oblMv/5zN6dY3g7e9P8XY4xhhzFhHZ5GhfdYmN8HXBRzsPk1taYXf9xpiAYcm/FarKs6tzGNCzM1eP6uvtcIwxxi0s+bdi06HjZOad4LtTBxJqUzkYYwKEJf9WLFqdQ0zncG6elNh6YWOM8ROW/M/hwNHTrNx9hNsvHECnCJvKwRgTOCz5n8Pf1uQQHhrC7RclezsUY4xxK0v+LTh2qpo3M/K5aWICcdGR3g7HGGPcypJ/C15dl0t1nU3lYIwJTJb8m1FVW8/Law9y5YjeDOnd1dvhGGOM21nyb8bbmws4drqGu21QlzEmQFnyb6KhQXn+ixzG9e/OBQNjvR2OMcZ0CEv+TXy8p5ico6f57rRBiNigLmNMYLLk38Rzq3NI6NGJWWNsKgdjTOCy5O9kS+5xNhws5a6pAwkLtUtjjAlcluGcPP/FAbpFhXHLZJvKwRgT2Cz5O+Qeq+AfO4q47cIBdI1sdY0bY4zxa5b8HV748gChIcKdFyd7OxRjjOlwlvyBExU1LN2Yx5yUBPp0i/J2OMYY0+Es+QOvrc+lsraeu6fZoC5jTHBwKfmLyEwRyRKRbBF5sJn9d4pIiYhkOn6+67TvDhHZ5/i5w53Bu0N1XT0vfXWQS4fFMbxvtLfDMcYYj2i1ZVNEQoGngauBfGCjiKSr6q4mRZeq6n1Njo0FfgWkAgpschx73C3Ru8GyzEJKTlaz4Fa76zfGBA9X7vzTgGxVzVHVGmAJMMfF888AVqpqqSPhrwRmnl+o7qeqPLc6h5H9unHx4J7eDscYYzzGleSfAOQ5Pc93bGvqJhHZJiJviciZjvKuHusVn+0tYV/xKRZcMtCmcjDGBBVXkn9zWVGbPH8PSFbVccAq4O9tOBYRWSAiGSKSUVJS4kJI7vHc6hz6doviunHxHntNY4zxBa4k/3zAechrf6DQuYCqHlPVasfT54BJrh7rOH6RqqaqampcXJyrsbfLjoIyvtp/jO9MTSbcpnIwxgQZV7LeRmCoiAwUkQhgHpDuXEBE+jk9nQ3sdjxeAUwXkRgRiQGmO7Z53XNf5NA1Mox5aUneDsUYYzyu1d4+qlonIvfRmLRDgRdUdaeILAQyVDUduF9EZgN1QClwp+PYUhF5hMYPEICFqlraAf+PNik4Ucn724r4zpRkukWFezscY4zxOJcmsVHV5cDyJtsednr8EPBQC8e+ALzQjhjd7sU1BxDg21MGejsUY4zxiqCr7C6rrGXxhlyuG9eP+B6dvB2OMcZ4RdAl/yUbcjldU893bSoHY0wQC6rkX1PXwItfHmTKkJ6MSeju7XCMMcZrgir5v7+tkMPlVTaBmzEm6AVN8ldVFq3OYXifaC4d5pmxBMYY46uCJvmvyT7KnsMnuWuaTeVgjDFBk/wXrc4hLjqSOSk2lYMxxgRF8t9dVM4X+45y58XJRIaFejscY4zxuqBI/s99kUPniFBuu8CmcjDGGAiC5F9UVkl6ZiG3pCbSo3OEt8MxxhifEPDJ/6WvDtKgyl1TbSoHY4w5I6CT/8mqWl5fl8s1Y/uRGNvZ2+EYY4zPCOjkv3RjHier61hgg7qMMeZrAjb519U3TuWQNjCW8Yk9vB2OMcb4lIBN/st3HKbgRKXd9RtjTDMCMvk3TuWwn0FxXbhiRG9vh2OMMT4nIJP/upxSdhSUc/e0QYSE2FQOxhjTVEAm/+e+yKFnlwhumJDg7VCMMcYnBVzy33fkJJ/sKebfLkomKtymcjDGmOa4lPxFZKaIZIlItog8eI5yN4uIikiq43myiFSKSKbj56/uCrwlz39xgMiwEG6/aEBHv5QxxvitVhdwF5FQ4GngaiAf2Cgi6aq6q0m5aOB+YH2TU+xX1RQ3xXtOxSereGdLAbdM7k9sF5vKwRhjWuLKnX8akK2qOapaAywB5jRT7hHgUaDKjfG1yctfHaK2oYG7plr3TmOMORdXkn8CkOf0PN+x7Z9EZAKQqKrvN3P8QBHZIiKfi8i08w/13Cpq6nhl3SGmj+rDwF5dOupljDEmILRa7QM011dS/7lTJAR4ArizmXJFQJKqHhORScC7IjJaVcu/9gIiC4AFAElJ5zft8smqOqYO6cV3piaf1/HGGBNMXLnzzwcSnZ73BwqdnkcDY4DPROQgcCGQLiKpqlqtqscAVHUTsB8Y1vQFVHWRqqaqampc3Pmtr9unWxRP3zaRSQNiz+t4Y4wJJq4k/43AUBEZKCIRwDwg/cxOVS1T1V6qmqyqycA6YLaqZohInKPBGBEZBAwFctz+vzDGGNMmrVb7qGqdiNwHrABCgRdUdaeILAQyVDX9HIdfAiwUkTqgHrhXVUvdEbgxxpjzJ6raeikPSk1N1YyMDG+HYYwxfkVENqlqqqvlA26ErzHGmNZZ8jfGmCBkyd8YY4KQJX9jjAlClvyNMSYI+VxvHxEpAQ614xS9gKNuCscT/C1esJg9xd9i9rd4IbBiHqCqLo+S9bnk314iktGW7k7e5m/xgsXsKf4Ws7/FC8Eds1X7GGNMELLkb4wxQSgQk/8ibwfQRv4WL1jMnuJvMftbvBDEMQdcnb8xxpjWBeKdvzHGmFb4ZfJvbUF5EYkUkaWO/etFJNnzUX4tnkQR+VREdovIThH5YTNlLhORMqfF7h/2RqxNYjooItsd8Zw12540+rPjOm8TkYneiNMpnuFO1y9TRMpF5EdNynj9OovICyJSLCI7nLbFishKEdnn+DemhWPvcJTZJyJ3eDHex0Rkj+P3/o6I9Gjh2HO+hzwc869FpMDpdz+rhWPPmV88HPNSp3gPikhmC8e2/Tqrql/90Dit9H5gEBABbAVGNSnzfeCvjsfzgKVejrkfMNHxOBrY20zMlwHve/v6NonpINDrHPtnAf+gcbW3C4H13o65yfvkMI19n33qOtM41flEYIfTtkeBBx2PHwT+0MxxsTSuhxELxDgex3gp3ulAmOPxH5qL15X3kIdj/jXwMxfeN+fML56Mucn+PwIPu+s6++OdvysLys8B/u54/BZwpYg0txylR6hqkapudjw+CeymyTrIfmoO8LI2Wgf0EJF+3g7K4Upgv6q2Z8Bgh1DV1UDTdS2c37N/B+Y2c+gMYKWqlqrqcWAlMLPDAnVoLl5V/UhV6xxP19G4wp/PaOEau8KV/NIhzhWzI3/dAix21+v5Y/JvdUF55zKON2gZ0NMj0bXCUQU1AVjfzO6LRGSriPxDREZ7NLDmKfCRiGxyrLPclCu/C2+ZR8t/KL52nQH6qGoRNN4sAL2bKeOr1/s7NH4DbE5r7yFPu89RVfVCC1VrvnqNpwFHVHVfC/vbfJ39Mfmfc0H5NpTxOBHpCvwf8CNtsog9sJnGKorxwFPAu56OrxlTVHUicA3w7yJySZP9vnqdI4DZwJvN7PbF6+wqn7veIvILoA54rYUirb2HPOkZYDCQAhTRWI3SlM9dY4f5nPuuv83X2R+Tf2sLyn+tjIiEAd05v6+AbiMi4TQm/tdU9e2m+1W1XFVPOR4vB8JFpJeHw2waU6Hj32LgHRq/Ejtz5XfhDdcAm1X1SNMdvnidHY6cqTJz/FvcTBmfut6OBufrgNvUUfHclAvvIY9R1SOqWq+qDcBzLcTiU9cY/pnDbgSWtlTmfK6zPyb/cy4o75AOnOkJcTPwSUtvTk9w1Nf9Dditqo+3UKbvmXYJEUmj8XdzzHNRnhVPFxGJPvOYxga+HU2KpQP/5uj1cyFQdqbqwstavEvytevsxPk9ewewrJkyK4DpIhLjqLKY7tjmcSIyE/gPYLaqVrRQxpX3kMc0aY+6oYVYXMkvnnYVsEdV85vbed7X2ROt2B3QKj6Lxh4z+4FfOLYtpPGNCBBF41f+bGADMMjL8U6l8avjNiDT8TMLuJfGRe0B7gN20ti7YB1wsZdjHuSIZasjrjPX2TlmAZ52/B62A6k+8N7oTGMy7+60zaeuM40fTEVALY13mnfR2Cb1MbDP8W+so2wq8LzTsd9xvK+zgW97Md5sGuvGz7yfz/SuiweWn+s95MWYX3G8T7fRmND7NY3Z8fys/OKtmB3bXzrz/nUq2+7rbCN8jTEmCPljtY8xxph2suRvjDFByJK/McYEIUv+xhgThCz5G2NMELLkb4wxQciSvzHGBCFL/sYYE4T+P4BQl2BwL3VSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-e1cdedf9ae05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mold_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                             \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-55ec82625b8d>\u001b[0m in \u001b[0;36mmake_move\u001b[0;34m(self, dice)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# oppents random move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmoves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-55ec82625b8d>\u001b[0m in \u001b[0;36mlegal_moves\u001b[0;34m(self, dice, player)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmoves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Skóli Haust 2018/Reiknigreind/Backgammon/Backgammon.py\u001b[0m in \u001b[0;36mlegal_moves\u001b[0;34m(board, dice, player)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# try using the first dice, then the second dice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mpossible_first_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegal_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_first_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mtemp_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Skóli Haust 2018/Reiknigreind/Backgammon/Backgammon.py\u001b[0m in \u001b[0;36mlegal_move\u001b[0;34m(board, die, player)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# adding options if player is bearing off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdie\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mpossible_moves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdie\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "player = Agent(gamma = 0.9)\n",
    "\n",
    "win_pct = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        rewards = []\n",
    "        boards = []\n",
    "        afterstates = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = player.sample_action(possible_boards)\n",
    "                old_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                boards.append(old_board)\n",
    "                afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                \n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        old_state, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "        afterstates.append(old_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        Dones = np.zeros(len(boards))\n",
    "        Dones[-1] = 1\n",
    "        Boards = np.vstack(boards)\n",
    "        Rewards = player.get_cumulative_rewards(rewards)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        player.update(boards = Boards, rewards = Rewards, afterstates = AfterStates, done = Dones)\n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
