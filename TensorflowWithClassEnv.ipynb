{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Backgammon as B\n",
    "import agent as A\n",
    "import flipped_agent as FA\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backgammon:\n",
    "    def __init__(self):\n",
    "        self.board = B.init_board()\n",
    "            \n",
    "    def reset(self):\n",
    "        self.board = B.init_board()\n",
    "        self.done = False\n",
    "    \n",
    "    def legal_moves(self, dice, player):\n",
    "        moves, boards = B.legal_moves(board = self.board, dice = dice, player = player)\n",
    "        if len(boards) == 0:\n",
    "            return [], []\n",
    "        boards = np.vstack(boards)\n",
    "        return moves, boards\n",
    "    \n",
    "    def swap_player(self):\n",
    "        self.board = FA.flip_board(board_copy=np.copy(self.board))\n",
    "    \n",
    "    # oppents random move\n",
    "    def make_move(self, dice):\n",
    "        moves, _ = self.legal_moves(dice, -1)\n",
    "        if len(moves) == 0:\n",
    "            return self.step([], -1)\n",
    "        move = moves[np.random.randint(len(moves))]\n",
    "        return self.step(move, -1)\n",
    "    \n",
    "    def step(self, move, player):\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                self.board = B.update_board(board = self.board, move = m, player = player)\n",
    "        reward = 0\n",
    "        self.done = False\n",
    "        if self.iswin():\n",
    "            reward = player\n",
    "            self.done = True\n",
    "        return np.copy(self.board), reward, self.done\n",
    "    \n",
    "    def symbolic_step(self, move):\n",
    "        board = np.copy(self.board)\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                board = B.update_board(board = board, move = m, player = 1)\n",
    "        reward = 0\n",
    "        done = False\n",
    "        if B.game_over(board):\n",
    "            reward = 1\n",
    "            done = True\n",
    "        return board, reward, self.done\n",
    "        \n",
    "    def iswin(self):\n",
    "        return B.game_over(self.board)\n",
    "        \n",
    "    def render(self):\n",
    "        B.pretty_print(self.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolicyGrad Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradient:\n",
    "    def __init__(self, sess, gamma = 0.99, learning_rate = 1e-3, entropy = 0.1,\n",
    "                epsilon = 1, epsdecay = 0.999):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        self._epsilon = epsilon\n",
    "        self._epsdecay = epsdecay\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.network = keras.models.Sequential()\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(1))\n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.network(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_entropy = -tf.reduce_sum(self._actor_policy * self._actor_log_policy)\n",
    "        \n",
    "        # Losses\n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * self._cumulative_rewards)\n",
    "        self._actor_loss -= entropy * self._actor_entropy\n",
    "        \n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        self._update = self._optimizer.minimize(self._actor_loss)\n",
    "        \n",
    "        self._s = sess\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        if np.random.uniform() < self._epsilon:\n",
    "            action = np.random.choice(np.arange(len(probs)), p = probs)\n",
    "        else:\n",
    "            action = np.argmax(probs)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def update(self, states, rewards, afterstates, done):\n",
    "        self._s.run(self._update, \n",
    "                    ({self._states: states, \n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        self._epsilon *= self._epsdecay\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R\n",
    "    \n",
    "    def ExamplePolicy(self):\n",
    "        _, st = B.legal_moves(B.init_board(), B.roll_dice(), 1)\n",
    "        \n",
    "        out = np.round(self._s.run(self._actor_policy, ({self._states: st})) * 100)/100\n",
    "        out = out.flatten()\n",
    "        out.sort()\n",
    "        return out[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic (Shared network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic:\n",
    "    def __init__(self, sess, gamma = 0.99, learning_rate = 1e-3, entropy = 0.1,\n",
    "                epsilon = 1, epsdecay = 0.999):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        self._epsilon = epsilon\n",
    "        self._epsdecay = epsdecay\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._currstates = tf.placeholder(\"float32\", (None, 29), name = \"currstates\")\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.network = keras.models.Sequential()\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(1))\n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = tf.nn.tanh(self.network(self._currstates))\n",
    "        self._afterstate_values = tf.nn.tanh(self.network(self._afterstates)) * (1 - self._done)\n",
    "        \n",
    "        self._target_state_values = self._cumulative_rewards\n",
    "        self._target_state_values += self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done) - self._state_values\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.network(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_entropy = -tf.reduce_mean(self._actor_policy * self._actor_log_policy)\n",
    "        \n",
    "        # Losses\n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values))**2)\n",
    "        self._actor_loss = -tf.reduce_mean(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_loss -= entropy * self._actor_entropy\n",
    "        \n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        self._update = self._optimizer.minimize(self._actor_loss + self._critic_loss)\n",
    "        \n",
    "        self._s = sess\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        if np.random.uniform() < self._epsilon:\n",
    "            action = np.random.choice(np.arange(len(probs)), p = probs)\n",
    "        else:\n",
    "            action = np.argmax(probs)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def update(self, states, currstates, afterstates, rewards, done):\n",
    "        self._s.run(self._update, \n",
    "                    ({self._states: states, \n",
    "                      self._currstates: currstates,\n",
    "                      self._afterstates: afterstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        self._epsilon *= self._epsdecay\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R\n",
    "    \n",
    "    def ExamplePolicy(self):\n",
    "        _, st = B.legal_moves(B.init_board(), B.roll_dice(), 1)\n",
    "        \n",
    "        out = np.round(self._s.run(self._actor_policy, ({self._states: st})) * 100)/100\n",
    "        out = out.flatten()\n",
    "        out.sort()\n",
    "        return out[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-02a9ee519b92>, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-02a9ee519b92>\"\u001b[0;36m, line \u001b[0;32m70\u001b[0m\n\u001b[0;31m    if type != \"compete\"\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def PlayGame(player1, player2 = \"random\"):\n",
    "    \n",
    "    env = backgammon()\n",
    "        \n",
    "    states = []\n",
    "    afterstates = []\n",
    "    rewards = []\n",
    "    afterstates.append([])\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        dice = B.roll_dice()\n",
    "        for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "            possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "            n_actions = len(possible_moves)\n",
    "\n",
    "            if n_actions == 0:\n",
    "                break\n",
    "\n",
    "\n",
    "            action = player1.sample_action(possible_boards)\n",
    "            new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "            rewards.append(reward)\n",
    "            states.append(new_board)\n",
    "            afterstates.append(old_board)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        if not done:\n",
    "            dice = B.roll_dice()\n",
    "            \n",
    "            if player2 != \"random\":\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "\n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "\n",
    "                        action = player2.sample_action(possible_boards)\n",
    "\n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                env.swap_player()\n",
    "                \n",
    "            else:\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                    old_state, reward, done = env.make_move(dice)\n",
    "                    if done:\n",
    "                        rewards[-1] = -1\n",
    "                        break\n",
    "\n",
    "    afterstates.append(old_board)\n",
    "    afterstates = afterstates[2:]\n",
    "\n",
    "    Dones = np.zeros(len(states))\n",
    "    Dones[-1] = 1\n",
    "\n",
    "    States = np.vstack(states)\n",
    "    CumulativeRewards = player.get_cumulative_rewards(rewards)\n",
    "    AfterStates = np.vstack(afterstates)\n",
    "\n",
    "    if type != \"compete\"\n",
    "    player1.update(states = States, \n",
    "                  rewards = CumulativeRewards,\n",
    "                  afterstates = AfterStates, \n",
    "                  done = Dones)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "AC = ActorCritic(sess = s, entropy = 0.1, learning_rate = 0.001, gamma = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG = PolicyGradient(sess = s, entropy = 0.0, learning_rate=1e-4, gamma = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                960       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,049\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AC.network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06, 0.06, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
       "       0.03, 0.02, 0.02, 0.02, 0.02], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AC.ExamplePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stakt episode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spila við sjálft sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage:  0.46\n",
      "Agent epsilon:  0.3676954247709635\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example policy: \n",
      " [0.31 0.19 0.12 0.12 0.06 0.06 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.\n",
      " 0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        currstates = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                currstates.append(env.board)\n",
    "                afterstates.append(env.board)\n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = AC.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        afterstates.append(new_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "        \n",
    "        States = np.vstack(states)\n",
    "        CumulativeRewards = AC.get_cumulative_rewards(rewards)\n",
    "        CurrStates = np.vstack(currstates)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        AC.update(states = States, \n",
    "                  currstates = CurrStates,\n",
    "                  afterstates = AfterStates, \n",
    "                  rewards = CumulativeRewards,\n",
    "                  done = Dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    print(\"Agent epsilon: \", AC._epsilon)\n",
    "    plt.figure()\n",
    "    x = [(n + 1) * 100 for n in range(len(win_pct))]\n",
    "    y = (100*np.array(win_pct)).astype('int')\n",
    "    plt.plot(x, y, 'o-')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Win percentage of last 100 episodes')\n",
    "    plt.savefig('tensorflow_random.pdf')\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage:  0.86\n",
      "Agent epsilon:  0.1985312939636264\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example policy: \n",
      " [0.5 0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-619b135383f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                         \u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c11eb305c3a6>\u001b[0m in \u001b[0;36mmake_move\u001b[0;34m(self, dice)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# oppents random move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmoves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c11eb305c3a6>\u001b[0m in \u001b[0;36mlegal_moves\u001b[0;34m(self, dice, player)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlegal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmoves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Skóli Haust 2018/Reiknigreind/Backgammon/Backgammon.py\u001b[0m in \u001b[0;36mlegal_moves\u001b[0;34m(board, dice, player)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_first_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mtemp_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mpossible_second_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegal_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_board\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_second_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Skóli Haust 2018/Reiknigreind/Backgammon/Backgammon.py\u001b[0m in \u001b[0;36mlegal_move\u001b[0;34m(board, die, player)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# adding options if player is bearing off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdie\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mpossible_moves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdie\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "win_pct = []\n",
    "for i in range(100):\n",
    "\n",
    "    wins = []\n",
    "\n",
    "    for _ in range(50):\n",
    "\n",
    "        env = backgammon()\n",
    "\n",
    "        #states = []\n",
    "        #currstates = []\n",
    "        #afterstates = []\n",
    "        #rewards = []\n",
    "        #afterstates.append([])\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "\n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "\n",
    "                #currstates.append(env.board)\n",
    "                #afterstates.append(env.board)\n",
    "\n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                #rewards.append(reward)\n",
    "                #states.append(new_board)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        new_board, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            reward = -1\n",
    "                            break\n",
    "\n",
    "        #afterstates.append(new_board)\n",
    "        #afterstates = afterstates[2:]\n",
    "\n",
    "        #Dones = np.zeros(len(states))\n",
    "        #Dones[-1] = 1\n",
    "\n",
    "        #States = np.vstack(states)\n",
    "        #CurrStates = np.vstack(currstates)\n",
    "        #AfterStates = np.vstack(afterstates)\n",
    "        #Rewards = AC.get_cumulative_rewards(rewards)\n",
    "\n",
    "\n",
    "        #AC.update(states = States, \n",
    "        #          rewards = Rewards, \n",
    "        #          currstates = CurrStates,\n",
    "        #          afterstates = AfterStates, \n",
    "        #          done = Dones)\n",
    "\n",
    "        wins.append(int(reward == 1))\n",
    "\n",
    "    win_pct.append(np.mean(wins))\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    print(\"Agent epsilon: \", AC._epsilon)\n",
    "    plt.figure()\n",
    "    x = [(n + 1) * 50 for n in range(len(win_pct))]\n",
    "    y = (100 * np.array(win_pct)).astype('int')\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Win percentage of last 100 episodes')\n",
    "    plt.ylim(0, 100)\n",
    "    #plt.savefig('tensorflow_random.pdf')\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "#AC = ActorCritic(sess = s, entropy = 0.01, learning_rate = 0.001, gamma = 0.99,\n",
    "#                epsilon = 1, epsdecay = 0.999)\n",
    "for i in range(10):\n",
    "\n",
    "    wins = []\n",
    "\n",
    "    for _ in range(50):\n",
    "\n",
    "        env = backgammon()\n",
    "\n",
    "        states = []\n",
    "        currstates = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "\n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "\n",
    "                currstates.append(env.board)\n",
    "                afterstates.append(env.board)\n",
    "\n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        new_board, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "\n",
    "        afterstates.append(new_board)\n",
    "        afterstates = afterstates[2:]\n",
    "\n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "\n",
    "        States = np.vstack(states)\n",
    "        CurrStates = np.vstack(currstates)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        Rewards = AC.get_cumulative_rewards(rewards)\n",
    "\n",
    "\n",
    "        AC.update(states = States, \n",
    "                  rewards = Rewards, \n",
    "                  currstates = CurrStates,\n",
    "                  afterstates = AfterStates, \n",
    "                  done = Dones)\n",
    "\n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "\n",
    "    win_pct.append(np.mean(wins))\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    print(\"Agent epsilon: \", AC._epsilon)\n",
    "    plt.figure()\n",
    "    x = [(n + 1) * 50 for n in range(len(win_pct))]\n",
    "    y = (100 * np.array(win_pct)).astype('int')\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Win percentage of last 100 episodes')\n",
    "    plt.ylim(0, 100)\n",
    "    #plt.savefig('tensorflow_random.pdf')\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spila við random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage:  [0.65 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example policy: \n",
      " [0.18 0.18 0.09 0.09 0.07 0.07 0.04 0.04 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-db723e46d411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mafterstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_boards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3139f60e684e>\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "win_pct = np.zeros([10, 10])\n",
    "\n",
    "for j in range(10):\n",
    "    AC = ActorCritic(sess = s, entropy = 0.01, learning_rate = 1e-3, gamma = 0.99)\n",
    "    for i in range(10):\n",
    "\n",
    "        wins = []\n",
    "\n",
    "        for _ in range(100):\n",
    "\n",
    "            env = backgammon()\n",
    "\n",
    "            states = []\n",
    "            currstates = []\n",
    "            afterstates = []\n",
    "            rewards = []\n",
    "            afterstates.append([])\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                dice = B.roll_dice()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "                    possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                    n_actions = len(possible_moves)\n",
    "\n",
    "                    if n_actions == 0:\n",
    "                        break\n",
    "\n",
    "                    currstates.append(env.board)\n",
    "                    afterstates.append(env.board)\n",
    "\n",
    "                    action = AC.sample_action(possible_boards)\n",
    "                    new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                    rewards.append(reward)\n",
    "                    states.append(new_board)\n",
    "\n",
    "                    if done:\n",
    "                        break\n",
    "\n",
    "                if not done:\n",
    "                    dice = B.roll_dice()\n",
    "\n",
    "                    for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                            new_board, reward, done = env.make_move(dice)\n",
    "                            if done:\n",
    "                                rewards[-1] = -1\n",
    "                                break\n",
    "\n",
    "            afterstates.append(new_board)\n",
    "            afterstates = afterstates[2:]\n",
    "\n",
    "            Dones = np.zeros(len(states))\n",
    "            Dones[-1] = 1\n",
    "\n",
    "            States = np.vstack(states)\n",
    "            CurrStates = np.vstack(currstates)\n",
    "            AfterStates = np.vstack(afterstates)\n",
    "            Rewards = AC.get_cumulative_rewards(rewards)\n",
    "\n",
    "\n",
    "            AC.update(states = States, \n",
    "                      rewards = Rewards, \n",
    "                      currstates = CurrStates,\n",
    "                      afterstates = AfterStates, \n",
    "                      done = Dones)\n",
    "\n",
    "            wins.append(int(rewards[-1] == 1))\n",
    "\n",
    "        win_pct[i, j] = np.mean(wins)\n",
    "\n",
    "        clear_output(True)\n",
    "        print(\"Win percentage: \", win_pct[-1])\n",
    "        plt.figure()\n",
    "        x = [(n + 1) * 100 for n in range(10)]\n",
    "        y = (100 * win_pct).astype('int')\n",
    "        plt.plot(x, y, 'o-', color = \"b\")\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Win percentage of last 100 episodes')\n",
    "        plt.savefig('tensorflow_random.pdf')\n",
    "        plt.show()\n",
    "        print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAELCAYAAADURYGZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl8VPW9//HXJ6wJCmEJCGFHNsEqiAjuikr1thaXVq3WDUV7Xeut1+qtgq33aqvVtr9WK+5Vq7WIQN1QcWtdUDZlCZEdCUgSIKwBsnx+f5wTCSHLCWRmksz7+XjMY3K+c87MJ8Mwn5zv+Xy/X3N3REQkeaUkOgAREUksJQIRkSSnRCAikuSUCEREkpwSgYhIklMiEBFJcjFNBGZ2k5ktMLOFZnZz2DbBzHLMbF54OyuWMYiISPWaxuqJzWwwcDUwHNgNvGlmr4UPP+TuD8TqtUVEJLqYJQJgIPCpu+8AMLMPgHNi+HoiIrIfYtk1tAA40czam1kacBbQLXzsejP70syeNLO2MYxBRERqYLGcYsLMxgLXAduARUAhcB+QDzjwa6Czu19ZybHjgHEArVq1OmrAgAExi1NEpDGaPXt2vrtn1LRfTBPBXi9k9n/AGnd/uFxbT+BVdx9c3bHDhg3zWbNmxTZAEZFGxsxmu/uwmvaLddVQx/C+O3Au8IKZdS63yzkEXUgiIpIgsbxYDPCymbUHioDr3H2TmT1rZkcSdA2tBK6JcQwiIlKNmCYCdz+hkrafxPI1RUSkdjSyWEQkySkRiIgkuVhfIxARkf0wZW4O90/PZm1BIV3SU7l1dH/GDMmMyWspEYiI1DNT5uZw++T5FBaVAJBTUMjtk+cDxCQZqGtIRKSe+e30xd8mgTKFRSXcPz07Jq+nMwIRkXpgy84iPvwqjxlZuawt2FnpPmsLCmPy2koEIiIJsmrDdt7JymVG1no+W7GR4lKnbVozUps12eeMAKBLempM4lAiEBGJk+KSUuasLmBG1npmLM5lae42APp2PIirTujNqIEdGdq9Lf/8Yu1e1wgAUps14dbR/WMSlxKBiEgMbdlZxAfZeby7OJf3snMp2FFEsybGMb3ac/Ex3Rk1oBPd26ftdUzZBWFVDYmINFAr87czY/G+XT6nDujIqAGdOLFfBw5u2aza5xgzJDNmX/wVKRGIiByg8l0+72StZ1nedgD6dQq6fE4b2JEh3dvSJMUSHGnllAhERPZDWZfPjKz1vP9V3l5dPpeM6FFpl099pUQgIvVCPEfS7m8cK/O3807WemZk5fL5yqDLp12r5pw6oCOnDezECX1r7vKpj2q1MI2ZpQAHufuW2IW0Ly1MI9K4VRxJC0GVzL3nHh7XZFBZHM2bpnBcn/as2riD5eW6fEYN7MRpAztyZLf62+UTdWGaGs8IzOxvwLVACTAbaGNmD7r7/QcepohIUB1T2UjaCf9cSHFpfFZRBLjntUX7xLG7uJT3svM4oW8HLh3Rg1EDO9GtXcPo8okqStfQYe6+xcwuBl4HbiNICEoEIlInqhoxW7CjiJ//44s4R7MvA54de0yiw4iZKImgmZk1A8YAf3L3IjOLX4oWkUavY+sWrN+ya5/2Tq1bMOnaY+MWx/l/+bjSOGI1ore+iJIIHiVYUvIL4EMz6wFEukZgZjcBVxMk1Mfc/fdm1g74O9AzfN4fufumWkcuIo3C9l3FNLF9+9hTmzXh9jMHxrUb5vYzB8Z1RG99UePso+7+R3fPdPezPLAKOKWm48xsMEESGA4cAXzPzPoCvwBmuHtfYEa4LSJJqLTU+dnf5/HNlp2MO7EXmempGJCZnhr3C8UQDOK699zDEx5HvNVYNWRmnYD/A7q4+5lmdhgw0t2fqOG4HwKj3f2qcPtOYBcwFjjZ3deZWWfgfXevNt2qakikcbp/+mL+/N4y7vreYVx5fK9Eh9PoRK0airIewdPAdKBLuP0VcHOE4xYAJ5pZezNLA84CugGd3H0dQHjfsbKDzWycmc0ys1l5eXkRXk5EGpJX5q7hz+8t46Lh3bjiuJ6JDiepRUkEHdz9JaAUwN2LCUpJq+XuWcBvgLeBNwmuMRRHDczdJ7r7MHcflpGREfUwEWkAZq/axG0vz2dE73bcffZgrJJrBBI/URLBdjNrDziAmY0ANkd5cnd/wt2HuvuJwEZgCbA+7BIivM/dr8hFpEHKKSjkmmdn0blNSx65+CiaN9VCiYkWpWroFmAa0MfMPgIygPOjPLmZdXT3XDPrDpwLjAR6AZcB94X3U/cncBFpeLbvKuaqZ2axq6iUF8cNo22r5okOSYiQCNx9jpmdBPQnKAPNdveiiM//cng2UQRc5+6bzOw+4CUzGwusBn64n7GLSANSViGU/c0Wnrz8aA7teHCiQ5JQlYnAzM6t4qF+Zoa7T67pyd39hEraNgCjoocoIo3BA29l89ai9Yz//mGc3L/SGhFJkOrOCL4f3ncEjgXeDbdPAd4HakwEIiIAk+es4eH3l3HR8O5cfmzPRIcjFVSZCNz9CgAze5VgvqF14XZn4M/xCU9EGrrZqzbxi7BC6Fc/GKQKoXooyuX6nmVJILQe6BejeESkEVmzaUdQIZQeVAg1a6IKofooStXQ+2Y2HXiBoIT0QuC9mEYlIg3etxVCxaW8OO5oVQjVY1Gqhq43s3OAE8Omie7+SmzDEpGGrLTUufnv8/hq/VaevmI4h3Y8KNEhSTWiLlX5McGoYAc+i104ItIY3P9WNm8vWs+E7x/Gif00M0B9V2OHnZn9iODL/3zgR8BMM4s0oExEks/Ls9fwyPvL+PEx3blMFUINQpQzgv8Bjnb3XAAzywDeASbFMjARaXhmr9rI7ZPnc2yf9tx9tiqEGoool/BTypJAaEPE40QkiazZtINxf51Nl/SWPHzxUFUINSBRzgjeLFc1BHABwdrFIiIAbAsrhHaXlPL4ZUeTnqYKoYYkStXQreF0E8cTzDWkqiER+VZpqXPzi/NYkruNpy4/WhVCDVCNicDMWgFT3X2ymfUH+ptZs1pMPCcijdhvp2fzTtZ67j57kCqEGqgonXgfAi3MLJPgIvEVBKuWiUiSmzR7DX/5YBkXH9OdS0f2SHQ4sp+iJAJz9x0E6wn8P3c/BzgstmGJSH03a+VG7ggrhCaoQqhBi5QIzGwkcDHwWtgWdSCaiDRCX2/cwTXPqkKosYjyr3czcDvwirsvNLPeaK4hkaS1bVcxV/81qBB64nJVCDUGUaqGPgA+KLe9HLgxypOb2c+AqwimpphPcH3hL8BJ7Fn3+HJ3n1e7sEUkEUpKnZtfnMuS3G08fcXR9MlQhVBjUN0KZb9395vN7J+EC9eX5+5nV/fE4cXlGwnWMig0s5cIZi4FuNXdNTJZpIH57fTFvJOVy69+MIgT+qpCqLGo7ozg2fD+gQN8/lQzKwLSgLUH8FwikkD/mPU1j36wnEtGdOfSkT0THY7UoSqvEbj77PD+A+ATYBOwEfgkbKuWu+cQJJHVwDpgs7u/FT78v2b2pZk9ZGYtDvB3EJEY+3zlRu54ZT7HHdqe8d8flOhwpI5FmX30P4BlwB+BPwFLzezMCMe1BX4A9AK6AK3M7BKCC88DgKOBdsBtVRw/zsxmmdmsvLy8iL+OiNS1sgqhrm3TePjHWmWsMYryL/o74BR3P9ndTyJYvP6hCMedBqxw97xwFPJk4Fh3X+eBXcBTwPDKDnb3ie4+zN2HZWSoL1IkEcrmECouKeXxy4bRJq1ZokOSGIiSCHLdfWm57eVAblU7l7MaGGFmaRaMNBkFZJlZZwgGJwBjgAW1jFlE4qCk1LnphbkszdvGwxcfpQqhRizKwLCFZvY68BJB9dAPgc/Diehw98mVHeTuM81sEjCHYHWzucBE4I1wTQMD5gHXHvBvISJ17rdvLmbG4lx+/YNBHN+3Q6LDkRiKkghaAusJav8B8gj69r9PkBgqTQQA7j4eGF+h+dTahyki8fSPWV/z6IfL+cmIHvxEFUKNXpQBZVfEIxARqR/KKoSOP7QDd31f04olgyhVQ/3MbIaZLQi3v2Nmv4x9aCISb2UVQt3apvHnH2sOoWQRpWvoMeBW4FEAd//SzP4G3BPLwEQkPqbMzeH+6dmsLSikSYrRNAUmXTtSFUJJJEq6T3P3zyq0FcciGBGJrylzc7h98nxyCgpxoLjUKXXjyzWbazxWGo8oiSDfzPoQzjdkZucTjBQWkQbu/unZFBaV7NW2u6SU+6dnJygiSYQoXUPXEZR9DjCzHGAFwdoEItJAlZY6H3yVR05BYaWPr62iXRqnKFVDy4HTwrWLU9x9a+zDEpFY2FlUwpS5OTz+7xUszd1GikHpPnMLQ5f01PgHJwkTeaUxd98ey0BEJHY2bt/Ns5+s4tlPV5K/bTeHdW7NQxccQUmJc+fUhXt1D6U2a8Kto/snMFqJNy05KdKILc/bxhP/XsHLc9aws6iUU/pncPUJvRnZp/23aww3bZLybdVQl/RUbh3dnzFDMhMcucSTEoFII+PufLZiI4/9awUzFq+nWUoK5wzJ5KoTetG308H77D9mSKa++JNctYnAzAYQTCWdSVA1tBaY5u5ZcYhNRGqhuKSU1xd8w+P/Ws6XazbTNq0ZN5xyKD8Z2ZOMg7Xsh1StuqUqbwMuAl4EysYRdAVeMLMX3f2+OMQnIjXYurOIv3/+NU99tJKcgkJ6dWjFPWMGc97QrqQ2b5Lo8KQBqO6MYCwwKFxL4Ftm9iCwEFAiEEmgtQWFPP3xSl6YuZqtu4oZ3qsdE84exKgBHUlJsUSHJw1IdYmglGBlsVUV2juHj4lIAizI2cxj/1rOa1+uw4EzBx/C1Sf05ohu6YkOTRqo6hLBzcAMM1sCfB22dQcOBa6PdWAiskdpqfNedi6P/Ws5ny7fyEEtmnLZsT254riedG2blujwpIGrMhG4+5tm1o9gKclMgoVk1gCfu3tJVceJSN3ZWVTC5Dk5PPHv5SzL207nNi2546wBXDi8O61balI4qRs1lY96uVtpuftIzOxnwFXhcfOBKwi6ll4kWNxmDvATd99d68hFGrH8bbt49pNVPPfpKjZs383gzNb84cIjOevwzpoaWupcdVVDZwAPA0uAnLC5K3Comf2nu79V3RObWSZwI3CYuxea2UvAhcBZwEPu/qKZ/YXgovQjB/6riDQs5ad/LhvINTizzbcDwHYXlzJqQEeuOqE3I3q3+3YAmEhdq+6M4A/Aae6+snyjmfUCXgcGRnz+VDMrAtIIZi09Ffhx+PgzwASUCCTJlE3/XDa1Q05BIbe8NI9Sh+ZNUzhvaCZjj+/FoR33HQAmUteqSwRNCa4JVJQD1Ng56e45ZvYAsBooBN4CZgMF7l62nsEagusPIkmlsumfSx0ObtmU935+Mh0O0gAwiZ/qEsGTwOdm9iJ7qoa6EXTvPFHTE5tZW4JRyb2AAuAfwJmV7FrJ3IdgZuOAcQDdu3ev6eVEGpSqpnnetrNYSUDirsqrTu5+L0EXjgEjgWPDny8OH6vJacAKd88LB6VNDp8j3czKElBXgmkrKnv9ie4+zN2HZWRkRP6FRBqCqqZ51vTPkgjVVg2Fcwrt77xCq4ERZpZG0DU0CpgFvAecT1A5dBkwdT+fX6TBuvrEXkyYtmivNk3/LImyX3VoZvZGTfu4+0xgEkGJ6PzwtSYCtwG3mNlSoD0RuplEGpvPV2yiiUGn1i0wIDM9lXvPPVyzgEpCVFc+OrSqh4Ajozy5u48HxldoXk4wSE0kKX34VR6vzV/HLaf348ZRfRMdjki1XUOfAx8QfPFXpElNRPbDruISxk9bSM/2aYw7sXeiwxEBqk8EWcA17r6k4gNm9nUl+4tIDSZ+sJwV+dt55srhtGymKaKlfqjuGsGEah6/oe5DEWncvt64gz+9t5SzDj+Ek/qpEk7qj+omnZtUzWNTYhOOSON19z8X0iTFuPN7hyU6FJG9aPYqkTh4e9F63snK5aZRfencRmMFpH5RIhCJscLdJUyYtpC+HQ/iyuN7JTockX3UmAjMbJ/x7pW1iUjl/vzeUnIKCvn1mMGaQlrqpSifyk8itolIBcvytjHxw+WcMySTEb3bJzockUpVN6DsEIKZQVPNbAh7xhO0JphSWkSq4e6Mn7qQFk1TuP2sAYkOR6RK1Y0jGA1cTjAx3O/Ykwi2AnfENiyRhu+1+ev499J87j57EB0PbpnocESqVF356DPAM2Z2nru/HMeYRBq8bbuK+fWrixjUpTWXjOiR6HBEqhXlGkFXM2ttgcfNbE64jKWIVOEP73zF+i27+PWYwTRJ0RKTUr9FSQRXuvsW4AygI8EC9PfFNCqRBmzxN1t48qOVXHh0N4Z2b5vocERqFCURlP05cxbwlLt/QeUT0YkkPXfnrikLad2yKbd9VxeIpWGIkghmm9lbBIlgupkdDJTGNiyRhmnynBw+W7mR2747gLatmic6HJFIql2hLDSWYP2B5e6+w8zaE3QPiUg5m3cUce8bWQzpns6PhnVLdDgikdWYCNy91MxWAP3MTDVwIlV44K1sNm7fzdNXDCdFF4ilAakxEZjZVcBNBOMJ5gEjCEYWn1rDcf2Bv5dr6g3cRbCozdVAXth+h7u/XuvIReqR+Ws289zMVVw2sieDM9skOhyRWolyjeAm4GhglbufAgxhz5d4ldw9292PdPcjgaOAHcAr4cMPlT2mJCANXUmp88sp82nfqgW3nNEv0eGI1FqURLDT3XdCMNmcuy8G+tfydUYBy9x9VW0DFKnvXvx8NV+s2cz//McAWrdsluhwRGotSiJYY2bpwBTgbTObCqyt5etcCLxQbvt6M/vSzJ40s0oLrc1snJnNMrNZeXk1noCIJMSGbbv47ZvZHNOrHWOOzEx0OCL7xdw9+s5mJwFtgDfdfXfEY5oTJI5B7r7ezDoB+YADvwY6u/uV1T3HsGHDfNasWZHjFImX/570BZPn5PDGTSfQt9PBiQ5HZC9mNtvdh9W0X3Wzj7arpHl+eH8QsDFiLGcCc9x9PUDZffgajwGvRnwekXpl9qqNvDRrDdec2FtJQBq06qqGZhP81V6+Dq5s2wmqgKK4iHLdQmbW2d3XhZvnAAsiRytSTxSXlPI/ryygc5uW3Diqb6LDETkg1c0+esBr6plZGnA6cE255t+a2ZEEyWRlhcdEGoS/frKKxd9s5ZGLh9KqRZRxmSL1V0w/we6+A2hfoe0nsXxNkVjL3bKTB9/+ihP7ZfDdwYckOhyRA6YFVEVq6Z7XsthdUsqvzh6EmUYQS8NXZSIwswPuGhJpbD5ems+0L9Zy7Ul96NmhVaLDEakT1Z0RTAIwsxlxikWkXttdXMqdUxfQrV0q/3lyn0SHI1JnqrtGkGJm4wkmm7ul4oPu/mDswhKpf5749wqW5W3nycuH0bJZk0SHI1JnqjsjuBDYSZAsDq7kJpI0cgoK+eOMJZxxWCdOHdAp0eGI1Knqykezgd+Y2Zfu/kYcYxKpd371z4U4zl3fPyzRoYjUuShVQx+b2YNl8/6Y2e/MTPPsStJ4LzuX6QvXc8OpfenaNi3R4YjUuSiJ4ElgK/Cj8LYFeCqWQYnUFzuLShg/dSF9Mlpx9QlRB9OLNCxRBpT1cffzym3fbWbzYhWQSH3yyPvLWL1xB3+76hiaN9WwG2mconyyC83s+LINMzsOKIxdSCL1w6oN23nkg2V8/4guHHtoh0SHIxIzUc4IrgX+Wu66wCbgstiFJJJ47s5dUxfSvEkKv/yPgYkORySmoixe/wVwhJm1Dre3xDwqkQSbvvAbPvgqjzu/dxidWrdMdDgiMRV50jklAEkWO3YX86t/LmLAIQdz2cgeiQ5HJOZ09Uukgj/OWMrazTu5Z8xgmjbRfxFp/PQpFylnyfqtPP6v5fzwqK4M61nZIn0ijU+NicDM0szsznBZScysr5l9L/ahicSXu3Pn1AW0atGUX5w5INHhiMRNlDOCp4BdwMhwew1wT00HmVl/M5tX7rbFzG42s3Zm9raZLQnv2x5A/CJ1ZtoXa/l0+UZuHd2f9ge1SHQ4InETJRH0cfffAkUA7l7I3usYV8rds939SHc/EjgK2AG8AvwCmOHufYEZ4bZIQm3ZWcQ9r2Xxna5tuGh490SHIxJXURLBbjNLJVhjGDPrQ3CGUBujgGXuvgr4AfBM2P4MMKaWzyVS5x56+yvyt+3injGDaZKiVcckuUQpHx0PvAl0M7PngeOAy2v5OhcCL4Q/d3L3dQDuvs7MOtbyuUTq1MK1m3nm45VcfEx3vtM1PdHhiMRdlAFlb5vZHGAEQZfQTe6eH/UFzKw5cDZwe20CM7NxwDiA7t11qi6xUVrq3DllAW3TmnPrGbpALMkpStXQUKAHsA5YC3Q3sz5mFnUw2pnAHHdfH26vN7PO4XN3BnIrO8jdJ7r7MHcflpGREfGlRGpn0uw1zFldwO1nDaRNWrNEhyOSEFG+zB8GhgJfEpwRDA5/bm9m17r7WzUcfxF7uoUAphHMVXRfeD+1tkGLHIgpc3O4f3o2awsKMYNeHdI4b2hmosMSSZgoF4tXAkPCv86PAoYAC4DTgN9Wd6CZpQGnA5PLNd8HnG5mS8LH7tuPuEX2y5S5Odw+eT45BYU4UOqwtmAnU+etTXRoIgkTJREMcPeFZRvuvoggMSyv6UB33+Hu7d19c7m2De4+yt37hvcb9y90kdq7f3o2hUUle7XtKi7l/unZCYpIJPGidA1lm9kjwIvh9gXAV2bWgnBsgUhDsbag8qU0qmoXSQZRzgguB5YCNwM/A5aHbUXAKbEKTCQWDmlT+ZTSXdJT4xyJSP0RpXy0EPhdeKtoW51HJBIjJaVOemoz1m3euVd7arMm3Dq6f4KiEkm8KOWjfc1skpktMrPlZbd4BCdSl+59PYusb7byw2FdyUxPxYDM9FTuPfdwxgxR1ZAkryjXCJ4iGF38EEFX0BVEmGtIpD75++erefzfK7j82J5MOHtQosMRqVeiXCNIdfcZgLn7KnefAJwa27BE6s7M5Rv45ZQFnNgvQ+sPi1QiyhnBTjNLAZaY2fVADqD5gaRBWL1hB9c+N5vu7dL4fxcN0YpjIpWI8r/iZiANuJFgOulLgEtjGZRIXdi6s4ixz3yOA09cdjRtUjWFhEhloiSCnu6+zd3XuPsV7n4eoFngpF4rKXVueGEuK/K38/DFQ+nZoVWiQxKpt6IkgspmDa3VTKIi8fZ/r2fxfnYed/9gEMf26ZDocETqtSqvEZjZmcBZQKaZ/bHcQ62B4lgHJrK/XvxsNU+EFUIXH9Mj0eGI1HvVXSxeC8wiWEtgdrn2rQQjjEXqnU9VISRSa1UmAnf/AvjCzP7m7ppTSOq9VRu289PnZtOjfRp/+rEqhESiilI+OtzMJhAsTtOUYDCZu3vvWAYmUhtbdhYx9plZ31YItW6pCiGRqKIkgicIuoJmAyU17CsSd8Ulpdzwt7mszN/Os2OPUYWQSC1FSQSb3f2NmEcisp/+7/XFfPBVHveeezgj+7RPdDgiDU6URPCemd1PsMrYrrJGd59T04Fmlg48TrC8pQNXAqOBq4G8cLc73P31WsYtAsALn63myY9WcMVxPblouIa3iOyPKIngmPB+WLk2J9p8Q38A3nT3882sOcEI5dHAQ+7+QK0iFangk2UbuHPKAk7ql8H/nKUKIZH9FWU9gv1afMbMWgMnEixig7vvBnabaeJSOXCrNmznp8/PpmeHVvw/VQiJHJAo6xF0MrMnzOyNcPswMxsb4bl7E3T/PGVmc83scTMru4p3vZl9aWZPmlnb/Q9fklFZhRDAE5cNU4WQyAGK8mfU08B0oEu4/RXBRHQ1aQoMBR5x9yHAduAXwCNAH+BIYB2Vr3yGmY0zs1lmNisvL6+yXSQJFZeUcn1YIfTIxUfRo70qhEQOVJRE0MHdXwJKAdy9mGhlpGuANe4+M9yeBAx19/XuXuLupcBjwPDKDnb3ie4+zN2HZWRkRHg5SQb/+3oWH36Vxz1jBqtCSKSOREkE282sPcEFYsxsBLC5poPc/RvgazMrWwx2FLDIzDqX2+0cYEHtQpZk9beZq3nqo5VceVwvLlSFkEidiVI1dAswDehjZh8BGcD5EZ//BuD5sGJoOcEyl380syMJEstK4JraBi3J5+Nl+dw1dQEn98/gjrMGJDockUYlStXQHDM7CehPML1EdtS5h9x9HnuXnQL8pNZRSlJbmb+d/3x+Dj07tOKPWmVMpM5FqRq6DjjI3Re6+wLgIDP7z9iHJgKbC4NVxgxVCInESpQ/ra5294KyDXffRDAyWCSmiktKueGFuazasINHLlGFkEisREkEKVZuFJiZNQGaxy4kkcA9rwUVQv97zmBG9FaFkEisRLlY/Bbwkpn9heAC77XAmzGNSpLe8zNX8fTHKxl7fC8uOFoVQiKxFCUR/DcwDvgpwcXitwgmkhOJiY+X5TN+6kJO6Z/BHZpDSCTmqk0EYTfQM+5+CfCX+IQkyWxF/nZ++twceoUVQk1SNDeVSKxVe43A3UuAjHAcgEhMlVUIpViwytjBqhASiYsoXUMrgY/MbBrBfEEAuPuDsQpKkk8wh9Acvt64g+fGHkP39mmJDkkkaURJBGvDWwpwcGzDkWR1z2tZ/GtJPr8573COUYWQSFxFGVl8N4CZtXL37TXtL1Jbz30aVAhdpQohkYSIMrJ4pJktArLC7SPM7OGYRyZJ4eOl+YyfFlQI3a4KIZGEiDKg7PcEy0tuAHD3LwhWHhM5ICvyt/PT5+fQJ0MVQiKJFOUaAe7+dYUlJqOsRyCyjylzc7h/ejZrCwppkmK0aJrC45eqQkgkkaKcEXxtZscCbmbNzeznhN1EIrUxZW4Ot0+eT05BIQ4UlzpFpc6c1ZsSHZpIUouSCK4FrgMygRyCJSavi2VQ0jjdPz2bwqK9TyZ3F5dy//TsBEUkIhCtaigfuDgOsUgjt7agsFbtIhIfUaqGepvZP80sz8xyzWyqmfWOR3DSOGwuLGLCtIXBWqeV6JKeGtd4RGRvUbqG/ga8BHQGugD/AF6I8uRmlm5mk8xssZllhaWo7czsbTNbEt633f/wpT4rLXUmzV7DqN+9z18/Wcnxh7ZiiWY5AAANzUlEQVSnZbO9P3KpzZpw6+j+lT+BiMRFlERg7v6suxeHt+egyj/uKvoD8Ka7DwCOILjI/Atghrv3BWaE29LILFq7hR89+gk//8cXdG+XxrTrj+e5q0Zw37nfITM9FQMy01O599zDGTMkM9HhiiQ1c6/+O93M7gMKgBcJEsAFQAvgzwDuvrGK41oDXwC9vdyLmFk2cLK7rzOzzsD77l7tn4TDhg3zWbNmRf6lJHE2Fxbx0Ntf8ddPVtI2rTm3nTmA84d2JUVjBETizsxmu3vFdeP3EWUcwQXh/TUV2q8kSAxVXS/oDeQBT5nZEcBs4Cagk7uvAwiTQccIMUg9V1rqTJ6bw31vZLFx+24uGdGD/zq9P23SND5ApL6LUjXU6wCeeyhwg7vPNLM/UItuIDMbR7AgDt27a/6Z+mzh2s3cNXUhs1dtYmj3dJ6+YjiDM9skOiwRiSjSyOL9tAZY4+4zw+1JBIlgvZl1Ltc1lFvZwe4+EZgIQddQDOOU/bS5sIgH38rm2U9X0TatOfef/x3OUzeQSIMTs0Tg7t+Y2ddm1t/ds4FRwKLwdhlwX3g/NVYxSGyUljovz1nDfW8sZtOO3fxkRA9uUTeQSIMVyzMCgBuA58MVzpYDVxBUKr1kZmOB1cAPYxyD1KEFOZu5a+oC5qwu4KgebfnrD4YzqIu6gUQaskiJwMwygR7l93f3D2s6zt3nAZVdsR4VNUCpHzbvKOJ3b2fznLqBRBqdGhOBmf2GoHJoEXtmHXWgxkQgDV9pqTNpzhp+o24gkUYryhnBGKC/u++KdTBSv6gbSCQ5REkEy4FmgBJBklA3kEhyiZIIdgDzzGwG5ZKBu98Ys6gkISrtBjqjP21S1Q0k0phFSQTTwps0YgtyNnPn1AXMVTeQSNKJMrL4mXgEIomxeUcRD7yVzfMzg26gB354BOcOyVQ3kEgSqTIRmNlL7v4jM5tPJbONuvt3YhqZxFTZFNH3vbmYgh27uXRkT352ej91A4kkoerOCG4K778Xj0AktsovGt/h4BakNUth1cZChvVoy93qBhJJatUlggvM7CNgrrsXxysgqXtli8aXrRectzW45v/j4d3433MOx0zdQCLJrLpE0JVgYZkBZvYl8DHwEfBJVWsQSP2Tu3UnE6Yt3GfReIAPvspXEhCRqhOBu/8cIJwnaBhwLMEaBI+ZWYG7HxafEKU23J1F67bwblYu7yzO5YuvC6rcV4vGiwhEKx9NBVoDbcLbWmB+LIOS2tlZVMInyzcwI2s972blsnbzTszgiK7p/Nfp/Xj201Xkbt13PKAWjRcRqL5qaCIwCNgKzCToGnrQ3TfFKTapRu7Wnby3OJd3snL595J8CotKSGvehOMP7cDNp/XjlAEdyTi4BQDd2qXtdY0AtGi8iOxR3RlBd4K1iZcAOQQLzVTdzyAxVdblMyMrlxlZ6/lizWYAurRpyflHdWXUwI6M6N2els2a7HNs2eLwZVVDXdJTuXV0fy0aLyJADYvXW3AlcRDB9YFjgcHARoILxuPjEiHJu3j9zqISPlm2gXey1vPu4lzWlevyOW1gR0YN7MSAQw7WBV8RqVSdLF7vQZZYYGYFwObw9j1gOBC3RJBMcrfs5N2wy+ejpXu6fE7o24Gfnd6PU/rv6fIREakL1V0juJHgLOA4oIiwdBR4kogXi81sJcE1hhKg2N2HmdkE4GogL9ztDnd/fT/jb/DcnYVrgy6fdxfv6fLJTE/lh8O6cuqAqrt8RETqQnVnBD0JFpz/mbuvO4DXOMXd8yu0PeTuDxzAczYY5Uf0lvXNf3fwIXy8LJ93snJ5NyuXb7YEXT5Hdkvn1tH9OXVAR3X5iEjcVDeO4JZ4BtIYVRzRm1NQyC0vzePn/4DiUkhr3oQT+2Zw6sCO6vIRkYSJ9eL1DrxlZg486u4Tw/brzexSYBbwX42lJNXdyd+2m+V521iRv517XsvaZ0RvqQelm09cchQjerejRVN1+YhIYsU6ERzn7mvNrCPwtpktBh4Bfk2QJH4N/I5gxPJezGwcMA6ge/fuMQ6zdrbvKmZF/naW529nRd52VuRv+/bnrbtqnpZpx+4STuqXEYdIRURqFtNE4O5rw/tcM3sFGO7u3y56b2aPAa9WcexEYCIE5aOxjLMyxSWlfL2pMPiSz9vzpb88fxvrt+w9SjczPZXeGa04Z2gmvTu0olfGQfTu0IoLJn7C2oKd+zy3RvSKSH0Ss0RgZq2AFHffGv58BvArM+tc7uLzOcCCWLx+ZRdpKw6gcnfytu0Kv+C3B3/l5wV/3a/esIPi0j35p01qM3pntOL4QzPondGKXh1a0TujFT3bt6qyoue/Rw/QiF4RqfdieUbQCXglrHxpCvzN3d80s2fN7EiCrqGVwDV1/cKVXaS97eUvmb16E+1bNWdF+KVfsSunedMUerVvRb+OBzN60CH0Dr/se3c4iLatmtc6Do3oFZGGoNqRxfVFbUcWH3ffu+RUMbOmGXRpkxp+wZf9ZX8QvTq0okt6Kk20RKOINBJ1MrK4oapqemUDsn71XQ3OEhEpJyXRAcRCVRdju6SnKgmIiFTQKBPBraP7k1rhC18XaUVEKtcou4Z0kVZEJLpGmQggSAb64hcRqVmj7BoSEZHolAhERJKcEoGISJJTIhARSXJKBCIiSa5BTDFhZnnAqkTHcYA6ABVXaktmej/20HuxN70fezuQ96OHu9c4532DSASNgZnNijLnR7LQ+7GH3ou96f3YWzzeD3UNiYgkOSUCEZEkp0QQPxNr3iWp6P3YQ+/F3vR+7C3m74euEYiIJDmdEYiIJDklgjpgZt3M7D0zyzKzhWZ2U9jezszeNrMl4X3bsN3M7I9mttTMvjSzoYn9DWLDzJqY2VwzezXc7mVmM8P34+9m1jxsbxFuLw0f75nIuGPBzNLNbJKZLQ4/JyOT9fNhZj8L/58sMLMXzKxlMn02zOxJM8s1swXl2mr9WTCzy8L9l5jZZQcSkxJB3SgG/svdBwIjgOvM7DDgF8AMd+8LzAi3Ac4E+oa3ccAj8Q85Lm4Csspt/wZ4KHw/NgFjw/axwCZ3PxR4KNyvsfkD8Ka7DwCOIHhfku7zYWaZwI3AMHcfDDQBLiS5PhtPA9+t0Farz4KZtQPGA8cAw4HxZcljv7i7bnV8A6YCpwPZQOewrTOQHf78KHBRuf2/3a+x3ICu4Qf6VOBVgpVC84Gm4eMjgenhz9OBkeHPTcP9LNG/Qx2+F62BFRV/p2T8fACZwNdAu/Df+lVgdLJ9NoCewIL9/SwAFwGPlmvfa7/a3nRGUMfCU9chwEygk7uvAwjvO4a7lf1nKLMmbGtMfg/8N1AabrcHCty9ONwu/zt/+36Ej28O928segN5wFNhV9njZtaKJPx8uHsO8ACwGlhH8G89m+T9bJSp7WehTj8jSgR1yMwOAl4Gbnb3LdXtWklboynfMrPvAbnuPrt8cyW7eoTHGoOmwFDgEXcfAmxnz6l/ZRrt+xF2X/wA6AV0AVoRdH9UlCyfjZpU9fvX6fuiRFBHzKwZQRJ43t0nh83rzaxz+HhnIDdsXwN0K3d4V2BtvGKNg+OAs81sJfAiQffQ74F0MytbFa/87/zt+xE+3gbYGM+AY2wNsMbdZ4bbkwgSQzJ+Pk4DVrh7nrsXAZOBY0nez0aZ2n4W6vQzokRQB8zMgCeALHd/sNxD04Cyq/mXEVw7KGu/NKwIGAFsLjstbAzc/XZ37+ruPQkuBL7r7hcD7wHnh7tVfD/K3qfzw/0bzV997v4N8LWZ9Q+bRgGLSM7Px2pghJmlhf9vyt6LpPxslFPbz8J04AwzaxueZZ0Rtu2fRF80aQw34HiC07IvgXnh7SyCvswZwJLwvl24vwF/BpYB8wkqKBL+e8TovTkZeDX8uTfwGbAU+AfQImxvGW4vDR/vnei4Y/A+HAnMCj8jU4C2yfr5AO4GFgMLgGeBFsn02QBeILg+UkTwl/3Y/fksAFeG78tS4IoDiUkji0VEkpy6hkREkpwSgYhIklMiEBFJckoEIiJJTolARCTJKRFIUjKzEjObV+5W3UhfzOxaM7u0Dl53pZl1ONDnEalLKh+VpGRm29z9oAS87kqCWvD8eL+2SFV0RiBSTvgX+2/M7LPwdmjYPsHMfh7+fKOZLQrnh38xbGtnZlPCtk/N7Dthe3szeyucbO5Rys0RY2aXhK8xz8weNbMmCfiVRZQIJGmlVugauqDcY1vcfTjwJ4I5kir6BTDE3b8DXBu23Q3MDdvuAP4ato8H/u3BZHPTgO4AZjYQuAA4zt2PBEqAi+v2VxSJpmnNu4g0SoXhF3BlXih3/1Alj38JPG9mUwimi4BgmpHzANz93fBMoA1wInBu2P6amW0K9x8FHAV8Hky5Qyp7JhoTiSslApF9eRU/l/kPgi/4s4E7zWwQ1U8LXNlzGPCMu99+IIGK1AV1DYns64Jy95+Uf8DMUoBu7v4ewcI76cBBwIeEXTtmdjKQ78GaFOXbzySYbA6CicXON7OO4WPtzKxHDH8nkSrpjECSVaqZzSu3/aa7l5WQtjCzmQR/KF1U4bgmwHNht48RrLNbYGYTCFYg+xLYwZ4phe8GXjCzOcAHBNMw4+6LzOyXwFthcikCrgNW1fUvKlITlY+KlKPyTklG6hoSEUlyOiMQEUlyOiMQEUlySgQiIklOiUBEJMkpEYiIJDklAhGRJKdEICKS5P4/OVDY6h1GYc4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x = [(n + 1) * 100 for n in range(10)]\n",
    "y = (100 * np.mean(win_pct, axis = 1)).astype('int')\n",
    "plt.plot(x, y, 'o-')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Win percentage of last 100 episodes')\n",
    "plt.savefig('tensorflow_random.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Þjálfa Player2 (Policy Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = PG.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "                afterstates.append(new_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        afterstates.append(new_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "        \n",
    "        States = np.vstack(states)\n",
    "        Rewards = PG.get_cumulative_rewards(rewards)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        PG.update(states = States, \n",
    "                      rewards = Rewards, \n",
    "                      afterstates = AfterStates, \n",
    "                      done = Dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    print(PG.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PG vs. Random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        #states = []\n",
    "        #afterstates = []\n",
    "        #rewards = []\n",
    "        #afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = PG.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                #rewards.append(reward)\n",
    "                #states.append(old_board)\n",
    "                #afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                \n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        new_board, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            reward = 0\n",
    "                            break\n",
    "                            \n",
    "        #afterstates.append(old_board)\n",
    "        #afterstates = afterstates[2:]\n",
    "        \n",
    "        #Dones = np.zeros(len(states))\n",
    "        #Dones[-1] = 1\n",
    "        \n",
    "        #States = np.vstack(states)\n",
    "        #Rewards = player.get_cumulative_rewards(rewards)\n",
    "        #AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        #player.update(states = States, \n",
    "        #              rewards = Rewards, \n",
    "        #              afterstates = AfterStates, \n",
    "        #              done = Dones)\n",
    "        \n",
    "        wins.append(reward)\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keppni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        #states = []\n",
    "        #afterstates = []\n",
    "        #rewards = []\n",
    "        #afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                #rewards.append(reward)\n",
    "                #states.append(old_board)\n",
    "                #afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            reward = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        #afterstates.append(old_board)\n",
    "        #afterstates = afterstates[2:]\n",
    "        \n",
    "        #Dones = np.zeros(len(states))\n",
    "        #Dones[-1] = 1\n",
    "        \n",
    "        #States = np.vstack(states)\n",
    "        #Rewards = player.get_cumulative_rewards(rewards)\n",
    "        #AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        #player.update(states = States, \n",
    "        #              rewards = Rewards, \n",
    "        #              afterstates = AfterStates, \n",
    "        #              done = Dones)\n",
    "        \n",
    "        wins.append(int(reward == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Þjálfa AC á PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "                afterstates.append(new_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        afterstates.append(new_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "        States = np.vstack(states)\n",
    "        CumulativeRewards = AC.get_cumulative_rewards(rewards)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        AC.update(states = States, \n",
    "                      rewards = CumulativeRewards,\n",
    "                      afterstates = AfterStates, \n",
    "                      done = Dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    print(\"Example policy: \", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prófa batch training (Virkar illa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    States = []\n",
    "    AfterStates = []\n",
    "    Rewards = []\n",
    "    Dones = []\n",
    "    \n",
    "    for _ in range(50):\n",
    "        \n",
    "        env = backgammon()\n",
    "        done = False\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        \n",
    "        afterstates.append([])\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = player.sample_action(possible_boards)\n",
    "                old_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(old_board)\n",
    "                afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                \n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        old_state, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "        afterstates.append(old_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        dones = np.zeros(len(rewards))\n",
    "        dones[-1] = 1\n",
    "        rewards = player.get_cumulative_rewards(rewards)\n",
    "        \n",
    "        States.append(states)\n",
    "        AfterStates.append(afterstates)\n",
    "        Rewards.append(rewards)\n",
    "        Dones.append(dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    #Rewards = np.concatenate(Rewards).flatten()\n",
    "    #States = np.vstack(States)\n",
    "    #AfterStates = np.vstack(AfterStates)\n",
    "    #Dones = np.concatenate(Dones).flatten()\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    \n",
    "    for r, s, a, d in zip(Rewards, States, AfterStates, Dones):\n",
    "        player.update(states = np.vstack(s), \n",
    "                      rewards = r, \n",
    "                      afterstates = np.vstack(a), \n",
    "                      done = d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Agent (Virkar illa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvActorCritic:\n",
    "    def __init__(self, gamma = 0.99, learning_rate = 1e-3, entropy = 0.1):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._states2D = tf.expand_dims(self._states, 2)\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._afterstates2D = tf.expand_dims(self._afterstates, 2)\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.network = keras.models.Sequential()\n",
    "        self.network.add(L.InputLayer(input_shape = (29, 1)))\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 2))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 4))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 8))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5,filters = 16))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 8))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Flatten())\n",
    "        self.network.add(L.Dense(128))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(1))\n",
    "                         \n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = self.network(self._states2D)\n",
    "        self._afterstate_values = self.network(self._afterstates2D) * (1 - self._done)\n",
    "        self._target_state_values = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values - self._state_values\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.network(self._states2D)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_entropy = -tf.reduce_sum(self._actor_policy * self._actor_log_policy)\n",
    "        \n",
    "        # Losses\n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values)))\n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_loss -= entropy * self._actor_entropy\n",
    "        \n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        self._update = self._optimizer.minimize(self._critic_loss + self._actor_loss)\n",
    "        \n",
    "        self._s = tf.InteractiveSession()\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        \n",
    "        return np.random.choice(np.arange(len(probs)), p = probs)\n",
    "    \n",
    "    def update(self, states, rewards, afterstates, done):\n",
    "        self._s.run(self._update, \n",
    "                    ({self._states: states, \n",
    "                      self._afterstates: afterstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "PG = PolicyGradient(sess = s, entropy = 0.1, learning_rate=1e-4, gamma = 0.9)\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(10):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        reward_vector = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                reward_vector.append(np.zeros(len(possible_boards)))\n",
    "                states.append(possible_boards)\n",
    "                actions.append(action)\n",
    "                afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        old_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                                     \n",
    "                            \n",
    "        afterstates.append(old_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        CumulativeRewards = PG.get_cumulative_rewards(rewards)\n",
    "        \n",
    "        for States, Reward, Reward_vector, Action in zip(states, CumulativeRewards, reward_vector, actions):\n",
    "            Reward_vector[Action] = Reward\n",
    "            \n",
    "            States = np.vstack(States)\n",
    "            Reward_vector = np.array(Reward_vector)\n",
    "            \n",
    "            PG.update(rewards = Reward_vector, states = States, afterstates = 0, done = 0)\n",
    "        \n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", PG.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sér network fyrir Actor og Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, gamma = 0.99):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.actor = keras.models.Sequential()\n",
    "        self.actor.add(L.Dense(32))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(64))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(32))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(1))\n",
    "        \n",
    "        # Critic\n",
    "        \n",
    "        self.critic = keras.models.Sequential()\n",
    "        self.critic.add(L.Dense(32))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(64))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(32))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(1))\n",
    "        \n",
    "        # Losses and logits\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = self.critic(self._states)\n",
    "        self._afterstate_values = self.critic(self._afterstates) * (1 - self._done)\n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values - self._state_values\n",
    "        \n",
    "    \n",
    "        self._target_state_values = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values)))\n",
    "        self._critic_optimizer = tf.train.AdamOptimizer()\n",
    "        self._critic_update = self._critic_optimizer.minimize(self._critic_loss)\n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.actor(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        \n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_optimizer = tf.train.AdamOptimizer()\n",
    "        self._actor_update = self._actor_optimizer.minimize(self._actor_loss)\n",
    "        \n",
    "        self._s = tf.InteractiveSession()\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        \n",
    "        return np.random.choice(np.arange(len(probs)), p = probs)\n",
    "    \n",
    "    def update(self, boards, rewards, afterstates, done):\n",
    "        self._s.run([self._actor_update, self._critic_update], \n",
    "                    ({self._states: boards, \n",
    "                      self._afterstates: afterstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
