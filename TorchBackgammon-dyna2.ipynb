{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Backgammon as B\n",
    "import agent as A\n",
    "import flipped_agent as FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backgammon:\n",
    "    def __init__(self):\n",
    "        self.board = B.init_board()\n",
    "            \n",
    "    def reset(self):\n",
    "        self.board = B.init_board()\n",
    "        self.done = False\n",
    "        \n",
    "    def choose_board(self, board):\n",
    "        self.board = board\n",
    "        self.done = False\n",
    "        return np.copy(self.board)\n",
    "    \n",
    "    def legal_moves(self, dice, player):\n",
    "        moves, boards = B.legal_moves(board = self.board, dice = dice, player = player)\n",
    "        if len(boards) == 0:\n",
    "            return [], self.board\n",
    "        return moves, np.vstack(boards)\n",
    "    \n",
    "    def swap_player(self):\n",
    "        self.board = FA.flip_board(board_copy=np.copy(self.board))\n",
    "    \n",
    "    # oppents random move\n",
    "    def make_move(self, dice):\n",
    "        moves, _ = self.legal_moves(dice, -1)\n",
    "        if len(moves) == 0:\n",
    "            return self.step([], -1)\n",
    "        move = moves[np.random.randint(len(moves))]\n",
    "        return self.step(move, -1)\n",
    "    \n",
    "    def step(self, move, player):\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                self.board = B.update_board(board = self.board, move = m, player = player)\n",
    "        reward = 0\n",
    "        self.done = False\n",
    "        if self.iswin():\n",
    "            reward = player\n",
    "            self.done = True\n",
    "        return np.copy(self.board), reward, self.done\n",
    "        \n",
    "    def iswin(self):\n",
    "        return B.game_over(self.board)\n",
    "        \n",
    "    def render(self):\n",
    "        B.pretty_print(self.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    #tf.reset_default_graph()\n",
    "    #tf.set_random_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "D_in, H1, H2, H3, D_out = 29, 32, 64, 128, 1\n",
    "\n",
    "actor = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H1, H2),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H2, H3),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H3, D_out),\n",
    "    torch.nn.Softmax(dim=0),\n",
    ")\n",
    "critic = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H1, H2),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H2, H3),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H3, D_out),\n",
    "    torch.nn.Tanh(),\n",
    ")\n",
    "memory = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H1, H2),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H2, H3),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H3, D_out),\n",
    "    torch.nn.Tanh(),\n",
    ")\n",
    "# save initial parameters of transient memory\n",
    "initial_memory = [copy.deepcopy(param) for param in memory.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_and_value(actor, boards):\n",
    "    boards = torch.from_numpy(boards).float()\n",
    "    possible_actions_probs = actor(boards)\n",
    "    with torch.no_grad():\n",
    "        action = int(torch.multinomial(possible_actions_probs.view(1,-1), 1))\n",
    "    action_value = possible_actions_probs[action]\n",
    "    return action, action_value\n",
    "\n",
    "def get_action_value(actor, boards, action):\n",
    "    boards = torch.from_numpy(boards).float()\n",
    "    possible_actions_probs = actor(boards)\n",
    "    action_value = possible_actions_probs[action]\n",
    "    return action_value\n",
    "\n",
    "def get_action(actor, boards):\n",
    "    with torch.no_grad():\n",
    "        boards = torch.from_numpy(boards).float()\n",
    "        possible_actions_probs = actor(boards)\n",
    "        action = torch.multinomial(possible_actions_probs.view(1,-1), 1)\n",
    "    return int(action)\n",
    "\n",
    "def get_state_value(nn_model, after_state):\n",
    "    after_state = torch.from_numpy(after_state).float()\n",
    "    value = nn_model(after_state)\n",
    "    return value\n",
    "\n",
    "def epsilon_greedy(critic, possible_boards, epsilon=.9):\n",
    "    possible_boards = torch.from_numpy(possible_boards).float()\n",
    "    values = critic(possible_boards)\n",
    "    if np.random.random()<epsilon:\n",
    "        _ , index = values.max(0)\n",
    "    else:\n",
    "        index = np.random.randint(0, len(possible_boards))\n",
    "    return int(index)\n",
    "\n",
    "def composite_greedy(critic, memory, possible_boards, epsilon=1):\n",
    "    possible_boards = torch.from_numpy(possible_boards).float()\n",
    "    critic_values = critic(possible_boards)\n",
    "    memory_values = memory(possible_boards)\n",
    "    values = critic_values + memory_values\n",
    "    if np.random.random()<epsilon:\n",
    "        _ , index = values.max(0)\n",
    "    else:\n",
    "        index = np.random.randint(0, len(possible_boards))\n",
    "    return int(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use: valuefn_temp = search(pre_state, memory, n_dreams, max_steps)\n",
    "Input: pre_state is current state,\n",
    "       memory is the transient memorythe value function,\n",
    "       old_value is the value of last after state\n",
    "       n_dreams is number of dreams,\n",
    "       max_steps is maximum number of steps,\n",
    "Output: memory has been updated for episodes in dream\n",
    "\"\"\"\n",
    "def search(pre_state, pre_value, pre_dice, n_dreams, max_steps = 1000):    \n",
    "    # Dream n_dreams\n",
    "    for dreams in range(n_dreams):\n",
    "        # Clear eligibility trace\n",
    "        memory_Z = [0 for layer in critic.parameters()]\n",
    "        done = False\n",
    "        step = 1\n",
    "        state = env.choose_board(np.copy(pre_state))\n",
    "        #Set after_state = pre_state to deal with possibilty of no legal move on first step\n",
    "        #after_state = env.choose_board(np.copy(pre_state))\n",
    "        old_value = pre_value\n",
    "        \n",
    "        # play one round and update\n",
    "        while not (done or step > max_steps):\n",
    "            if step == 1:\n",
    "                dice = pre_dice\n",
    "            else:\n",
    "                dice = B.roll_dice()\n",
    "                \n",
    "            for i in range(1 + int(dice[0] == dice[1])):\n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                if len(possible_moves) == 0:\n",
    "                    after_state = np.copy(state)\n",
    "                    #skip_round = True\n",
    "                    #after_state = next_state\n",
    "                    break\n",
    "                # Use composite value function to choose action\n",
    "                action = composite_greedy(critic, memory, possible_boards)\n",
    "                after_state, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                if done:\n",
    "                    break\n",
    "            if not done:\n",
    "                with torch.no_grad():\n",
    "                    critic_value = get_state_value(critic, after_state)\n",
    "                    \n",
    "                memory_value = get_state_value(memory, after_state)\n",
    "                value = critic_value + memory_value\n",
    "                #calc critic gradient\n",
    "                memory.zero_grad()\n",
    "                memory_value.backward()\n",
    "            else:\n",
    "                value = 0\n",
    "            with torch.no_grad():\n",
    "                if step > 1:\n",
    "                    delta = reward + gamma*value - old_value\n",
    "                    for i, param in enumerate(memory.parameters()):\n",
    "                        param += memory_alpha * delta * memory_Z[i]\n",
    "                if not done:        \n",
    "                    for i, param in enumerate(memory.parameters()):\n",
    "                        memory_Z[i] = memory_lambda * memory_Z[i] + param.grad\n",
    "\n",
    "                old_value = value\n",
    "            \n",
    "\n",
    "                # other players move\n",
    "                if not done:\n",
    "                    dice = B.roll_dice()\n",
    "                    for i in range(1 + int(dice[0] == dice[1])):\n",
    "                        next_state, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            break\n",
    "                    #next_value = get_state_value(critic, next_state)\n",
    "                else:\n",
    "                    next_value = 0\n",
    "                \n",
    "            step +=1\n",
    "        if reward == -1:\n",
    "            with torch.no_grad():\n",
    "                delta = reward - old_value\n",
    "                for i, param in enumerate(memory.parameters()):\n",
    "                        param += memory_alpha * delta * memory_Z[i]\n",
    "\n",
    "    state = env.choose_board(pre_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew_plt = []\n",
    "\n",
    "def playAgainstRandom(iters = 100):\n",
    "    global rew_plt\n",
    "    rew = []\n",
    "    for episode in range(iters):\n",
    "        env.reset()\n",
    "        done = False\n",
    "\n",
    "        if (episode%20==0):\n",
    "            print(\"EPISODE: \", episode)\n",
    "\n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for i in range(1 + int(dice[0] == dice[1])):\n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                if len(possible_moves) == 0:\n",
    "                    break\n",
    "\n",
    "                action = epsilon_greedy(critic, possible_boards) # No search on first step                    \n",
    "                after_state, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                if not done:\n",
    "                    dice = B.roll_dice()\n",
    "                    for i in range(1 + int(dice[0] == dice[1])):\n",
    "                        next_state, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            break\n",
    "\n",
    "\n",
    "        rew.append(reward)\n",
    "\n",
    "\n",
    "    clear_output(True)\n",
    "    print('Reward: ',reward)\n",
    "    rew_plt.append(np.mean(np.equal(rew,1)))\n",
    "    rew = []\n",
    "    plt.plot(rew_plt)\n",
    "    plt.axhline(0.5, color=\"gray\")\n",
    "    plt.show()\n",
    "    print(rew_plt[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x207bc98b320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "EPISODE:  720\n",
      "EPISODE:  740\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.99\n",
    "actor_alpha = 0.01\n",
    "critic_alpha = 0.01\n",
    "memory_alpha = 0.01\n",
    "actor_lambda = 0.7\n",
    "critic_lambda = 0.7\n",
    "memory_lambda = 0.7\n",
    "forever = 2000\n",
    "\n",
    "plt_iter = 100\n",
    "\n",
    "\n",
    "from time import time\n",
    "tic = time()\n",
    "\n",
    "\n",
    "env = backgammon()\n",
    "for episode in range(1,forever+1):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    step = 1\n",
    "    value_grad = [ [0 for layer in actor.parameters()] for player in range(2) ]\n",
    "    critic_Z = [ [0 for layer in critic.parameters()] for player in range(2) ]\n",
    "    value = [[0,0],[0,0]] #value[player][0(old),1(new)]\n",
    "    \n",
    "#    # Transient memory\n",
    "#    with torch.no_grad():\n",
    "#        for i, param in enumerate(memory.parameters()):\n",
    "#            param.data.copy_(initial_memory[i])\n",
    "#    n_dreams = 5\n",
    "#    max_rounds = 5\n",
    "    \n",
    "    \n",
    "    player = 0\n",
    "    \n",
    "    if (episode%20==0):\n",
    "        print(\"EPISODE: \", episode)\n",
    "\n",
    "    while not done:\n",
    "        dice = B.roll_dice()\n",
    "        for i in range(1 + int(dice[0] == dice[1])):\n",
    "            possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "            if len(possible_moves) == 0:\n",
    "                break\n",
    "            '''                \n",
    "            if (step > 1):\n",
    "                pre_state = np.copy(env.board)\n",
    "                search(pre_state, old_value, n_dreams, max_rounds)\n",
    "                action = composite_greedy(critic, memory, possible_boards)\n",
    "            else:\n",
    "                action = epsilon_greedy(critic, possible_boards) # No search on first step\n",
    "            '''\n",
    "            action = epsilon_greedy(critic, possible_boards) # this or ^\n",
    "                \n",
    "            after_state, reward, done = env.step(possible_moves[action], player = 1)\n",
    "            if done:\n",
    "                break\n",
    "        if not done:\n",
    "            value[player][0] = float(value[player][1]) # old_value\n",
    "            value[player][1] = get_state_value(critic, after_state)\n",
    "            critic.zero_grad()\n",
    "            value[player][1].backward()\n",
    "            with torch.no_grad():\n",
    "                for i, param in enumerate(critic.parameters()):\n",
    "                    value_grad[player][i] = param.grad\n",
    "                    \n",
    "            if (step>2):\n",
    "                with torch.no_grad():\n",
    "                    reward = 0 # Reward er 0\n",
    "                    delta = reward + gamma*value[player][1] - value[player][0]\n",
    "\n",
    "                    for i, param in enumerate(critic.parameters()):\n",
    "                        param += critic_alpha * delta * critic_Z[player][i]\n",
    "                        critic_Z[player][i] = critic_lambda * critic_Z[player][i] + value_grad[player][i]\n",
    "            step += 1\n",
    "            player = not player\n",
    "            env.swap_player()\n",
    "            \n",
    "    value[player][0] = float(value[player][1])\n",
    "    value[player][1] = 0\n",
    "    \n",
    "    value[not player][0] = float(value[not player][1])\n",
    "    value[not player][1] = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        delta1 = reward + gamma*value[player][1] - value[player][0]\n",
    "        delta2 = -reward + gamma*value[not player][1] - value[not player][0]\n",
    "\n",
    "        for i, param in enumerate(critic.parameters()):\n",
    "            param += critic_alpha * delta * critic_Z[player][i]\n",
    "            param += critic_alpha * delta2 * critic_Z[not player][i]\n",
    "            \n",
    "    if episode%plt_iter == 0:\n",
    "        playAgainstRandom(iters = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
