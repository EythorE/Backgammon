{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import Backgammon as B\n",
    "import agent as A\n",
    "import flipped_agent as FA\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_rewards(rewards, gamma = 1):\n",
    "    rewards = np.array(rewards)\n",
    "    R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "    r = 0.\n",
    "    for i, reward in enumerate(reversed(rewards)):\n",
    "        r += reward\n",
    "        R[-(i + 1)] = r\n",
    "        r *= gamma\n",
    "        \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(_states, _rewards):\n",
    "    _cumulative_rewards = get_cumulative_rewards(_rewards)\n",
    "    update.run({states: _states, \n",
    "                cumulative_rewards: _cumulative_rewards})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Þetta fall spilar heilan leik gegn random agent\n",
    "'''\n",
    "\n",
    "def PlayRandomAgent(Explore = True, Debug = False, Verbose = False, Learn = True):\n",
    "\n",
    "    boards, rewards = [], []\n",
    "    board = B.init_board()\n",
    "    player = 1\n",
    "    \n",
    "    Error = False\n",
    "    GameOver = False\n",
    "    k = 1\n",
    "    '''\n",
    "    Pælingin hér er að spila einn leik til enda og geyma öll boards og actions. \n",
    "    Reikna svo eligibility trace og update'a modelið með öllu episodeinu.\n",
    "    '''\n",
    "    while True:\n",
    "        dice = B.roll_dice()\n",
    "        for i in range(1 + int(dice[0] == dice[1])):\n",
    "            \n",
    "            legal_moves, legal_boards = B.legal_moves(board, dice, 1)\n",
    "\n",
    "            if len(legal_moves) == 0:\n",
    "                break\n",
    "\n",
    "            \n",
    "            probs = get_action_prob(legal_boards)\n",
    "            n_actions = probs.shape[0]\n",
    "            probs = probs.reshape(n_actions)\n",
    "            \n",
    "            if Explore == True:\n",
    "                action = np.random.choice(np.arange(0, n_actions), \n",
    "                                     p = probs)\n",
    "            else:\n",
    "                action = np.argmax(probs)\n",
    "\n",
    "            move = legal_moves[action]\n",
    "\n",
    "\n",
    "            if Debug:\n",
    "                print(\"Action: \\n\", action)\n",
    "                print(\"Board now: \\n\", board)\n",
    "                print(\"Chosen move:\\n\", move)\n",
    "\n",
    "            if len(move) != 0:\n",
    "                for m in move:\n",
    "                    board = B.update_board(board = board, move = m, player = 1)\n",
    "            boards.append(board)\n",
    "            \n",
    "            GameOver = B.game_over(board)\n",
    "            if GameOver:\n",
    "                rewards.append(1)\n",
    "                break\n",
    "        if GameOver:\n",
    "                break\n",
    "                \n",
    "        \n",
    "        board = FA.flip_board(board)\n",
    "        player *= -1\n",
    "        dice = B.roll_dice()\n",
    "            \n",
    "            \n",
    "        for i in range(1 + int(dice[0] == dice[1])):\n",
    "            \n",
    "            legal_moves, legal_boards = B.legal_moves(board, dice, 1)\n",
    "            legal_boards = np.array([board for board in legal_boards])\n",
    "\n",
    "            if len(legal_moves) == 0:\n",
    "                break\n",
    "\n",
    "            \n",
    "            move = legal_moves[np.random.randint(len(legal_moves))]\n",
    "\n",
    "\n",
    "            if Debug:\n",
    "                print(\"Action: \\n\", action)\n",
    "                print(\"Board now: \\n\", board)\n",
    "                print(\"Chosen move:\\n\", move)\n",
    "\n",
    "            if len(move) != 0:\n",
    "                for m in move:\n",
    "                    board = B.update_board(board = board, move = m, player = 1)\n",
    "            \n",
    "            GameOver = B.game_over(board)\n",
    "            if GameOver:\n",
    "                rewards.append(-1)\n",
    "                break\n",
    "            else:\n",
    "                rewards.append(0)\n",
    "            player *= -1\n",
    "\n",
    "        if GameOver:\n",
    "            if Verbose:\n",
    "                print(\"Game is over.\")\n",
    "            break\n",
    "\n",
    "        if B.check_for_error(board):\n",
    "            Error = True\n",
    "            print(\"Error at game step \", k)\n",
    "            break\n",
    "        k += 1\n",
    "         \n",
    "    if not Error and Learn: \n",
    "        train_step(boards, rewards)\n",
    "    return (player + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Þetta fall spilar heilan leik, uppfærir tauganetið og skilar K, sem er fjöldi umferða í leiknum.\n",
    "'''\n",
    "\n",
    "def generate_session(Explore = True, Debug = False, Verbose = False):\n",
    "\n",
    "    # Spila leikinn\n",
    "    boards, rewards = [[], []], [[], []]\n",
    "\n",
    "    board = B.init_board()\n",
    "    player = 1\n",
    "    \n",
    "    Error = False\n",
    "    GameOver = False\n",
    "    k = 0\n",
    "    '''\n",
    "    Pælingin hér er að spila einn leik til enda og geyma öll boards og actions. \n",
    "    Reikna svo eligibility trace og update'a modelið með öllu episodeinu.\n",
    "    '''\n",
    "    while True:\n",
    "        dice = B.roll_dice()\n",
    "        for i in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "            legal_moves, legal_boards = B.legal_moves(board, dice, 1)\n",
    "\n",
    "            if len(legal_moves) == 0:\n",
    "                break\n",
    "\n",
    "            #probs = np.array([get_action_prob(state.reshape(1, 29)) for state in legal_boards])\n",
    "            probs = get_action_prob(legal_boards)\n",
    "            n_actions = probs.shape[0]\n",
    "            probs = probs.reshape(n_actions)\n",
    "            \n",
    "            if Explore == True:\n",
    "                action = np.random.choice(np.arange(0, n_actions), \n",
    "                                     p = probs)\n",
    "            else:\n",
    "                action = np.argmax(probs)\n",
    "\n",
    "            move = legal_moves[action]\n",
    "\n",
    "\n",
    "            if Debug:\n",
    "                print(\"Action: \\n\", action)\n",
    "                print(\"Board now: \\n\", board)\n",
    "                print(\"Chosen move:\\n\", move)\n",
    "\n",
    "            if len(move) != 0:\n",
    "                for m in move:\n",
    "                    board = B.update_board(board = board, move = m, player = 1)\n",
    "\n",
    "            #record session history to train later\n",
    "            \n",
    "            boards[int((player + 1) / 2)].append(board)\n",
    "            \n",
    "            GameOver = B.game_over(board)\n",
    "            if GameOver:\n",
    "                rewards[int((player + 1) / 2)].append(1)\n",
    "                rewards[int((-player + 1) / 2)].append(-1)\n",
    "                break\n",
    "            else:\n",
    "                rewards[int((player + 1) / 2)].append(0)\n",
    "\n",
    "        board = FA.flip_board(board)\n",
    "        player *= -1\n",
    "        if GameOver:\n",
    "            if Verbose:\n",
    "                print(\"Game is over.\")\n",
    "            break\n",
    "\n",
    "        if B.check_for_error(board):\n",
    "            Error = True\n",
    "            print(\"Error at game step \", k)\n",
    "            break\n",
    "        k += 1\n",
    "    if not Error:  \n",
    "        for i in range(2):\n",
    "            train_step(boards[i], rewards[i])\n",
    "            \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skilgreina inputs í model\n",
    "states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"cumulative_rewards\")\n",
    "\n",
    "# Skilgreina model (arkitektúrinn skiptir litlu máli þangað til að þjálfunin gengur)\n",
    "model = keras.models.Sequential()\n",
    "model.add(L.Dense(100, activation = \"linear\"))\n",
    "model.add(L.Dense(100, activation = \"linear\"))\n",
    "model.add(L.Dense(100, activation = \"relu\"))\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "\n",
    "logits = model(states)\n",
    "policy = tf.nn.softmax(logits, axis = 0)\n",
    "log_policy = tf.nn.log_softmax(logits, axis = 0)\n",
    "\n",
    "get_action_prob = lambda s: policy.eval({states: s})\n",
    "\n",
    "J = tf.reduce_mean(log_policy * cumulative_rewards)\n",
    "entropy = tf.reduce_sum(tf.multiply(policy, log_policy), 1, name=\"entropy\")\n",
    "\n",
    "loss = - J + 0.1 * entropy\n",
    "\n",
    "\n",
    "# Að maximiza J er það sama og að minimiza -J\n",
    "all_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "update = tf.train.AdamOptimizer().minimize(loss, var_list = all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession()\n",
    "s.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8036630e-02],\n",
       "       [2.4270599e-07],\n",
       "       [1.5166575e-20],\n",
       "       [4.8171246e-01],\n",
       "       [6.4856208e-06],\n",
       "       [4.0498639e-19],\n",
       "       [2.4420439e-04],\n",
       "       [2.7009231e-10],\n",
       "       [3.2887919e-09],\n",
       "       [2.0540205e-22],\n",
       "       [1.8996019e-13],\n",
       "       [2.5577186e-18],\n",
       "       [5.4747050e-29],\n",
       "       [1.5989395e-31],\n",
       "       [1.8036630e-02],\n",
       "       [4.8171246e-01],\n",
       "       [2.4420439e-04],\n",
       "       [1.8996019e-13],\n",
       "       [2.4270599e-07],\n",
       "       [2.7009231e-10],\n",
       "       [6.4856208e-06],\n",
       "       [3.2887919e-09],\n",
       "       [2.5577186e-18],\n",
       "       [1.5166575e-20],\n",
       "       [4.0498639e-19],\n",
       "       [2.0540205e-22],\n",
       "       [5.4747050e-29],\n",
       "       [1.5989395e-31]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, boards = B.legal_moves(B.init_board(), B.roll_dice(), 1)\n",
    "policy.eval({states: boards})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training against self\n",
      "Mean rounds to win:  59.01\n",
      "Playing random agent\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5b23699a61ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Playing random agent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mwins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPlayRandomAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExplore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mwin_pct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Win percentage: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-5b23699a61ca>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Playing random agent\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mwins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPlayRandomAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExplore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mwin_pct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Win percentage: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1563d0cbdde1>\u001b[0m in \u001b[0;36mPlayRandomAgent\u001b[0;34m(Explore, Debug, Verbose, Learn)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mlegal_moves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegal_boards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Skóli Haust 2018/Reiknigreind/Backgammon/Backgammon.py\u001b[0m in \u001b[0;36mlegal_moves\u001b[0;34m(board, dice, player)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mpossible_second_moves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegal_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_board\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_second_moves\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m                 \u001b[0mboards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_board\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "win_pct = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    k = [generate_session() for _ in range(100)]\n",
    "    clear_output(True)\n",
    "    print(\"Training against self\")\n",
    "    print(\"Mean rounds to win: \", np.mean(k))\n",
    "    \n",
    "    print(\"Playing random agent\")\n",
    "    wins = [PlayRandomAgent(Learn = False, Explore = False) for _ in range(10)]\n",
    "    win_pct.append(np.mean(wins))\n",
    "    print(\"Win percentage: \", np.mean(wins))\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allt hér fyrir neðan var notað sem fikkt\n",
    "\n",
    "Útgáfa þar sem við flippum borðið þ.a. agentinn er bara alltaf nr 1 og flippum aldrei moveinu hans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step2(_states, _actions, _rewards):\n",
    "    _cumulative_rewards = get_cumulative_rewards(_rewards)\n",
    "    _actions[_actions == 1] = _cumulative_rewards\n",
    "    update.run({states: _states, \n",
    "                actions: _actions,\n",
    "                cumulative_rewards: _cumulative_rewards})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637, 29) (637, 1) (34,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f812eaad12a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-967fc04e8d58>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(_states, _actions, _rewards)\u001b[0m\n\u001b[1;32m      4\u001b[0m     update.run({states: _states, \n\u001b[1;32m      5\u001b[0m                 \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 cumulative_rewards: _cumulative_rewards})\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Spila leikinn\n",
    "boards, actions, rewards = [[], []], [[], []], [[], []]\n",
    "#all_boards = []\n",
    "\n",
    "board = B.init_board()\n",
    "player = 1\n",
    "\n",
    "Error = False\n",
    "GameOver = False\n",
    "Explore = True\n",
    "Debug = False\n",
    "Verbose = False\n",
    "k = 0\n",
    "'''\n",
    "Pælingin hér er að spila einn leik til enda og geyma öll boards og actions. \n",
    "Reikna svo eligibility trace og update'a modelið með öllu episodeinu.\n",
    "'''\n",
    "while True:\n",
    "    dice = B.roll_dice()\n",
    "    for i in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "        legal_moves, legal_boards = B.legal_moves(board, dice, 1)\n",
    "\n",
    "        if len(legal_moves) == 0:\n",
    "            break\n",
    "\n",
    "        #probs = np.array([get_action_prob(state.reshape(1, 29)) for state in legal_boards])\n",
    "        probs = get_action_prob(legal_boards)\n",
    "        n_actions = probs.shape[0]\n",
    "        probs = probs.reshape(n_actions)\n",
    "\n",
    "        if Explore == True:\n",
    "            action = np.random.choice(np.arange(0, n_actions), \n",
    "                                 p = probs)\n",
    "        else:\n",
    "            action = np.argmax(probs)\n",
    "\n",
    "        move = legal_moves[action]\n",
    "\n",
    "\n",
    "        if Debug:\n",
    "            print(\"Action: \\n\", action)\n",
    "            print(\"Board now: \\n\", board)\n",
    "            print(\"Chosen move:\\n\", move)\n",
    "\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                board = B.update_board(board = board, move = m, player = 1)\n",
    "\n",
    "        #record session history to train later\n",
    "        all_actions = np.zeros((n_actions, 1))\n",
    "        all_actions[action, 0] = 1\n",
    "        boards[int((player + 1) / 2)].append(legal_boards)\n",
    "        actions[int((player + 1) / 2)].append(all_actions)\n",
    "        #all_boards[int((player + 1) / 2)].append(legal_boards)\n",
    "\n",
    "        GameOver = B.game_over(board)\n",
    "        if GameOver:\n",
    "            rewards[int((player + 1) / 2)].append(1)\n",
    "            rewards[int((-player + 1) / 2)].append(-1)\n",
    "            break\n",
    "        else:\n",
    "            rewards[int((player + 1) / 2)].append(0)\n",
    "\n",
    "    board = FA.flip_board(board)\n",
    "    player *= -1\n",
    "    if GameOver:\n",
    "        if Verbose:\n",
    "            print(\"Game is over.\")\n",
    "        break\n",
    "\n",
    "    if B.check_for_error(board):\n",
    "        Error = True\n",
    "        print(\"Error at game step \", k)\n",
    "        break\n",
    "    k += 1\n",
    "if not Error:  \n",
    "    for i in range(2):\n",
    "        train_step(np.vstack(boards[i]), np.vstack(actions[i]), rewards[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rewards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(637, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.vstack(actions[0])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0., -2.,  1., -0., -0.,  1.,  4., -0.,  2., -0., -0., -0., -4.,\n",
       "        5., -0., -0., -0., -4., -0., -4., -0., -0., -0., -1.,  2., -0.,\n",
       "       -0., -0., -0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(boards[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rewards[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-1bb44e196acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cumulative_rewards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m s.run(loss, ({states: s, \n\u001b[0m\u001b[1;32m      5\u001b[0m               \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               cumulative_rewards: cr}))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "ss = np.vstack(boards[0])[0]\n",
    "a = np.vstack(actions[0])[0]\n",
    "cr = get_cumulative_rewards(rewards[0])\n",
    "\n",
    "s.run(loss, ({states: ss, \n",
    "              actions: a, \n",
    "              cumulative_rewards: cr}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'object' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-db8a56eff87b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_cumulative_rewards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'object' (pos 1) not found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Útgáfa þar sem við flippum boardið fyrir Player -1 og flippum múvið hans. \n",
    "Virkar ekki eins og er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game is over.\n"
     ]
    }
   ],
   "source": [
    "# Spila leikinn\n",
    "boards, moves, rewards = [], [], []\n",
    "    \n",
    "board = B.init_board()\n",
    "player = 1\n",
    "\n",
    "k = 1 # Halda utan um hvenær ég fæ villu\n",
    "Error = False\n",
    "Debug = False\n",
    "\n",
    "\n",
    "'''\n",
    "Pælingin hér er að spila einn leik til enda og geyma öll boards og actions. \n",
    "Reikna svo eligibility trace og update'a modelið með öllu episodeinu.\n",
    "'''\n",
    "while True:\n",
    "    dice = B.roll_dice()\n",
    "    for i in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "        legal_moves, legal_boards = B.legal_moves(board, dice, 1)\n",
    "        legal_boards = np.array([board for board in legal_boards])\n",
    "\n",
    "        if len(legal_moves) == 0:\n",
    "            break\n",
    "\n",
    "        #probs = np.array([get_action_prob(state.reshape(1, 29)) for state in legal_boards])\n",
    "        probs = get_action_prob(legal_boards)\n",
    "        n_actions = probs.shape[0]\n",
    "        probs = probs.reshape(n_actions)\n",
    "        probs = probs / np.sum(probs)\n",
    "\n",
    "        action = np.random.choice(np.arange(0, n_actions), \n",
    "                             p = probs)\n",
    "        \n",
    "        move = legal_moves[action]\n",
    "        \n",
    "        \n",
    "        if Debug:\n",
    "            print(\"Action: \\n\", action)\n",
    "            print(\"Board now: \\n\", board)\n",
    "            print(\"Chosen move:\\n\", move)\n",
    "            \n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                board = B.update_board(board = board, move = m, player = 1)\n",
    "\n",
    "        #record session history to train later\n",
    "        boards.append(board)\n",
    "        moves.append(move)\n",
    "\n",
    "        if B.game_over(board):\n",
    "            rewards.append(1)\n",
    "            break\n",
    "        else:\n",
    "            rewards.append(0)\n",
    "            \n",
    "        board = FA.flip_board(board)\n",
    "    \n",
    "    if B.game_over(board):\n",
    "            print(\"Game is over.\")\n",
    "            break\n",
    "    \n",
    "    if B.check_for_error(board):\n",
    "        Error = True\n",
    "        print(\"Error at game step \", k)\n",
    "        break\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[13, 10],\n",
       "        [13, 11]]), array([[13, 10],\n",
       "        [24, 22]]), array([[10,  8],\n",
       "        [13, 10]]), array([[22, 21],\n",
       "        [ 6,  4]]), array([[6, 5],\n",
       "        [8, 2]]), array([[24, 22],\n",
       "        [ 8,  6]]), array([[6, 4],\n",
       "        [4, 2]]), array([[25, 20],\n",
       "        [22, 16]]), array([[25, 20],\n",
       "        [11,  6]]), array([[13,  8],\n",
       "        [16, 11]]), array([[24, 22],\n",
       "        [13,  8]]), array([[ 6,  3],\n",
       "        [13,  9]]), array([[25, 22],\n",
       "        [ 8,  5]]), array([[25, 22],\n",
       "        [25, 22]]), array([[8, 4],\n",
       "        [2, 1]]), array([[4, 1],\n",
       "        [9, 3]]), array([[25, 24],\n",
       "        [25, 21]]), array([[25, 23],\n",
       "        [22, 18]]), array([[25, 20],\n",
       "        [ 8,  2]]), array([[25, 24],\n",
       "        [18, 15]]), array([[25, 22]]), array([[25, 22],\n",
       "        [22, 20]]), array([[25, 23],\n",
       "        [25, 21]]), array([[13,  7],\n",
       "        [ 6,  1]]), array([[25, 20],\n",
       "        [ 8,  2]]), array([[15, 10],\n",
       "        [22, 21]]), array([[25, 20],\n",
       "        [22, 16]]), array([[7, 1],\n",
       "        [8, 2]]), array([[25, 23],\n",
       "        [20, 16]]), array([[25, 21],\n",
       "        [21, 15]]), array([[23, 20],\n",
       "        [21, 18]]), array([[24, 21],\n",
       "        [10,  7]]), array([[25, 22],\n",
       "        [22, 16]]), array([[ 8,  7],\n",
       "        [15, 12]]), array([[25, 23],\n",
       "        [ 6,  2]]), array([[ 7,  3],\n",
       "        [11,  7]]), array([[21, 17],\n",
       "        [16, 12]]), array([[25, 22]]), array([[23, 22],\n",
       "        [16, 10]]), array([[25, 21],\n",
       "        [25, 20]]), array([[ 6,  1],\n",
       "        [10,  9]]), array([[22, 18],\n",
       "        [10,  9]]), array([[25, 22],\n",
       "        [ 9,  8]]), array([[9, 8],\n",
       "        [6, 4]]), array([[25, 21],\n",
       "        [20, 15]]), array([[25, 21],\n",
       "        [18, 15]]), array([[22, 17],\n",
       "        [12,  6]]), array([[25, 24],\n",
       "        [12,  6]]), array([[25, 21],\n",
       "        [15, 14]]), array([[24, 22],\n",
       "        [15, 10]]), array([[ 6,  1],\n",
       "        [22, 21]]), array([[21, 20],\n",
       "        [ 7,  3]]), array([[14, 12],\n",
       "        [ 8,  2]]), array([[21, 15],\n",
       "        [22, 21]]), array([[20, 18],\n",
       "        [21, 17]]), array([[25, 24],\n",
       "        [ 6,  3]]), array([[25, 23],\n",
       "        [18, 16]]), array([[20, 18],\n",
       "        [20, 18]]), array([[20, 16],\n",
       "        [17, 13]]), array([[20, 16],\n",
       "        [18, 14]]), array([[13, 11],\n",
       "        [12, 11]]), array([[25, 20],\n",
       "        [ 6,  5]]), array([[25, 23],\n",
       "        [16, 15]]), array([[25, 21],\n",
       "        [ 5,  3]]), array([[15, 13],\n",
       "        [17, 13]]), array([[24, 22],\n",
       "        [15, 13]]), array([[11,  9],\n",
       "        [16, 14]]), array([[25, 20],\n",
       "        [21, 15]]), array([[23, 19],\n",
       "        [14,  8]]), array([[25, 22],\n",
       "        [ 3,  2]]), array([[25, 19],\n",
       "        [11,  7]]), array([[25, 22],\n",
       "        [13,  9]]), array([[19, 13],\n",
       "        [13, 10]]), array([[25, 21],\n",
       "        [22, 16]]), array([[25, 20],\n",
       "        [ 8,  6]]), array([[21, 20],\n",
       "        [20, 16]]), array([[19, 13],\n",
       "        [21, 20]]), array([[21, 15],\n",
       "        [16, 14]]), array([[25, 20],\n",
       "        [ 7,  2]]), array([[21, 16],\n",
       "        [15, 10]]), array([[21, 15],\n",
       "        [20, 16]]), array([[25, 20],\n",
       "        [25, 21]]), array([[13, 11],\n",
       "        [13,  8]]), array([[25, 24],\n",
       "        [22, 18]]), array([[20, 15],\n",
       "        [16, 12]]), array([[16, 15],\n",
       "        [ 3,  1]]), array([[12, 11],\n",
       "        [15, 13]]), array([[20, 15],\n",
       "        [24, 21]]), array([[13, 11],\n",
       "        [20, 19]]), array([[21, 18],\n",
       "        [18, 17]]), array([[25, 21],\n",
       "        [19, 15]]), array([[16, 12],\n",
       "        [12,  8]]), array([[25, 22],\n",
       "        [15, 14]]), array([[25, 21],\n",
       "        [20, 17]]), array([[ 6,  3],\n",
       "        [21, 18]]), array([[25, 22],\n",
       "        [21, 18]]), array([[25, 20],\n",
       "        [18, 16]]), array([[17, 11],\n",
       "        [22, 21]]), array([[25, 22],\n",
       "        [22, 21]]), array([[ 8,  2],\n",
       "        [11,  6]]), array([[21, 16],\n",
       "        [15, 13]]), array([[17, 13],\n",
       "        [15, 13]]), array([[ 6,  1],\n",
       "        [22, 20]]), array([[15, 12],\n",
       "        [ 2,  1]]), array([[25, 20],\n",
       "        [20, 15]]), array([[12,  7],\n",
       "        [ 6,  1]]), array([[11,  8],\n",
       "        [15, 11]]), array([[13, 12],\n",
       "        [21, 18]]), array([[20, 17],\n",
       "        [ 8,  2]]), array([[21, 17],\n",
       "        [13, 10]]), array([[16, 12],\n",
       "        [ 6,  4]]), array([[25, 19],\n",
       "        [10,  8]]), array([[25, 19],\n",
       "        [19, 18]]), array([[25, 24],\n",
       "        [18, 12]]), array([[25, 21],\n",
       "        [11,  6]]), array([[25, 20],\n",
       "        [18, 16]]), array([[4, 1],\n",
       "        [6, 1]]), array([[25, 21],\n",
       "        [20, 15]]), array([[20, 14],\n",
       "        [12,  7]]), array([[25, 19],\n",
       "        [17, 16]]), array([[16, 12],\n",
       "        [21, 18]]), array([[12, 10],\n",
       "        [10,  5]]), array([[14,  8],\n",
       "        [ 7,  2]]), array([[12,  6],\n",
       "        [ 6,  3]]), array([[12,  8],\n",
       "        [18, 14]]), array([[16, 12],\n",
       "        [ 5,  1]]), array([[11,  7],\n",
       "        [18, 12]]), array([[20, 18],\n",
       "        [15, 11]]), array([[25, 20]]), array([[11,  6],\n",
       "        [19, 14]]), array([[25, 20],\n",
       "        [25, 20]]), array([[18, 15],\n",
       "        [15, 13]]), array([[25, 20],\n",
       "        [20, 14]]), array([[13, 12],\n",
       "        [ 8,  7]]), array([[8, 7],\n",
       "        [8, 7]]), array([[21, 20],\n",
       "        [ 7,  1]]), array([[14, 10],\n",
       "        [20, 17]]), array([[12,  6],\n",
       "        [12,  8]]), array([[25, 21],\n",
       "        [21, 20]]), array([[16, 15],\n",
       "        [15,  9]]), array([[25, 20],\n",
       "        [ 7,  6]]), array([[8, 6],\n",
       "        [9, 4]]), array([[20, 15],\n",
       "        [ 7,  4]]), array([[14, 11],\n",
       "        [ 6,  3]]), array([[20, 17],\n",
       "        [20, 17]]), array([[20, 18],\n",
       "        [11,  7]]), array([[17, 13],\n",
       "        [15, 11]]), array([[ 6,  2],\n",
       "        [18, 14]]), array([[25, 21],\n",
       "        [17, 13]]), array([[25, 21],\n",
       "        [ 6,  2]]), array([[25, 19],\n",
       "        [ 6,  2]]), array([[3, 1],\n",
       "        [7, 5]]), array([[25, 22],\n",
       "        [ 2,  1]]), array([[25, 20],\n",
       "        [ 5,  3]]), array([[25, 22],\n",
       "        [22, 20]]), array([[25, 22],\n",
       "        [22, 20]]), array([[19, 14],\n",
       "        [13,  7]]), array([[20, 17],\n",
       "        [ 2,  1]]), array([[ 2,  1],\n",
       "        [21, 17]]), array([[20, 17],\n",
       "        [21, 19]]), array([[13,  9],\n",
       "        [14, 10]]), array([[19, 15],\n",
       "        [15, 11]]), array([[25, 22],\n",
       "        [ 7,  2]]), array([[14, 10],\n",
       "        [11,  6]]), array([[ 9,  4],\n",
       "        [17, 14]]), array([[17, 12],\n",
       "        [12,  8]]), array([[22, 17],\n",
       "        [14, 12]]), array([[25, 19],\n",
       "        [19, 13]]), array([[25, 19],\n",
       "        [20, 14]]), array([[25, 19],\n",
       "        [17, 12]]), array([[4, 3],\n",
       "        [3, 1]]), array([[19, 18],\n",
       "        [18, 16]]), array([[14,  9],\n",
       "        [ 9,  5]]), array([[25, 21],\n",
       "        [13,  9]]), array([[ 5,  1],\n",
       "        [17, 13]]), array([[25, 22],\n",
       "        [10,  4]]), array([[13, 12],\n",
       "        [19, 18]]), array([[21, 20],\n",
       "        [20, 19]]), array([[18, 13],\n",
       "        [ 2,  1]]), array([[4, 2],\n",
       "        [9, 4]]), array([[13,  8],\n",
       "        [12, 10]]), array([[ 4,  1],\n",
       "        [19, 14]]), array([[ 8,  3],\n",
       "        [10,  7]]), array([[25, 19],\n",
       "        [14, 11]]), array([[3, 1],\n",
       "        [7, 1]]), array([[19, 16],\n",
       "        [16, 14]]), array([[ 2, 27],\n",
       "        [ 2, 27]]), array([[11,  5],\n",
       "        [14,  9]]), array([[ 2, 27],\n",
       "        [ 2, 27]]), array([[ 9,  5],\n",
       "        [ 2, 27]]), array([[ 2, 27],\n",
       "        [ 2, 27]]), array([[ 5,  3],\n",
       "        [ 5, 27]]), array([[ 1, 27],\n",
       "        [ 1, 27]]), array([[ 3, 27],\n",
       "        [ 2, 27]]), array([[ 1, 27],\n",
       "        [ 1, 27]]), array([[ 2, 27],\n",
       "        [ 1, 27]]), array([[ 1, 27],\n",
       "        [ 1, 27]]), array([[ 1, 27],\n",
       "        [ 1, 27]]), array([[ 1, 27],\n",
       "        [ 1, 27]]), array([[ 1, 27],\n",
       "        [ 1, 27]]), array([[ 1, 27]])]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
