{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Backgammon as B\n",
    "import agent as A\n",
    "import flipped_agent as FA\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backgammon:\n",
    "    def __init__(self):\n",
    "        self.board = B.init_board()\n",
    "            \n",
    "    def reset(self):\n",
    "        self.board = B.init_board()\n",
    "        self.done = False\n",
    "    \n",
    "    def legal_moves(self, dice, player):\n",
    "        moves, boards = B.legal_moves(board = self.board, dice = dice, player = player)\n",
    "        if len(boards) == 0:\n",
    "            return [], []\n",
    "        boards = np.vstack(boards)\n",
    "        return moves, boards\n",
    "    \n",
    "    def swap_player(self):\n",
    "        self.board = FA.flip_board(board_copy=np.copy(self.board))\n",
    "    \n",
    "    # oppents random move\n",
    "    def make_move(self, dice):\n",
    "        moves, _ = self.legal_moves(dice, -1)\n",
    "        if len(moves) == 0:\n",
    "            return self.step([], -1)\n",
    "        move = moves[np.random.randint(len(moves))]\n",
    "        return self.step(move, -1)\n",
    "    \n",
    "    def step(self, move, player):\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                self.board = B.update_board(board = self.board, move = m, player = player)\n",
    "        reward = 0\n",
    "        self.done = False\n",
    "        if self.iswin():\n",
    "            reward = player\n",
    "            self.done = True\n",
    "        return np.copy(self.board), reward, self.done\n",
    "    \n",
    "    def symbolic_step(self, move):\n",
    "        board = np.copy(self.board)\n",
    "        if len(move) != 0:\n",
    "            for m in move:\n",
    "                board = B.update_board(board = board, move = m, player = 1)\n",
    "        reward = 0\n",
    "        done = False\n",
    "        if B.game_over(board):\n",
    "            reward = 1\n",
    "            done = True\n",
    "        return board, reward, self.done\n",
    "        \n",
    "    def iswin(self):\n",
    "        return B.game_over(self.board)\n",
    "        \n",
    "    def render(self):\n",
    "        B.pretty_print(self.board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolicyGrad Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradient:\n",
    "    def __init__(self, sess, gamma = 0.99, learning_rate = 1e-3, entropy = 0.1,\n",
    "                epsilon = 1, epsdecay = 0.999):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        self._epsilon = epsilon\n",
    "        self._epsdecay = epsdecay\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.network = keras.models.Sequential()\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(1))\n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.network(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_entropy = -tf.reduce_sum(self._actor_policy * self._actor_log_policy)\n",
    "        \n",
    "        # Losses\n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * self._cumulative_rewards)\n",
    "        self._actor_loss -= entropy * self._actor_entropy\n",
    "        \n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        self._update = self._optimizer.minimize(self._actor_loss)\n",
    "        \n",
    "        self._s = sess\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        if np.random.uniform() < self._epsilon:\n",
    "            action = np.random.choice(np.arange(len(probs)), p = probs)\n",
    "        else:\n",
    "            action = np.argmax(probs)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def update(self, states, rewards, afterstates, done):\n",
    "        self._s.run(self._update, \n",
    "                    ({self._states: states, \n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        self._epsilon *= self._epsdecay\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R\n",
    "    \n",
    "    def ExamplePolicy(self):\n",
    "        _, st = B.legal_moves(B.init_board(), B.roll_dice(), 1)\n",
    "        \n",
    "        out = np.round(self._s.run(self._actor_policy, ({self._states: st})) * 100)/100\n",
    "        out = out.flatten()\n",
    "        out.sort()\n",
    "        return out[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic (Shared network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic:\n",
    "    def __init__(self, sess, gamma = 0.99, learning_rate = 1e-3, entropy = 0.1,\n",
    "                epsilon = 1, epsdecay = 0.999):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        self._epsilon = epsilon\n",
    "        self._epsdecay = epsdecay\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._currstates = tf.placeholder(\"float32\", (None, 29), name = \"currstates\")\n",
    "        #self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.network = keras.models.Sequential()\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.BatchNormalization())\n",
    "        self.network.add(L.PReLU())\n",
    "        self.network.add(L.Dense(64))\n",
    "        self.network.add(L.BatchNormalization())\n",
    "        self.network.add(L.PReLU())\n",
    "        self.network.add(L.Dense(32))\n",
    "        self.network.add(L.BatchNormalization())\n",
    "        self.network.add(L.PReLU())\n",
    "        self.network.add(L.Dense(1))\n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = tf.nn.tanh(self.network(self._currstates))\n",
    "        self._afterstate_values = tf.nn.tanh(self.network(self._states)) * (1 - self._done)\n",
    "        \n",
    "        self._target_state_values = self._cumulative_rewards\n",
    "        self._target_state_values += self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done) - self._state_values\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.network(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_entropy = -tf.reduce_mean(self._actor_policy * self._actor_log_policy)\n",
    "        \n",
    "        # Losses\n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values))**2)\n",
    "        self._actor_loss = -tf.reduce_mean(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_loss -= entropy * self._actor_entropy\n",
    "        \n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        self._update = self._optimizer.minimize(self._actor_loss + self._critic_loss)\n",
    "        \n",
    "        self._s = sess\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        if np.random.uniform() < self._epsilon:\n",
    "            action = np.random.choice(np.arange(len(probs)), p = probs)\n",
    "        else:\n",
    "            action = np.argmax(probs)\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def update(self, states, currstates, rewards, done):\n",
    "        self._s.run(self._update, \n",
    "                    ({self._states: states, \n",
    "                      self._currstates: currstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        self._epsilon *= self._epsdecay\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R\n",
    "    \n",
    "    def ExamplePolicy(self):\n",
    "        _, st = B.legal_moves(B.init_board(), B.roll_dice(), 1)\n",
    "        \n",
    "        out = np.round(self._s.run(self._actor_policy, ({self._states: st})) * 100)/100\n",
    "        out = out.flatten()\n",
    "        out.sort()\n",
    "        return out[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-02a9ee519b92>, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-02a9ee519b92>\"\u001b[0;36m, line \u001b[0;32m70\u001b[0m\n\u001b[0;31m    if type != \"compete\"\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def PlayGame(player1, player2 = \"random\"):\n",
    "    \n",
    "    env = backgammon()\n",
    "    \n",
    "    players = [player1, player2]\n",
    "    \n",
    "    active = np.random.randint(2)\n",
    "    \n",
    "    currstates = [[], []]\n",
    "    states = [[], []]\n",
    "    rewards = [[], []]\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        dice = B.roll_dice()\n",
    "        for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "            possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "            n_actions = len(possible_moves)\n",
    "\n",
    "            if n_actions == 0:\n",
    "                break\n",
    "\n",
    "            currstates[active].append(env.board)\n",
    "            action = players[active].sample_action(possible_boards)\n",
    "            new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "            rewards[active].append(reward)\n",
    "            states[active].append(new_board)\n",
    "            afterstates[active].append(old_board)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            env.swap_player()\n",
    "            active = (active + 1) % 2\n",
    "\n",
    "        if not done:\n",
    "            dice = B.roll_dice()\n",
    "            \n",
    "            if player2 != \"random\":\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "\n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "\n",
    "                        action = player2.sample_action(possible_boards)\n",
    "\n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                env.swap_player()\n",
    "                \n",
    "            else:\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                    old_state, reward, done = env.make_move(dice)\n",
    "                    if done:\n",
    "                        rewards[-1] = -1\n",
    "                        break\n",
    "\n",
    "    afterstates.append(old_board)\n",
    "    afterstates = afterstates[2:]\n",
    "\n",
    "    Dones = np.zeros(len(states))\n",
    "    Dones[-1] = 1\n",
    "\n",
    "    States = np.vstack(states)\n",
    "    CumulativeRewards = player.get_cumulative_rewards(rewards)\n",
    "    AfterStates = np.vstack(afterstates)\n",
    "\n",
    "    if type != \"compete\"\n",
    "        player1.update(states = States, \n",
    "                      rewards = CumulativeRewards,\n",
    "                      afterstates = AfterStates, \n",
    "                      done = Dones)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "AC = ActorCritic(sess = s, entropy = 1, learning_rate = 0.00025, gamma = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG = PolicyGradient(sess = s, entropy = 0.0, learning_rate=1e-4, gamma = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 32)                960       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 32)                32        \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "p_re_lu_6 (PReLU)            (None, 32)                32        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,825\n",
      "Trainable params: 5,569\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AC.network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06, 0.06, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
       "       0.03, 0.02, 0.02, 0.02, 0.02], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AC.ExamplePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stakt episode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spila við sjálft sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage:  0.44\n",
      "Agent epsilon:  0.05494344105065345\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzsvXl83Hd95/98z0ijYySNpNFpybZ8xvFBQnCckEBCAg3Y4W5LodDmJNAChXa3BXZ/+6Pdbrvd3cIC3bbbcAYaSikLJUvsHCQEyhES57LkHLbjOLHu+9bMSJr3/vH9fqWxPDP6zj2SP8/HYx7SfOd7fGxJ3/f3fb3eoqoYDAaDwbAankIvwGAwGAxrA2MwDAaDweAKYzAMBoPB4ApjMAwGg8HgCmMwDAaDweAKYzAMBoPB4ApjMAwGg8HgCmMwDAaDweAKYzAMBoPB4IqSQi8gmzQ0NGhHR0ehl2EwGAxrhieeeGJYVRvd7JtTgyEitcCXgb2AArcC7wbeBkSAF4FbVHU8zrFngClgEVhQ1f2rXa+jo4OjR49mbf0Gg8Gw3hGRl93um+uQ1BeA+1R1F3AJ8BzwILBXVV8FnAA+neT461T1UjfGwmAwGAy5JWcGQ0RqgGuArwCoakRVx1X1AVVdsHd7FGjP1RoMBoPBkD1y6WFsBYaAr4nIUyLyZRHxr9jnVuBIguMVeEBEnhCRO3K4ToPBYDC4IJcGowS4DPh7VX01MAN8yvlQRP4jsADcneD4q1X1MuAg8BERuSbeTiJyh4gcFZGjQ0NDWf0HGAwGg2GZXBqMbqBbVX9lv/8ulgFBRG4C3gq8XxMM5FDVXvvrIPB94ECC/e5U1f2qur+x0VWi32AwGAxpkDODoar9wFkRucje9EbgWRF5C/BJ4O2qOhvvWBHxi0i18z1wA9CVq7UaDAaDYXVy3YfxMeBuEfEBp4FbgMeBMuBBEQF4VFU/LCIbgC+r6iGgGfi+/XkJ8C1VvS/HazUYDAZDEnJqMFT1aWBlSez2BPv2Aofs709jleEaLhBUle8/1cMNe1qoKltX/aQGw7rBSIMYioIzI7P80Xee4YfP9BZ6KQaDIQHGYBiKgqGpMADD0+ECr8RgMCTCGAxDUTA6YxmKkZlIgVdiMBgSYQyGoShwDMWoMRgGQ9FiDIahKBidNgbDYCh2jMEwFAWOhzEybQyGwVCsGINhKApGTUjKYCh6jMEwFAWxBiOBWozBYCgwxmAYigKnnDayGGUqvLDK3gaDoRCkZDBExGPPuTAYssroTARfifXrOGryGAZDUbKqwRCRb4lIjS0C+Czwgoj8ce6XZrhQUFXGZiNsa6wCTC+GwVCsuPEwdqvqJPBO4DCwCfidnK7KcEExGVpgflHZ0WQZDJP4NhiKEzcGo1RESrEMxg9UdR5rGp7BkBUcA7FsMIw8iMFQjLgxGP8AnAH8wE9FZDMwmctFGS4sHAOxo9mEpAyGYmZVHWlV/SLwxZhNL4vIdblbkuFCw2nW21BbQUWp1yS9DYYixU3Su1lEviIiR+z3u4Gbcr4ywwWDE5IKVpURrPKZHIbBUKS4CUl9Hbgf2GC/PwF8IlcLMlx4OCGooN9H0O8zISmDoUhxYzAaVPU7QBRAVReAxZyuynBBMTIdodLnpbzUS73fx4hJehsMRYkbgzEjIkHsyigRuRKYyOmqDBcUozNh6v0+AOr9ZSaHYTAUKW4Mxh8B9wDbROTnwDeAj7k5uYjUish3ReR5EXlORF4rIvUi8qCInLS/1iU49iZ7n5MiYnIm65iRmQhB22AEq6yQlNGTMhiKj1UNhqo+CVwLXAV8CNijqsdcnv8LwH2qugu4BHgO+BTwkKruAB6y35+DiNQDnwGuAA4An0lkWAxrn9GZSIyH4SO8EGU2YqKeBkOxkbCsVkTeneCjnSKCqn4v2YltzalrgJsBVDUCRETkHcAb7N3uAh4BPrni8DcDD6rqqH2uB4G3AP+U7JqGtcnoTIRdLZZEmWM4Rmci+MtWrfo2GAx5JNlf5Nvsr01Y3sXD9vvrsG7ySQ0GsBUYAr4mIpcATwAfB5pVtQ9AVftEpCnOsW3A2Zj33fa28xCRO4A7ADZt2rTKkgzFhqpaIakqOyRlG4yRmQgb6ysLuTSDwbCChCEpVb1FVW/BSnbvVtVfV9VfB/a4PHcJcBnw96r6amCGOOGnBEi8JSVY552qul9V9zc2Nro8vaFYmIksElmILhmKZQ/DVEoZDMWGm6R3h+MR2AwAO10c1w10q+qv7PffxTIgAyLSCmB/HUxw7MaY9+1Ar4trGtYYTkWUYygaqsoAM6rVYChG3BiMR0TkfhG52a5Wuhf48WoHqWo/cFZELrI3vRFLHv0eljvFbwJ+EOfw+4EbRKTOTnbfYG8zrDOcngsnJFUfE5IyGAzFhRstqY+KyLuwEtgAd6rq912e/2PA3SLiA04Dt2AZqe+IyG3AK8BvAojIfuDDqnq7qo6KyJ8Dj9vn+c9OAtywvhhZ8jAsz6LS56WsxGPkQQyGIsRtGcovgAWsPMJjbk+uqk8D++N89MY4+x4Fbo95/1Xgq26vZVibjMbIggCIiCUPYkJSBkPR4UZ88D1YRuI3gPcAvxKR38j1wgwXBk7oyQlFAdRX+UzS22AoQtx4GP8RuFxVBwFEpBH4EVYS22DIiNGZMGUlHip93qVt9f4yE5IyGIoQN0lvj2MsbEZcHmcwrIojCyKyXEltFGsNhuLEjYdxn4jcz3KX9W9hzfY2GDJmdCZC0C6ldaj3m5kYBkMx4kZL6o+xxrS+CksP6k5VXSnlsWZRVf7r4ed44Hh/wdYwMTvPV372EtHohSe4F6sj5VDv9zEbWSQ0b/SkDIZiwk3S2w/8QFX/CPjfwKKIlOZ8ZXlCRPjWY6/w81PDBVvD139xhj//4bN09V54qvEj08tKtQ4NVaYXw2AoRtzkIn4KlIlIG1ay+xasKXzrhkLHzI90WY30Z0ZmC7aGQhHfw3C6vU2llMFQTLgxGKKqs8C7gb9R1XcBu3O7rPxSyJj5i0PTPN8/BcDLwzMFWUOhmI0sMDe/SH3V+SEpMB6GwVBsuDIYIvJa4P1YsiDgvuFvTVDIMs4jnZZ3UV1WcsF5GE5z3sqQlPPeTN4zGIoLNzf+TwCfBr6vqsdFZCsutKTWEg1VPp7pHi/Ite/t7Oc1m+so9Qovj1xYHsbozLmyIA6Ox2EqpQyG4sJNldRPVPXtqvrf7PenVfUPcr+0/FHv9zFWgLGgLw3P8FzfJIf2tdIR9HPmgjUY53oY1WUllHrFhKQMhiIj2cS9z6vqJ0Tk/xJnFoWqvj2nK8sj9X4fC1Flcm6BQGX+CsAO2+Got+xtIbIQZXg6wlRonurydVOElhTHIDSsyGGIiJ1XMklvg6GYSBaS+qb99a/zsZBCElwq4wzn1WAc6erj0o21tNVW0BG0psu9PDLL3rZA3tZQSByDsNLDsLYZeRCDodhINnHvCfvrT4BfAmPAKPBLe9u6YamMM483qFdGZunqmeTGfa0AbA76ActgXCiMzETweT1UxZndXehSZ4PBcD5uGvduBF4Evgj8L+CUiBzM9cLyydIc6TxW5RzuWg5HAXQ0WB7GhZTHGJ22ejBidaQcglVG4txgKDbcVEl9FrhOVU8BiMg2rPLaI7lcWD5ZniOdR4PR2ccl7QE21luGotJXQlN1GWcuoF6MeE17DkZPymAoPtz0YQw6xsLmNPHncK9Zlg1GfpKsZ0dnOdY9wUE7HOXQEfRfUCGp4ZnIUv5oJUG/j+nwAuEFoydlMBQLbgzGcRE5HDPT+/8Cj4vIu0Xk3TleX14oL/Xi93nzFjN3pEAO7T3XYGwOVl5YIamZcBIPo8zex3gZBkOx4CYkVQ4MANfa74eAeuBtWOW230t0oIicAaaARWBBVfeLyD8DF9m71ALjqnqpm2NdrDVtglX5q8o53NnP3rYaNtmVUQ4dDX7+5YluZiMLVPrWVTN9XJwcRjzqY/JKrYGKfC7LYDAkYNW7kqrekuE1rlPVJSlYVf0t53sR+SyQTKL1nGNzSb5i5j3jczx9dpw/ectF533WEVMpdXFrTc7XUkhC84vMRBbPkwVxCJpub4Oh6HBTJbVTRB4SkS77/atE5P/L9MJilca8h+XBTAUl6M9PVY6jHbUyHAVWSAq4IBLfjiFYOTzJoRCFCAaDITluchhfwtKSmgdQ1WPAe12eX4EHROQJEbljxWevBwZU9WQax2adfHkYhzv72N1aQ0eD/7zPlgzGBZD4TiQL4hA0irUGQ9HhJlBeqaqPraiVX3B5/qtVtVdEmoAHReR5Vf2p/dn7SO5dJDt2CduY3AGwadMml8s6n/oqHyMzYVQ1bl9ANuibmOPJV8b59zfsjPt5dXkpDVW+C0KE0DEEiUJSNeWllHjEyIMYDEWEGw9j2O69UAAR+Q2gz83JVbXX/joIfB84YJ+jBGu+xj+nemyc/e5U1f2qur+xsdHNsuIS9PuYX1Smwm5tYerc12WNgT207/xwlMPmC0SEMJksCIDHI9TlKUxoMBjc4cZgfARrpvcuEenBkjv/8GoHiYhfRKqd74EbgC774zcBz6tqdxrH5oSlMs4c3qAOd/axq6WarY1VCfe5UHoxlmdhxM9hWJ8ZeRCDoZhwI29+WlXfBDQCu1T1dar6sotzNwM/E5FngMeAe1X1Pvuz97IiHCUiG0TksItjc0KuY+YDkyGOvjyW1LsA6AhW0jcRYi6yvhvWRmYilHiEmorEUVHT7W0wFBeui/1VNaU4iaqeBi5J8NnNcbb1AodWOzZX5Loq576uflTh0L6WpPtttpPhr4zOclFLdU7Wkin3Huujra6CSzfWpn2O0ekIdQl0pBzq/T6O906mfQ2DwZBd3ISkLgiW6/5zk2Q93NnHzuYqtjclNwIdweIXIfzMPcf52x+fWn3HJIzMRBImvB2sUmeT9DYYigVjMGyCOZQ4H5wK8diZUQ7G6b1YybLMeXEajIXFKCMz4YzXNzoTTqgj5VDvL2MytMD8YjSjaxkMhuyQNCQlIruAdwBtWFVSvcA9qvpcHtaWVyp8XipKvTlJet9/fMAOR61uMAIVpdT7fUXbizE8HUHV6kaPRhWPJ70S5NGZCPvqkoe0nNneYzMRmmrK07qOwWDIHgk9DBH5JPBtQLASz4/b3/+TiHwqP8vLL7lKsh4+1se2Rj87mxNXR8WyOVhZtN3eA5MhAMILUfrt79PBbUjK2ddgMBSeZB7GbcAeVZ2P3SginwOOA3+Vy4UVgmCVj+Es35yGp8P86qURPnLddtcNgR1BP4+9NJrVdWSLwanlnMKZkRk21KYuDBhZiDIVWkjYg+FQiMFWBoMhMclyGFFgQ5ztrfZn6w7Lw8hukvX+4/1EXYajHDYHK+mdmCM0X3yltYNTy15Fuv0iY7PJZUEcYmetGwyGwpPMw/gE8JCInATO2ts2AduBj+Z6YYWg3u/jRP9UVs95pLOfLQ1+dqVQIrulwY8qdI/NrlpVlW8GJsOIQKnHk3Yl13LT3upJbzAChAZDsZDQYKjqfSKyE0uSow0rf9ENPK6qxffomwWczuJs6UmNzkT45ekRPnzt1pTO51RKnRkuPoMxNBUi6PdRW+nj5eH0PIyRVWRBHGorSvGIMRgGQ7GwWlmtxrwW7a/rMhwF1hNteCHKbJa6rB843s9iVF2V08ZSzL0Yg5NhGqvL6chgOuCytHlyg+HxCHWVRh7EYCgWEnoYInID8HfASaDH3twObBeR31fVB/KwvrwSO7THX5b5xLt7O/vYHKxkz4bUhiHVVvoIVJQWpcEYmArRXFPG5qCfn50aTssbc6Mj5VDv9+VU38tgMLgn2V3xC8CbVPVM7EYR2QIcBi7O4boKQmwZ58b6ylX2Ts74bIRfvDjCB1+fWjjKoSNYWZQihIOTYWueR7CS0HyUwakwzSn2SIzORPB6hEBF6ar7rgc9qfu6+qnwebl2Z/pqygZDMZAsJFWClbNYSQ+w+l/6GmRZTyrzqpzjvZMsRpVrdjSkdXxHQ/HJnC9GleHpME3V5UsDoNLpFxmZiVBXWeqq6S9ozylZq8wvRvnU947x1/e/UOilGAwZk8zD+CrwuIh8m+UqqY1YSrNfyfXCCsGSPEgWQiB9E1b5aVtd6n0KYCW+/+8zvUQWovhKikPBZWQ6TFShuabsnPnjV2wNpnSe0Znwqglvh7XuYTx6eoTx2XkiC9MZdcYbDMVAwjuRqv5X4LexqqNeC1xlf/9++7N1R31V9jqL+8bnAFIO1zh0BCuJKpwdK56wlNO011hdTmugnFKv8FIaXtDoTMS1wQj6yxibnWdhjepJHe60hmbNRhbpsX8nDIa1StLMrq0Zte50oxLh93nxlXiy8kTbN2mVn5aXetM6PlaEcFuSgUv5xGnaa6opo8TrYWNdZVoihCMzES5ucVcI4BQijM3O01i9epK8mFhYjHL/8X421ldwdnSOU4PTGefGDIZCklasQ0SOZHshxYCI2JLamRuM/okQLYH0BfOWSmvT7HXIBQOTlofheE2W5lXq60vFw8j1nJJc8thLo4zORPjIG7YDcHIwu02hBkO+SVZWe1mij4BLc7OcwpMteZC+iRBttekbjHq/j+rykqKSOR+0DUZjlfWk39FgaV6lUlo7vxhlfHY+ZYNhJb6Lq4lxNe7t7KOi1Ms7Lm3jsw+e4OTAdKGXZDBkRLKQ1OPAT7AMxErSH7VW5GQrydo/McdrNqf/3yQidAT9RSVzPjgVoq6ydCkJ3xH0MxNZZMiunHKDoyPVsErTnkNwjcqDLEaV+4/3c/2uJip8XnY0VXFi0BgMw9omWUjqOeBDqnrdyhcw7ObkInJGRDpF5GkROWpv+1MR6bG3PS0ihxIc+xYReUFETuVTTr2hqizjpHdofpGx2XlaA+lVSDlszqCbOhcMTJ7bc7HZDpul0i/i3PjrXTTtWfutzZDUYy+NMjwdWRKd3NFUxamBKVS1wCszGNInmcH40ySffyyFa1ynqpeq6v6Ybf/T3napqh5eeYCIeIG/BQ4Cu4H3icjuFK6ZNtnwMJyS2pYMh/50BP10j80VzcS5oanQOYnnjmDqvRhO17bbkFRdpdXys9Ykzo909VFe6uG6XVaz3vbmamYii0u/GwbDWiRZWe13VTVut5Gq/mvulgRYgoenVPW0qkawBjm9I8fXBKwb2WxkMSNp8b4Jq3yyNYMcBlhP8ItRpWesOMoxB6fODT211VXg9UhKHsaISx0phxKvh9rK0jXlYSxGlSNd/Vx3UROVPivqu7PJqnQ7acJShjVMrjvCFHhARJ4QkTtitn9URI6JyFdFpC7OcW0sNwuC1XHelsuFOmRjylu//RSZaUhqi9NNXQRhqWhUGZoK01yz7GGUej1srKtIaX3LISl3BsPZdy0ZjCdeHmNoKszBmBkoO5qthP3JAVMpZVi75NpgXK2ql2GFlj4iItcAfw9sw6q06gM+G+e4eIn2uMFfEblDRI6KyNGhoaGMF7xUlTOdfqVUtkJSm2O6qQvN6GyEhajStKIXYnMwNQmTkZkIIlBX6d5gNPjLGM7g55FvDnf2UVbi4fpdTUvb6v0+gn6fqZQyrGlWNRgicl52Mt62eKhqr/11EPg+cEBVB1R1UVWjwJewwk8r6caSIXFoB3oTXONOVd2vqvsbGzMXdwtmodu7fyJEbWUpFb70mvYcGqp8+H1eXiqC+d5OSW3TCiPYEazk5eFZ18nc0ZkwtRWleFOQyFhLHkY0qhzp6uPanY1UrVA83t5UZXoxDGsaNx7GL11uOwcR8YtItfM9cAPQJSKxwyHeBXTFOfxxYIeIbBERH5Z+1T0u1poxS1PeMkiy9k2EMvYuwCqt3Rz0F0UvxoDd5R0bkgLLw5gKL7i+oafStOdQX7V2DMZTZ8cYmAxz46vOn4Gys7mak4PTplLKsGZJ1rjXgpU3qBCRV7McJqoB3OgbNAPftxu6SoBv2VP8vikil2KFmM4AH7KvtwH4sqoeUtUFEfkocD/gBb6qqsfT+QemSjbKOPsn52jNoMs7lo6GSp7vK/xT6ZDjYazot+hocIY9zRKsWt3xHJ6OuJqDEUvQ72NsNrImxPvuPdaPb0U4ymFHcxVToQUGJsMZqQAYDIUiWePem4GbscJBn2XZYEwB/2G1E6vqaeCSONt/J8H+vcChmPeHseZu5JWa8hJKvZJRSKpvPMS+tuz0NnYE/Tz47AALi1FKvIVTrXV0pFbqOXXEaF69ZnO8+oVzGZ2JsKMpNW2ser+PqML4nPsO8ULghKOu2dFIdfn5EwC2L1VKTRmDYViTJCurvctu0rtZVa+Padx7u6p+L49rzCsikpE8SGh+kZGZCBuy5WEE/cwvasHr9wcmwwQqSs8TU2yvq8Qj7nsx0gpJZXFOSS55unucvokQh/a1xP18R5NTKWUS34a1iZtH1nYRqRGLL4vIk/b41nVLvb8s7ZCUkxzO1hOk001d6MT34FTovAopAF+Jh7a6ClcSJotRZWw2slS67JZszinJJUc6+yj1Cm+8uDnu5w1VPuoqS00vhmHN4sZg3Kqqk1hJ6ybgFuCvcrqqAhP0+9IOSS017WXYg+HgTLYrdOJ7cCpMU0383EOHy8T8+GwE1dR6MGBtyIOoKoc7+3n9jsaEo2dFhB1N1ZwylVKGNYobg+HkLg4BX1PVZ4jfJ7FuyKSMs3/S7sHIkofRVF1GRam34CKEg5NhmhMIDFqaV6uvb6lpz0VyPBan1Hm4iA3Gse4JesbnOLg3fjjKYXtzFScGTKWUYW3ixmA8ISIPYBmM++1S2eIQN8oR9RnMxFhq2suSwbBKa9MbVJQtVK0u78YkHsbE3Dzjs8n/z5ZkQVL0MJwmv0xKnXPN4a4+SjzCDbuTG4wdTVVMzM0ztIYaEQ0GBzcG4zbgU8DlqjoL+LDCUuuWoN/HdHiB8ELqelJ943NUl5ec17SVCYWWOR+fnSeyGE3oYTiVUqvlWdKRBQErT1JTXlK0SW8rHNXH1dsbCFTGD0c57LQlQk6ZxLdhDbKqwbA7sl8CdtrSHntYx/MwYHm2dzphqb6JEBuylL9w2NxQySsjsyxGCxPGGIgZzRoPpxdjNQmTdD0MgGAWZOdzxfHeSc6OznHjvvOb9Vayw4gQGtYwbqRBbgd+itVE92f21z/N7bIKy5IAYRohkP7JzEazxqMj6CeyGF1KqOebwQRNew7tdZWIrC6S6Ohz1aVhMIpZHuTezj68HuHXdsevjoqlsbqMmvISThgRQsMaxE1I6uPA5cDLdl/Gq4HMVf6KGKdjOV0PI1td3g4dBRYhHJxyZnnH9zDKS71sCFSsur7RmQiBilJK02hALFaDoaoc6ezjqm1BV4ZQRNhhS4QYDGsNN3+5IVUNgSU6qKrPAxfldlmFJd0yzshClOHp7Ms+LMtvFCbxPWBXfiUbw9rRsPp0wJGZ1HswHDIpdc4lz/ZNcmZkdmmynht2NldxyhgMwxrEjcHoFpFa4F+BB0XkByRQjl0vpDsTY3AqhCpZ9zCaq8spK/EUzMMYmgpTXVaSVH13c9C/arf36HTqXd4O9X4fYzORoitHPdLZj9cjvHlP8uqoWLY3VTM6E8lIQt9gKASrlvKo6rvsb/9URH4MBID7crqqAlNTbslvp1qVs1xSm92kt8djldYWqtt7cCqUMOHt0BGsZGx2nonZ+YSVQqMzkaXO9VSp9/tYiCqTcwurViLlC6c66sqt9SkZQifxfWJgmtem2JNiMBSShB6GiNSvfAGdwM+A1NTj1hgej1BXmXrMvG9p0l72heUKKXM+MBlOGo6CmGFPo4nXODITcT2adSXLzXvF81T+wsAUp4dnOLjXfTgKLNVawHR8G9YcyTyMJ7AkyGO7up33CmzN4boKTtDvYzjFKqn+JVmQ7BuMLQ1+fnpiqCAS34NTIS7blFyJ1knMnxmZ5VXt51ddR20dqXRDUo6e1OhMhG2Zz8nKCoc7+/EIKYWjwJrEWF1WYhLfhjVHQoOhqlvyuZBiI52qnL6JEFVlJXGlrTNlc7CS8EKUgalQ1nSq3KCqlizIKgOhnFBTojzGZGiexaguDahKlfoMSp1zxeHOPg5sqT9P8n01RITtzVVGtdaw5ijcgIUiJ50pb/0T2e/BcFh6gh/Ob+J7cm6B8EI0rlJtLOWlXloD5QkrpZwCgoYMQ1LFUlp7cmCKU4PTrpr14rHDjGs1rEGMwUhA0O9LuYolFz0YDktP8HnOYyQanBQPS/MqvkFzPINMqqSgeGZi3NvZhwi8eRWxwUTsaKpmeDpSNAZwrfLdJ7p56LmBrJ4zGlU++8ALBVeILkaSJb0v6JBU0F/GZGiB+UX3Oov9WZrlHY/WQAU+r6cABsNp2lv935VM5ty50adrMMpKvFSVlRRNL8aRzn4u31y/ajFAIrYvJb5NWCpdVJW/PPwcX3z4VFbPe2Jwir95+BQ/PNaX1fOuB5J5GN8FEJGH8rSWosLRkxpzeYNaWIwyOJU7D8PrETYFK3k5zyGp5aY9Nx6Gn+HpCFOh+fM+W9aRSr+MtFi6vU8NTvPCwFTCyXpucEQITVgqffomQozORHiubzKlB7vV6OqZtM9fGCmeYiZZlZRHRD6DJTr4Rys/VNXPrXZyETmDNQN8EVhQ1f0i8j+AtwER4EXgFlUdd3Ps6v+c7BHbvNfk4ul6cCpMVLPfgxFLR3D1bups43gYbv4PtsSIEO5tC5zzmSNNXudPvyCgWAzGkU7ryfNgmvkLgA2Bcvw+r0l8Z0BnzwRgKSycGpzm4taarJy3yz5vf4HHIhcjyTyM9wIhLKNSHefllutU9dKYG/6DwF5VfRVwAvh0CsfmjVTlQZZ6MGpz42GA04sxm9du58HJMH6f15Vc++al0trzjdrITITqshLKShJ3i69GOqXOueDezj72b65zFaZLhIiw3SS+M8K5scOy8cgGzrn6jME4j2RltS8A/01EjqnqkWxdUFUfiHn7KPAb2Tp3NklVHqQ/h017Dh3BSubmFxmcWr3MNVsMTIVceRewnJiPl/genYkshfnSJVjlo6s3ezeGdDg9NM3z/VP8/2/dnfG5tjdV828n17XdBd/nAAAgAElEQVSOZ07p6plge1MVfeNzHO+ZgP0bMz7nYlR5ttcKSRkP43zcVEn9QkQ+JyJH7ddnRSSw+mGA1eD3gIg8ISJ3xPn8ViCRMVrt2JyyXPfvripnaZZ3Te5CUktP8HmUCBmaDLvuM6j0ldBUXRZ3faMz6TftOdT7yxgtsJ7Uka5+AA5mkL9w2NlcxeBUmInZ83M+huSoKp09k7yqPcCeDYGseRinh6aZm19kS4OfkZkIofnUh6itZ9wYjK9i5RLeY78mga+5PP/VqnoZcBD4iD2ACQAR+Y/AAnB3qsfGIiJ3OMZsaCh7T2u1lT5E3Iek+idCVJR6qanI3qS9lWxpyL/M+eBUKCVvpsMOm63EUqrNTDcp6Pcxv6hMhRcyOk8mHO7s47JNtVlpnlySCBkyYalUGZgMMzwdZl9bgL1tAZ7tm2QhC4lvx/A4s02cog+DhRuDsU1VP6Oqp+3Xn+FSFkRVe+2vg8D3gQMAInIT8Fbg/ZrgcTHRsXH2u1NV96vq/sbG7GlGeG09KbchKacHQyR3sh2tgXJKvZK3xLeq2jpS7m/0HQ2VvBRnfaMz4bSlzR2W8koFymO8PDLD8d7JlKTMk7GjyUoFnjCJ75Rx8heWwaghNB/ldBY8766eScpLPVy9vQEweYyVuDEYcyLyOueNiFwNrFpvJiJ+Eal2vgduALpE5C3AJ4G32zPCXR/rYq1Zpd7vc31z6puYy1mXt0OJ18PGusTNcdlmOrzA3PxiSgZjc9DP0FSYmRgvQFWzksNwji9UL8bhTicclR2D0VZbQUWpqZRKh86eCUTg4tYa9tkVeZ3dmYelunom2N1aQ3ud5UGaPMa5uDEYHwb+VkTO2KWu/wv4kIvjmoGficgzwGPAvap6n318NdZsjadF5H8DiMgGETm8yrF5JZhCGWcuZUFiyafMeSpNew7xpgNaDZCasYcRTHOwVbY40tXHJRtraavNTp7K4zGVUunS1TPBtsYq/GUlbG2sotLnzTiPEY0qx3sn2NcWWGrANR7GubiZh/EMcImI1NjvJ92cWFVPA5fE2b49wf69wKFkx+abYJWPF/pX/2NejCoDU2E25EEUsKPBz2MvjaKqOQ1/QWpNew7LlVIz7N5g1cU7N/jMk96Fkwc5OzrLse4J/sOhXVk9746mKn55eiSr57wQ6Oqd4KptVtjI6xF2t9ZwPMMKupdGZpiJLLKnLYC/rISa8pIlBeps0Dcxx1/c+xzhBXe5lo11lfynt16c87/zVHCdoXVrKNYTbhvFhqfDLEY1Lx7G9qYqZiKL9IzP0V6X3jAitwwtNe2lksNYljl3yFQWxMFJmhciJHWky27WS3H2xWpsb67ie0/1MBmapyYHKsfrkcGpEAOTYfZsWG7U29sW4DtHz7IYVbxpyv/H5kXAkuPJpofxyAtD/PBYHzubq/B6kgd3JmYjPPjsAB9+w9a05WdyQe5KetYB9f4yxufmV/0lzOXgpJXs3WD9Mnf1TOTcYAxOuu/ydqgqK6Gh6tzSWkd4MNMqqQqfl4pSb0Ekzu/t7GdfW4CN9dn9P3cS36cGp1edOWKwWHljB8tgfP0XZ3hpeJrtTan0FS/T2T1BWYlnaSJiS6A8qwaje2yWEo9w+A9eT4k3ucF4+PkBbv36UbrH5orKYBi12iQE/T5UYWw2+Q2qb9xyW/PhYVzUUk2JR7La2ZqIgckQ5aUeql10eceyUsJkKSSVYdIbrDBhvnMY3WOzPHN2PGvVUbE4N6dTJvHtGkfraU+MwXCMh/NZOnT2TLCrtWbpZt6adYMxR2tt+arGAlh6GOweKy49q1VXLiKVIvKfRORL9vsdIvLW3C+t8Lgd2rPsYeQ+h1Fe6mVHc3VGfxhuGZyyRrOmGkPdvKIXY1l4MAsGw+++1Dlb3Gc362UiNpiIjfWVlJV4TOI7BTp7Jtja4D9HrmZbo5/yUk/aD1JRu8N7X9tymKs1UMHwdJiIy5zDanSPzbkumHD261lrBgOrSS8MvNZ+3w38l5ytqIhYlgdJnmTtnwxRVuKhrjI/Meh9bTV09UzkvOPZatpLPYzUEaykfzLEXMTqkh2dieD3eSkvTV9HysHKK+U36X24s489G2qWOu2zidcjbGusMr0YKdDVM3GeuGWJ18PFrTVpG4yXR2eZCi+cE+ZyQszZat7rGXOfd/SXlVBXWUr3WH7VqVfDbePefwfmAVR1jnPnfK9b6l1OectH014se9sCjMxEcl7yNzgZTit+utlOfL8yav2yZ6MHw6HeX5bXxr3e8TmefCU34SiHHc1VZi6GS4anw/RNhM65sTvsawvwbO8k0WjqD1KOodmzYfm8Toi5PwsGI7ywyMBUaKm/ww3tdZVrLyQFRESkAkvbCRHZhuVxrHvcKtb256FpLxbn6SrXeYzBKfc6UrFssZ/EnX6R4elw2rO8VxKsskJS+dKTcsJRB9OcrOeGHU1V9IzPMV1AyZO1gpPw3tN2vpT53g0BpsMLaSkhHO+ZwOf1LM0pgWUPIxsPZn3jIVRJqYenrbZiTXoYnwHuAzaKyN3AQ8Cf5HRVRUJ9pfscRj7yFw67W2vwesRS6MwRM+EFpsMLaaniborpxQDL4GYjfwGWEQ8vRJmN5EcU7nBnH7taqtnaWJWza+ywb1IvGi9jVRyDsTIkFbstnQcpK+Fdja9k+ZboPAQ6RS2Z0GOfI5XKxva6CnrG5woqtrmSVQ2Gqj4IvBu4GfgnYL+qPpLbZRUHJV4PtZWlST2MaFQZmMxPl7dDeamX7Y1VOfUwlgYnpeFhBCpKqff7lnoxsqFU65DqnJJM6J8IcfTlMW7MYTgKliulThqDsSqdPRN0BCvj9qzsaK7CV+LheG9qBSGqSlfPxDnhKIDq8lKqykqy4mE4nkJqIakKQvPRohlLDO6qpC4DNgN9QC+wSUS2icgF0cOxWvPe8EyY+UXNSw9GLHvbAnT2TObs6WPQ6fJOI+kNVsf3yyMzqKqtVJsdg+GcZ9il7Hwm3NeV+WQ9N2yqr8Tn9XBywFRKrUZXz2Rc7wKg1Ovh4pbqlDWlzo7OMRlaiJsXaQmUZ0VPqntsDq9HUrpPtBVhaa2bkNTfYQ06uhP4EvBL4NvACRG5IYdrKwqsMs7ENyfnl6klTwONHPa11TA8HV7yBLJNOjpSsTgy5zORRSIL0TXpYRzu6uei5mq2N+UuHAWWJ7u10b+uPYxHT4/w+R+dyOgcYzMResbnEhoMsB6kunpTqyDsjNMI6NAaKKcvC0nvnrE5Wmrc9WA4ON5IMZXWuln9GeDVtoT4a4BXYynHvgn47zlcW1GwmoeRzx6MWPZmUaEzHunoSMXSEfTTOzG3FP/NlsFoqMqPPMjgVIjHz4xmZVCSG3Y0V6/rXozP/+gEn//RyaW8Vjoku7E77GsLMBVaWKrQc3veUq+ws+X8B4PWQHlW9KS6x+ZoSyEcBSztX0yJbzcGY5eqHnfeqOqzWAbkdO6WVTzU+8uSJr378zDLOx67N9TgkdxVSg1NhfGVeAhUpNdb0tFQiSo8dXYcWL7RZ0q+PIz7u/pRJef5C4cdTVV0j80xG1l/lVJDU2Eee2kUWJaITwdnPO/eDck9DEjt7+J47wQ7m6vjzptvCVQwOBVmPsPhTN1jsynlLwBqykupKS9ZcyGpF0Tk70XkWvv1d1jhqDLs3oz1TNDvY2w2krC2u28ihM/rWaqoyheVvhK2NVZlrNCZCKvLuyzt3hKnye2pV8aA7HkYlT4vZSWenBuMw539bG+qWqpgyjU7mqpQhRcH8zd+N1/cf7yfqFreqiPimA5dPRNsrK8gkKRBdmdzNT6v+45va9TrREKvpTVQjuqyEGc6zC9G6Z8M0Z6GLH57XeVShVUx4MZg3AycAj4B/CFw2t42D1yXq4UVC/V+H1GF8bn4trF/Yo7mQBmeNBUyM8FKfOcuJJVuOAqsbm+AJ1+2PIxsGQwRsfJKOWzeG54O86uXRnLarLcSZ1zregxLHe7sY2ujn9tet4Vj3ROcTSFcFEuyG7uDr8TDRS3VHHcpndM9Nsf47Pw5ulSxLJXWZhCW6p8IEdXUSmod2uuKqxfDTVntnKp+VlXfparvVNW/VtVZVY2q6vrN0tkEq5LPYOidCNFak9/8hcPetgADk2EGp7Lf8e3oSKVLbaWPQEUpJ+wbYDBLnd5gdeDnUh7EeSLOhXZUIjYH/ZR6Zd0lvkemwzx6eoRDe1uXDHA6XsbE7DxnR5MnvB32tlkSIW4S346HnszDgMya986mUVLr0FZXQfdY8fRiuCmr3SEi3xWRZ0XktPPKx+KKgaUZDAmeaPM1aS8ezi+526epVBicTE9HKpaOBj+qUF7qodKXvSrsen9ZTkNSzhPxRXkKR4FVErqlwb/uxrXef3zANr6tbKyvZF9bgHvTyGO4yV847G0LMDE37yr239kzgdcj7GqJ/7N2ilkyKa11qpxSTXqD5ZXMRhYZny2O6L9b8cG/BxawQlDfAL6Zy0UVE8mSrKpKv60jVQh2b6hBcpD4Ds0vMhlaSGkORjycsFSmczBWkkvFWuuJeJRDe1vzPulsR9P6q5Q60tVHR7CSi1utG/LBfS08c3Y85TCLmwoph2Wp89X/Ljp7JtnRVJVQGLOmvIRKnzcjD6N7bA6R9Cop25cqpYojj+HGYFSo6kOAqOrLqvqnwPVuTm7PAe+0Z3cftbfVi8iDInLS/hp3aoyI3GTvc1JEbnL7D8o2Tigl3g1qdCZCZDFaMA+jqqyELQ3+rBsMZ3BSOjpSsTiJ72zlLxzqc5jDeODZARajmrdy2li2N1Xxyugsofn8yJ7kmrGZCL940coFOcb3kD2x0NHocktXzwRttRXUufhd2tnsbmaM0+GdzAiJSMbNe912D0as7IhbHO2pYsljuPkXhETEA5wUkY+KyLuAphSucZ2qXqqq++33nwIeUtUdWLpUn1p5gIjUY2lYXQEcAD6TyLDkmrrKxB5GoXowYtnXFnD1JJUKTk4k3aY9B8fDyIXBmJtfXJJPzyaHO60n4t2t54vb5ZqdzdVWpdTQ+ghLPfBsP4tRPad4oKPBz+7WGg53ppbHsCTN3f1Myku97GyuXtVg9E2EGJ2JsK89uddiDVJK/wm/Z3w2JdHBWDbaifJiqZRyYzA+AVQCfwC8BvgA8LsZXPMdwF3293cB74yzz5uBB1V1VFXHgAeBt2RwzbTxlXioLi9hJI4URX8eR7MmYu+GAH0ToaxKZQxMpq8jFYvjYWQz4Q3QUOVuTkmqOE/EB/flPxwFy5VS60Xq/HBnP5vqK8+ZvQ1w46taefKVcdc34cnQPGdGZl2Foxz2tQU43ptcOqcziZBhLC01mc327h6bSyvhDVBTUUJ1WfH0YrgxGB2qOq2q3ap6i6r+OrDJ5fkVeEBEnhCRO+xtzaraB2B/jeettAFnY95329sKQqKYufMLX1CDkUK81i2Oh5Gpwdhiz8XIlo6UgyOVnu0/on99uofFqOatWW8lHUE/Xo/w1CvjBbl+NhmfjfDzU8Mc3NdynvF1pOKPuEx+O0UdbiqkHPa21TA6E6E3yY2+q2cCj8DFLck9l9ZAOYNTYRbSaN5bWIzSNxFKq6QWrJBYWxGV1roxGJ92uS0eV6vqZcBB4CMico3L4+I93sV9VBCRO0TkqIgcHRoacnn61EgkD9I3EaLEIwSz1MWcDs5cgOwajDClXlkKx6VLXWUpN1/VwZv3ZDcfcMnGAHWVpfzhPz+dkdRELPd19fMX9z7HgS315z0R5wtfiYc372nmrl+e4TtHz666fzHz4LMDLCQwvlsbq9jVUu26vDaZpHki3EjndPVMsKOpmgpf8kmQLYFyFqPKcBp5s4GpMItRTatCyqHdLq0tBhIaDBE5KCJ/A7SJyBdjXl/HqphaFVXttb8OAt/HykcMiEirfY1WYDDOod3Axpj37VhKufGucaetc7W/sbHRzbJSJlEZZ/9EiOaacrwFaNpzqCkvpSNYmdUZ3wOTIRqrMm9GFBH+9O172N9Rn6WVWTRVl3P37VcyN7/I++58NO1GMIcHjvfz0W89yb72AF+5aX9BwlEOn3vPpbxuewOf/D/H+O4T3QVbR6Yc7uyjva4iYRjp0L5Wjr485mr8aWfPBK2B8pTkZS52ZsYkUEKwOrwTK9/GsqE2/ea97tH0ezAc2usq6SmSXoxkHkYvcBQIAU/EvO7ByjEkRUT8IlLtfA/cgCVaeA/gVD3dBPwgzuH3AzeISJ2d7L7B3lYQEoekCteDEUu2O76HpsI05ll9N1V2b6jh7tuvYCayyHszMBo/enaAj3zrSfa0Bbjr1gNUx5mzkE/KS7186Xf3c/W2Bv74u8/w/afWntGYmJvnZ6eGz6mOWsmhfa2ouquW6uo9f4b3apSXetnRlHhmzMBkmOHpsKtEektN+r0YjmeQbkgKrEqpqfACk3OF1xlLaDBU9RlVvQvYrqp3xby+ZyeiV6MZ+JmIPAM8BtyrqvcBfwX8moicBH7Nfo+I7BeRL9vXHgX+HHjcfv1ne1tBCFb5GIszFrR/snA9GLHsawvQMz7HWJZ6EwYnwzRnmL/IB3s2BLj79iuYCs3zvi89mnKc98fPD/L7dz/Jxa01fOPWA3GH8hQCx2i8dmuQf/edZ/jB0z2FXlJK/OjZAeYXNelY2+1NVexsruLeVaqlpsMLvDQ8k1LC22GvXUEY78m8K4W+jky6vZ3qpkzuE0u9GOOFz2O4yWEcsPslTthd3i+56fRW1dOqeon92qOqf2FvH1HVN6rqDvvrqL39qKreHnP8V1V1u/36Wtr/wixQ7/exENVzLLyq0jcxVxQGYynxnSUhwoGpUNqDk/LN3rYAd99+JRNzltHodVl++MgLg3zom0+ws6WKb956RdqqvLmiwuflKzddzoEt9fzhPz/NPc/EjcgWJUe6+tgQKOfSjbVJ9zu0r5XHz4wmlbY53jOBKq5LamPZ1xZgeDqyVPUXS2fPBCKWp7oatZWllJV46E9jLkb32CxN1WUJGwPd0F5Eg5TcGIyvAJ8DXgdcDuy3v14wBOOUcY7PzhOaj9JSwB4MB0cuIRthqfCCJUOQiY5UvtnXHuAfb7uC8Zl53nvno6vGmn9yYog7vvkEO5qr+MfbrkiqflpIKnxevnrz5ezvqOcT336KHx4rfqMxGZrnpyeGXZUmO2Gp+5OEpbp6U6+QcnCMTLy/i66eCbY1VrmSrBGxJuW5fRiJJZOSWoe2Iur2dmMwJlT1iKoO2t7BiKqO5HxlRYRTxhmb+O4rgh4Mh0BlKZvqK7NSKTW0NGlvbXgYDpdsrOUbtx1gbCbC++58NGG8+d9ODnHHN46yrdEyFrV5lqVPlUpfCV+7+XL2b67n499+OuWGt3zz8HODRBajroQbd9rTDJPNyOjqmaC5piytB5jdrYGEM2O6eldXvo0l3W7vnvG5pVGr6VJXWUqlz1sUk/fcGIwfi8j/EJHXishlzivnKysiludILxuM/knrh1cMSW9YVujMlOWmveL4d6XCqzfV8fVbDzA8HeG3v/ToeRU4Pz81zO13HWVLg5+7b7/ClcxEMeAvK+Grt1zOqzfW8rF/empp1ngxcm9nHy015bx6ozthhkN7W/jVSyMJG087eyZcCQ7Go8LnZXtTFcdX/F0MToUYmAyn5LVsCKTevLcYVXrHM/cwRKRoZM7dGIwrsMJQfwl81n79dS4XVWzEEyAsJg8DLJf97OgcExmqWg7Z8eRMdaQKxWs213HXrZczMBnifV96lEHbaPzixWFuu+txOoKWsci2XEmuqSor4Wu3XM4l7QE++q2nuP94+pPrcsV0eIGfnBjiLXtbXJdkH3pVK1El7r9nJrzAi0PTaYWjHPZuOL+CcKmvI4V+m5ZAOQOToYSD1OIxOBViflEzNhhg5THWREhKVa+L83IlPrheWDYYy09B/RMhPAKNBWzai2VflhLfg0shqeIwhOnwms31fP3WA/RPWEbj3mN93Pr1x9lYV8ndH7yioI2WmVBdXspdtx5gb1uAj37rSR58dqDQSzqHh54bILIQ5cZXue+Uv6i5mq0N/rihtuf6JlF1V8mUiL1tAQanwksPDgBdPZOIkHBoUjxaA+UsRJXhFORolmTN09SRiqWttqIo9KTczMNoFpGviMgR+/1uEbkt90srHspLvfh93nN6Mfrspr0Sb+oKlLkgW4nvgckQXo9kXc4j31zeUc/Xbr6c3vEQH/nWk7TXVfKtD16ZtdnihaK6vJRv3HaA3RsC/P7dT/Do6eJJJx7p7KepuozXbHKvEyoiHNrXyqOnR8/Ta3Or9ZQMR1gw9kGqs2eCLQ1+qsrcz2hpSWMuRjZ6MBza6yqYmJtnMlTYuRhu7nZfx2qa22C/P4ElSHhBYU15i8lhFEnTnkOd30dbbUXGie/ByTANVb6CjJzNNldsDXLXrQd4x6Ub+NYHr1izYbaV1JSX8o1bD9ASKOcvDz9XFB3AM+EFfvzCIAdTCEc5HNzXwmJUeWCFx9TZM0FDVVlGBRi7W+2ZMd3LSghdaeRFnNBz73gqBiPzLm8Hx+gUOvHtxmA0qOp3gCiAqi4A60OwPwWCK+RBeoukByOWbEidD06F13Q4aiUHttTzhfe+ek0m8ZMRqCjlo9dt51j3BI+8kBsNtVT48QuDhBeiHExDuHF3aw0dwcrzwlLHeybZ11aTkVSLv6yErTEzY4anw/RNhFIOczkPh/0pyIP0jM/RUOXLqAfDwSmtXQsGY0ZEgtjifyJyJZDdAQxrgGDM0B5n0l5LgWZ5J2JvWw1nRmYzclsHJkMZq9Qa8sO7L2unva6Czz90suBexuHOPhqqyrg8Dd0wEeHgvlZ+8eLIklrBXGSRk4NTGeUvHCypc+uWlY6QIUB9pQ+f10NfCs173WOZl9Q6LE/eK2yllBuD8UdY+k/bROTnWCNaP5bTVRUhsYq1k6EFZiOLRedhOH8Emcz4HpoK07jOnsbXK6VeDx+5bjvPnB3npyeHC7aO2cgCP35+iLfsbU5biPPGfa0sRnUpkf9s3yRRTS0xnYi9bcszYxyDsSfFznGPJ/XJe9lo2nMI+n2Ul3oKXinlpkrqSeBa4CrgQ8AeVT2W64UVG04Ow/EuoHh6MBwynY0xvxhlZCay5pr2LmR+/bJ22mor+MKPThTMy/jJC0PMzS+eM1kvVfZsqGFjfQWH7R4TxyPIhoexJHXeM0FnzwQdwcq0dMNaAuWuezGiUaVnfI72LFRIgT0XowgqpdxUSX0EqFLV46raBVSJyO/nfmnFRdDvI7IYZSq8UBSDk+LRUFVGa6A87Uopp8t7vcX71zO+Eg+/94ZtPPnKOD87VRgv497OPoJ+HwcykLF3qqV+fmqYidl5OrsnCPp9Wfkbc+abHO+ZoMulpHk8WlPwMIanw0QWolnzMKA4ejHchKQ+qKpLI8BspdoP5m5JxcmSPMh0ZHk0a5aeHrLJ3rZA2r0Yg1PZGc1qyC+/ub+d1kA5X/hR/nMZoflFHn5+kBv2tGRcYn5obyvzi8qDzw3Q2TPBnrZAVmaTVJeXsqXBz09PDtMzPpe2wXBCUm7+j89msaTWoRi6vd38hD0S81MTES+wtov008DpSxixxz6KFOeNdV9bgJeGZ5gOp66d7zQ3racqqQuBshIvv/eGbRx9eYxfvpjfvoxHXhhiNrKYlbG2r2oP0FZbwfef6ubk4DT70lCoTcTetgCPvWRNSEg3zNVaU07EDtuuhhM6ymTS3kra6ioYm51nJo2/7WzhxmA8AHxHRN4oItcD/wTcl9tlFR+x8iD9E3M0VpVRWiRNe7HsbatBlfP0c9ww4HgYJoex5njP/o0015Tx+YdO5vW6R7r6qKss5cqtmU9VtMJSLfz81AiLUc1K/sIh1vikq02VSvOe4wlko8vbYakXo4B5DDd3vD8BHgJ+D/iI/f2f5HJRxUisPEjfRHEMTopHbIIvVYYmLc9prXd5X4iUl3r5vWu38dhLo3nzMkLzizz03CBvzkI4yiE2cb4nzRt7PBwjsbG+Im05+1QGKXWPzVHv9+FPoZt8NYqhtDbpT9kOP31DVf+3qv6Gqv66qv6Dql54jXtVyyGpYuvyjqWpupzmmjKO96ZeWjs4Faahqqxo5E4MqfHeA5toqi7jCw+dyMv1/u3kMNPhhbSa9RJx6cZaNgTKqa0szWrC2CnPzcRraa1137yXzZJaB6fiqpDNe0nvDLZhaBSRC/6Rs9JXQkWpdynp3VoEg5MSEU+h0w2maW9tU17q5UPXbuPR06P8Kg8aU4c7+whUlHLVtmDWzikifPLgLj7+xh1ZSXg7BCpK+dj12/nAlZvTPkeDv4wSj7jyMHrGZrMajgKrCtJXUtheDDf+0hng5yJyDzDjbFTVz+VqUcVKvd/HK6OzTIUXitbDACss9fALg8yEF1JyiQenwsZgrHHef8Um/v6RF/niwye5e2v2buQrCS8s8qNnB3jL3pas5/LecWlbVs/n8O9uuCij4z0eoblm9dJaVaV7bI7rdzVldL1412+vrSiowXDzk+4FfmjvWx3zcoWIeEXkKRH5of3+30TkafvVKyL/muC4xZj97nF7vVwSrPIthXqKNYcBltutaslDp8J605G6ECkv9fLha7fy81MjHD0zmrPr/OzkMFPhBQ6lIGW+HmgNlNO7SkhqeDpCeCGa1ZJah7a6CroLmPRe9fFTVf8MQET8qjqz2v5x+DjwHFBjn+/1zgci8n+AHyQ4bk5VL03jejmj3u/jWLcV6inqkFRM4nu/y2aqhcUow9PGw1gP/LbtZXzhoZN887YrcnKNw5391JSXcPW2hpycv1hpCZSvqqSwVFKbgz6t9rqKgs5BcdPp/VoReRbrpo+IXCIif+fm5CLSDtwIfDnOZ9XA9UBcD6MYiZ3SVsweRnNNGQ1VZSnlMUZmIqhCo/Ew1jyVvhLuuGYr/3ZymFc+CusAABOKSURBVCdfGcv6+SMLUR58tp9f292Cr+TCKpBoteVBkjXvLcma1+fCYFQyPB1hLlKYuiM3P+3PA28GRgBU9RngGpfn/zxWCW40zmfvAh5S1URxk3IROSoij4rIOxNdQETusPc7OjSUW5nn2HLTYu5VEBH2tdWkJEI4aM/ybjYexrrgA1dupt7v4ws/yn5fxs9fHGYytMChfS1ZP3ex0xqoILwQZTzJKOTuLE7aW4lzzkL1Yrh6PFDVsys2rWreROStwKCqPpFgl/dhNQEmYpOq7gd+G/i8iGxLsLY7VXW/qu5vbGxcbVkZ4ciDNFT5KCvJXOM+l+xtC3BycMr1k8iA3eXdZDyMdYG/rITbX7+Fn5wY4umz46sfkAKHj/VRXVbC63ZcWOEocNeL0TM2R6CilOo0BA5Xo9C9GG4MxlkRuQpQEfGJyL/HDk+twtXA20XkDPBt4HoR+UcAe77GAeDeRAeraq/99TTwCPBqF9fMKU4vRjFXSDnsbQsQVUsm2g1GR2r98buv7aC2spQvZrH7e34xygPPDvCm3c1F/9CUC5YGKU0mfsLvHpvNeg+Gg5NIL1SllBuD8WGsDu82oAe41H6fFFX9tKq2q2oH8F7gYVX9gP3xbwI/VNW4ZlpE6kSkzP6+Acv4POtirTnFCUkVc8LbYV+KUueDU9aPYr2MMTVAVVkJH3z9Vh5+fpBj3dnxMn7x4ggTc/Mc3HvhhaNg+W8/mYeRi6Y9h6bqMkq9UrwhKVUdVtX3q2qzqjaq6gdUNdOuoPeyIhwlIvtFxEmOXwwcFZFngB8Df6WqBTcY9UsGo/g9jNZAOfV+n2uDMTAZJuj3FaU+liF9fve1mwlUZM/LONLZh9/n5ZqduQ3/FiuN1WV4PUJfgtneqtYcjLba7JfUgtWLsaGAvRirltWKyFbgC8CVWGNafwn8oR0qcoWqPoIVVnLevyHOPkeB2+3vfwHsc3v+fBG0cxhrISQlIuxtC3Ckq59TQ9Or7v/S8AwtJn+x7qguL+W2123hcw+eoKtnIm1pb7BKr+8/3s8bL27OypzqtYjXIzRVlyX0MMZm55mNLObMw4DCypy7eZz8FvAdoBXYAPwLyZPV65a2ugpuubqDg3vXRrPSzVdt5rLNdVSVlaz62tcW4KarOgq9ZEMOuPnqDmrKSzL2Mh49PcrY7HxGk/XWAy2B8oQ5jKWS2hwajLbaioLpSbnRjRBV/WbM+38UkY/makHFjNcjfOZtewq9DNdcv6uZ63c1F3oZhgJTU17Kra/bwud/dJJneyfZvSG9OROHu/qo9Hl5w0UXZjjKYUOgguf64xeTODfybM7BWEl7XSWDU2FC84t59/TceBg/FpFPiUiHiGwWkT8B7hWRehHJXATfYDDknFuu2kJ1WfpexsJilPu7+rl+V9MFG45ySDZ5rzsHk/ZW4ngvvQVIfLvxMH7L/vqhFdtvxcppbM3qigwGQ9YJVJZyy9UdfPHhUzzfP8multS8jMfOjDIyE7ngw1FgFZTMRhaZDC0QqDi316J7bJbq8pLztmeT2Oa9rY1VObtOPNxUSW1J8jLGwmBYI9z6ui1UlZXwNw+dSvnYw519VJR6ue6i7CqwrkValpr3zn/Ctyqkclt2315fuF4MU0NpMFwg1Fb6uPmqDg539XFiYMr1cYtR5b6uAa7b1UiF78IOR0Hybm+rByN34Siw5HtKPFKQSiljMAyGC4jbXreFylIvf/Owey/j8TOjDE+HTTjKJtFsb2cORi4rpABKvB5aAuUFqZQyBsNguICo8/v43as6+OGxXk4NuvMyjnT2UVbiMeEom6bqMjxyvocxObfAdHgh5wYDnF6MIjUYItImIleJyDXOK9cLMxgMueGDr99KhUsvIxpVjnT1c91FTSlNb1zPlHo9NFaXnTfb+2weejAc2usqC2Iw3HR6/zesSqlnWVapVeCnOVyXwWDIEfV+H79z5Wa+9G+n+YM37mBbkkqbJ14ZY3AqzMELUMo8GS2BivM8jHyU1Dq01VYwMBUishDN60wSN1d6J3CRqh5S1bfZr7fnemEGgyF3fPCarZSVePnbVbyMe4/14Svx8MaLTQNoLK1xZnvnctLeStrrKlCNX6mVS9wYjNNA7oqKDQZD3mmoKuMDV27iX5/u4aXh+JOXo1Hlvq5+rt3ZSJUJR51Diz15L5busVn8Pi+1lbm/XRZK5tyNwZgFnhaRfxCRLzqvXC/MYDDkljuu2Uap18P/SuBlPHV2jP7JEDea6qjzaA2UMx1eYCq0PHnPKakVkZxf38mT5LtSyo3BuAf4c+AXwBMxL4PBsIZprC7j/Vds5l+f7uHlkfO9jMOd/fi8Hq6/2FRHrWRpkFKMl9EzNpdTDamV1/dI/ifvuen0viveKx+LMxgMueXD126lxCP87Y/P9TJUlSOdfVyzs4GaHIwaXetsqD1/kFIuJ+2tpNTroTWQ/9LahAZDRL5jf+0UkWMrX/lbosFgyBVNNeW878AmvvdkD2dHl59Wnz47Tu9EaM1I+ecbZ3aM42FMhuaZDOWnB8OhrbaC7jwLECbzMD5uf30r8LY4L4PBsA748LXb8Ijwd48sexlHuvop9Qpv2m2qo+LRXHOuPMiSrHmOJu3Fo70u/3MxkhmM3xKRy4EeVX155StfCzQYDLmlJVDOew9s5F+OdtM9Nouqcu+xPl63vSGnqqtrGV+Jh4aqsqWy1uUejPx5GO11FfRNzDG/GM3bNZMZjHas0ayDIvKIiPyliNyY6gwMEfGKyFMi8kP7/ddF5CURedp+XZrguJtE5KT9uimVaxoMhtT4vTc4XsaLdPZM0DM+x0FTHZWU1pjS2nxM2ltJW10FUT1f0yqXJCyuVtV/DyAiPmA/cBXWDIwvici4qu52eY2PA88BsQL8f6yq3010gG2UPmNfV4EnROQeVR1zeU2DwZACrYEK3nN5O//8+FmmQwuUeIQbTDgqKS2Bcl4ZsQxFz9gc5aUe6v2+vF0/thdjY31+QmFuymorsG72AfvVC/zKzclFpB24Efhyiut6M/Cgqo7aRuJB4C0pnsNgMKTA771hOwD3PNPLVdsbqK3M381vLbIhUH5OSCpfPRgOjjeTz9LaZFVSd4rIz4F/Bl6L1Yfxm6q6X1VvcXn+zwN/AqwMsv2FXW31P0WkLM5xbcDZmPfd9jaDwZAj2mor+I3XbATgRqMdtSotgQomQwvMhBfoHs9fSa1Da6ACkWVJknyQzMPYBJQB/UAP1k173O2JReStwKCqrmzy+zSwC7gcqAc+Ge/wONvOH6BrXecOETkqIkeHhobcLs9gMMThD9+0g9+5cjM3vmpDoZdS9DiDlPonQ1bTXh40pGLxlXhori7Pay9GQoOhqm/Buqn/tb3p3wGPi8gDIvJnLs59NfB2ETkDfBu4XkT+UVX71CIMfA04EOfYbmBjzPt2rFBYvHXeaXs9+xsbG10sy2AwJKKpppw/f+deox3lAqfb+9TgNGOz83lRqV2JNRejCEJSAPaNvQs4DBwBfg5sY7lHI9mxn1bVdlXtAN4LPKyqHxCRVgCxgn3vBLriHH4/cIOI1IlIHXCDvc1gMBiKAsfDeOJlqxYn3yEpsCqliiIkJSJ/ICLfFpGzWLMv3gq8ALwbK5SULneLSCfQCTQA/8W+3n4R+TKAqo5i6Vc9br/+s73NYDAYigKnee/xM9atqRAGo72ugr7xEAt56sVI5nd2AN8F/lBV+zK5iKo+Ajxif399gn2OArfHvP8q8NVMrmswGAy5orzUS73fR1fPBEDehAdjaa+rZCGqDEyF85JDSdaH8Uc5v7rBYPh/7d17jBVnGcfx76+swAIVlkt1LcilNo2Y1ILEQKuGWKWlNhiVBAimeE2qJt7SKIiX8idqbGM0gvGSqkirWJFglJqWaEyUFlqgSEtBi5baCqTSxtZEWh//mHdg2Jzdzq7szJzT3yeZnJl3Bs4zT86ZZ+ed98xYG+sdP5qnnv0Po7ouYMq4VgM+h1deJKq66F7ds/3MzDpMfh3j4p7uSn+Dkav6txguGGZmQ5SPlKp6SG0uv816VUNrXTDMzIaod3x2wK5jSC1k11GmXDiqsrvWumCYmQ1R/lyMOkZI5ab2dHPslLukzMwaLb+GUW/BGFNZl5R/zmlmNkRzp/fw4TfPZOFl9T33/MpLJjF25IhK3ksRLW/R1JbmzZsXu3fvrjsMM7O2IWlPRMwrs627pMzMrBQXDDMzK8UFw8zMSnHBMDOzUlwwzMysFBcMMzMrxQXDzMxKccEwM7NSOuqHe5JOAH8tNE0GTtYUzmC1U6zQXvG2U6zQXvG2U6zQXvFWFev0iJhSZsOOKhh9Sdpd9heMdWunWKG94m2nWKG94m2nWKG94m1irO6SMjOzUlwwzMyslE4vGN+uO4BBaKdYob3ibadYob3ibadYob3ibVysHX0Nw8zMzp9OP8MwM7PzpCMLhqRrJR2SdETS6rrjAZA0TdJOSQ9J+pOkT6T2iZJ+I+lweu1J7ZL09bQP+yXNrSHmEZIekLQ9Lc+UtCvFeoekkal9VFo+ktbPqCHWCZK2SHo45XhBU3Mr6VPpM3BA0mZJo5uUW0nfk3Rc0oFC26BzKWlV2v6wpFUVxvqV9DnYL+nnkiYU1q1JsR6SdE2hvZJjRqt4C+tukhSSJqflWnPbUkR01ASMAP4MzAJGAvuA2Q2IqxeYm+YvBB4BZgNfBlan9tXA+jR/HfArQMB8YFcNMX8a+DGwPS3/BFie5jcAH0nzHwU2pPnlwB01xHob8KE0PxKY0MTcAhcDjwLdhZy+r0m5Bd4CzAUOFNoGlUtgIvCX9NqT5nsqinUR0JXm1xdinZ2OB6OAmek4MaLKY0areFP7NGAH2e/IJjchty3jr+JNqpyABcCOwvIaYE3dcbWI8xfA24FDQG9q6wUOpfmNwIrC9me2qyi+qcDdwFuB7elDe7LwRTyT5/RBX5Dmu9J2qjDWl6eDsPq0Ny63ZAXjsfRl70q5vaZpuQVm9DkIDyqXwApgY6H9nO2GM9Y+694FbErz5xwL8txWfcxoFS+wBXg9cJSzBaP23PadOrFLKv9C5o6ltsZI3QpzgF3AKyLiCYD0mj8cuO79uBX4DPDftDwJOBURz7eI50ysaf3TafuqzAJOAN9PXWjfkTSWBuY2Ih4Hvgr8DXiCLFd7aG5uc4PNZd2f39wHyP5Kh4bGKmkJ8HhE7OuzqnHxdmLBUIu2xgwFkzQO+BnwyYh4ZqBNW7RVsh+SrgeOR8SekvHUnfMustP8b0XEHOBZsm6T/tSZ2x7gnWRdIq8CxgKLB4in7ty+mP7iqz1uSWuB54FNeVOLzWqNVdIYYC3wxVarW7TVGm8nFoxjZP2BuanA32uK5RySXkZWLDZFxJ2p+R+SetP6XuB4aq9zP64Clkg6CtxO1i11KzBBUleLeM7EmtaPB56qKNb8/Y9FxK60vIWsgDQxt28DHo2IExFxGrgTuJLm5jY32FzW+j1MF4KvB1ZG6rcZIKY6Y72E7I+Hfen7NhW4X9IrB4irtng7sWDcB1yaRp2MJLtQuK3mmJAk4LvAQxHxtcKqbUA+ymEV2bWNvP2GNFJiPvB03iUw3CJiTURMjYgZZPm7JyJWAjuBpf3Emu/D0rR9ZX9NRsSTwGOSLktNVwMHaWBuybqi5ksakz4TeayNzG3BYHO5A1gkqSedVS1KbcNO0rXAZ4ElEfFcn31YnkaezQQuBe6lxmNGRDwYERdFxIz0fTtGNjjmSRqY22G/SFLHRDa64BGykQ9r644nxfQmstPG/cDeNF1H1h99N3A4vU5M2wv4ZtqHB4F5NcW9kLOjpGaRfcGOAD8FRqX20Wn5SFo/q4Y4rwB2p/xuJRs90sjcAuuAh4EDwA/JRu00JrfAZrLrK6fJDmAfHEouya4fHEnT+yuM9QhZH3/+PdtQ2H5tivUQsLjQXskxo1W8fdYf5exF71pz22ryL73NzKyUTuySMjOzYeCCYWZmpbhgmJlZKS4YZmZWiguGmZmV4oJh1g9JL0jaW5gGvIuppBsl3XAe3vdofsdSsybxsFqzfkj6V0SMq+F9j5KNuT9Z9XubDcRnGGaDlM4A1ku6N02vSe03S7opzX9c0sH0HIPbU9tESVtT2x8lXZ7aJ0m6K904cSOFewVJem96j72SNkoaUcMumwEuGGYD6e7TJbWssO6ZiHgj8A2y+2z1tRqYExGXAzemtnXAA6ntc8APUvuXgN9HduPEbcCrASS9FlgGXBURVwAvACvP7y6aldf14puYvWT9Ox2oW9lceL2lxfr9wCZJW8luVQLZ7WHeAxAR96Qzi/FkD9V5d2r/paR/pu2vBt4A3Jfddopuzt70z6xyLhhmQxP9zOfeQVYIlgBfkPQ6Br4tdav/Q8BtEbHm/wnU7Hxxl5TZ0CwrvP6huELSBcC0iNhJ9hCqCcA44HekLiVJC4GTkT0Tpdi+mOzGiZDd5G+ppIvSuomSpg/jPpkNyGcYZv3rlrS3sPzriMiH1o6StIvsj64Vff7dCOBHqbtJwC0RcUrSzWRPBdwPPMfZ24WvAzZLuh/4Ldkt0ImIg5I+D9yVitBp4GNkz302q5yH1ZoNkoe92kuVu6TMzKwUn2GYmVkpPsMwM7NSXDDMzKwUFwwzMyvFBcPMzEpxwTAzs1JcMMzMrJT/AcCRfDeGp2yzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example policy: \n",
      " [0.49 0.49 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0e61eb28e341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_boards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-9eaee1eda164>\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        currstates = []\n",
    "        #afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                currstates.append(env.board)\n",
    "                #afterstates.append(env.board)\n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = AC.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        #afterstates.append(new_board)\n",
    "        #afterstates = afterstates[2:]\n",
    "        \n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "        \n",
    "        States = np.vstack(states)\n",
    "        CumulativeRewards = AC.get_cumulative_rewards(rewards)\n",
    "        CurrStates = np.vstack(currstates)\n",
    "        #AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        AC.update(states = States, \n",
    "                  currstates = CurrStates,\n",
    "                  #afterstates = AfterStates, \n",
    "                  rewards = CumulativeRewards,\n",
    "                  done = Dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    print(\"Agent epsilon: \", AC._epsilon)\n",
    "    plt.figure()\n",
    "    x = [(n + 1) * 50 for n in range(len(win_pct))]\n",
    "    y = (100*np.array(win_pct)).astype('int')\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Win percentage of last 100 episodes')\n",
    "    plt.savefig('tensorflow_random.pdf')\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage:  0.98\n",
      "Agent epsilon:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example policy: \n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c5f79b1c7ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m#afterstates.append(env.board)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_boards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-9eaee1eda164>\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "win_pct = []\n",
    "AC._epsilon = 0\n",
    "for i in range(100):\n",
    "\n",
    "    wins = []\n",
    "\n",
    "    for _ in range(50):\n",
    "\n",
    "        env = backgammon()\n",
    "\n",
    "        #states = []\n",
    "        #currstates = []\n",
    "        #afterstates = []\n",
    "        #rewards = []\n",
    "        #afterstates.append([])\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "\n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "\n",
    "                #currstates.append(env.board)\n",
    "                #afterstates.append(env.board)\n",
    "\n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                #rewards.append(reward)\n",
    "                #states.append(new_board)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        new_board, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            reward = -1\n",
    "                            break\n",
    "\n",
    "        #afterstates.append(new_board)\n",
    "        #afterstates = afterstates[2:]\n",
    "\n",
    "        #Dones = np.zeros(len(states))\n",
    "        #Dones[-1] = 1\n",
    "\n",
    "        #States = np.vstack(states)\n",
    "        #CurrStates = np.vstack(currstates)\n",
    "        #AfterStates = np.vstack(afterstates)\n",
    "        #Rewards = AC.get_cumulative_rewards(rewards)\n",
    "\n",
    "\n",
    "        #AC.update(states = States, \n",
    "        #          rewards = Rewards, \n",
    "        #          currstates = CurrStates,\n",
    "        #          afterstates = AfterStates, \n",
    "        #          done = Dones)\n",
    "\n",
    "        wins.append(int(reward == 1))\n",
    "\n",
    "    win_pct.append(np.mean(wins))\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    print(\"Agent epsilon: \", AC._epsilon)\n",
    "    plt.figure()\n",
    "    x = [(n + 1) * 50 for n in range(len(win_pct))]\n",
    "    y = (100 * np.array(win_pct)).astype('int')\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Win percentage of last 100 episodes')\n",
    "    plt.ylim(0, 100)\n",
    "    #plt.savefig('tensorflow_random.pdf')\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "#AC = ActorCritic(sess = s, entropy = 0.01, learning_rate = 0.001, gamma = 0.99,\n",
    "#                epsilon = 1, epsdecay = 0.999)\n",
    "for i in range(10):\n",
    "\n",
    "    wins = []\n",
    "\n",
    "    for _ in range(50):\n",
    "\n",
    "        env = backgammon()\n",
    "\n",
    "        states = []\n",
    "        currstates = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "\n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "\n",
    "                currstates.append(env.board)\n",
    "                afterstates.append(env.board)\n",
    "\n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        new_board, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "\n",
    "        afterstates.append(new_board)\n",
    "        afterstates = afterstates[2:]\n",
    "\n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "\n",
    "        States = np.vstack(states)\n",
    "        CurrStates = np.vstack(currstates)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        Rewards = AC.get_cumulative_rewards(rewards)\n",
    "\n",
    "\n",
    "        AC.update(states = States, \n",
    "                  rewards = Rewards, \n",
    "                  currstates = CurrStates,\n",
    "                  afterstates = AfterStates, \n",
    "                  done = Dones)\n",
    "\n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "\n",
    "    win_pct.append(np.mean(wins))\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    print(\"Agent epsilon: \", AC._epsilon)\n",
    "    plt.figure()\n",
    "    x = [(n + 1) * 50 for n in range(len(win_pct))]\n",
    "    y = (100 * np.array(win_pct)).astype('int')\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Win percentage of last 100 episodes')\n",
    "    plt.ylim(0, 100)\n",
    "    #plt.savefig('tensorflow_random.pdf')\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spila við random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win percentage:  [0.65 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example policy: \n",
      " [0.18 0.18 0.09 0.09 0.07 0.07 0.04 0.04 0.02 0.02 0.02 0.02 0.02 0.02\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-db723e46d411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mafterstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_boards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mnew_board\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3139f60e684e>\u001b[0m in \u001b[0;36msample_action\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "win_pct = np.zeros([10, 10])\n",
    "\n",
    "for j in range(10):\n",
    "    AC = ActorCritic(sess = s, entropy = 0.01, learning_rate = 1e-3, gamma = 0.99)\n",
    "    for i in range(10):\n",
    "\n",
    "        wins = []\n",
    "\n",
    "        for _ in range(100):\n",
    "\n",
    "            env = backgammon()\n",
    "\n",
    "            states = []\n",
    "            currstates = []\n",
    "            afterstates = []\n",
    "            rewards = []\n",
    "            afterstates.append([])\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                dice = B.roll_dice()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "\n",
    "                    possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                    n_actions = len(possible_moves)\n",
    "\n",
    "                    if n_actions == 0:\n",
    "                        break\n",
    "\n",
    "                    currstates.append(env.board)\n",
    "                    afterstates.append(env.board)\n",
    "\n",
    "                    action = AC.sample_action(possible_boards)\n",
    "                    new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "\n",
    "                    rewards.append(reward)\n",
    "                    states.append(new_board)\n",
    "\n",
    "                    if done:\n",
    "                        break\n",
    "\n",
    "                if not done:\n",
    "                    dice = B.roll_dice()\n",
    "\n",
    "                    for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                            new_board, reward, done = env.make_move(dice)\n",
    "                            if done:\n",
    "                                rewards[-1] = -1\n",
    "                                break\n",
    "\n",
    "            afterstates.append(new_board)\n",
    "            afterstates = afterstates[2:]\n",
    "\n",
    "            Dones = np.zeros(len(states))\n",
    "            Dones[-1] = 1\n",
    "\n",
    "            States = np.vstack(states)\n",
    "            CurrStates = np.vstack(currstates)\n",
    "            AfterStates = np.vstack(afterstates)\n",
    "            Rewards = AC.get_cumulative_rewards(rewards)\n",
    "\n",
    "\n",
    "            AC.update(states = States, \n",
    "                      rewards = Rewards, \n",
    "                      currstates = CurrStates,\n",
    "                      afterstates = AfterStates, \n",
    "                      done = Dones)\n",
    "\n",
    "            wins.append(int(rewards[-1] == 1))\n",
    "\n",
    "        win_pct[i, j] = np.mean(wins)\n",
    "\n",
    "        clear_output(True)\n",
    "        print(\"Win percentage: \", win_pct[-1])\n",
    "        plt.figure()\n",
    "        x = [(n + 1) * 100 for n in range(10)]\n",
    "        y = (100 * win_pct).astype('int')\n",
    "        plt.plot(x, y, 'o-', color = \"b\")\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Win percentage of last 100 episodes')\n",
    "        plt.savefig('tensorflow_random.pdf')\n",
    "        plt.show()\n",
    "        print(\"Example policy: \\n\", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x = [(n + 1) * 100 for n in range(10)]\n",
    "y = (100 * np.mean(win_pct, axis = 1)).astype('int')\n",
    "plt.plot(x, y, 'o-')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Win percentage of last 100 episodes')\n",
    "plt.savefig('tensorflow_random.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Þjálfa Player2 (Policy Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = PG.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "                afterstates.append(new_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        afterstates.append(new_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "        \n",
    "        States = np.vstack(states)\n",
    "        Rewards = PG.get_cumulative_rewards(rewards)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        PG.update(states = States, \n",
    "                      rewards = Rewards, \n",
    "                      afterstates = AfterStates, \n",
    "                      done = Dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    print(PG.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PG vs. Random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        #states = []\n",
    "        #afterstates = []\n",
    "        #rewards = []\n",
    "        #afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = PG.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                #rewards.append(reward)\n",
    "                #states.append(old_board)\n",
    "                #afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                \n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        new_board, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            reward = 0\n",
    "                            break\n",
    "                            \n",
    "        #afterstates.append(old_board)\n",
    "        #afterstates = afterstates[2:]\n",
    "        \n",
    "        #Dones = np.zeros(len(states))\n",
    "        #Dones[-1] = 1\n",
    "        \n",
    "        #States = np.vstack(states)\n",
    "        #Rewards = player.get_cumulative_rewards(rewards)\n",
    "        #AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        #player.update(states = States, \n",
    "        #              rewards = Rewards, \n",
    "        #              afterstates = AfterStates, \n",
    "        #              done = Dones)\n",
    "        \n",
    "        wins.append(reward)\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keppni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        #states = []\n",
    "        #afterstates = []\n",
    "        #rewards = []\n",
    "        #afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                #rewards.append(reward)\n",
    "                #states.append(old_board)\n",
    "                #afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            reward = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        #afterstates.append(old_board)\n",
    "        #afterstates = afterstates[2:]\n",
    "        \n",
    "        #Dones = np.zeros(len(states))\n",
    "        #Dones[-1] = 1\n",
    "        \n",
    "        #States = np.vstack(states)\n",
    "        #Rewards = player.get_cumulative_rewards(rewards)\n",
    "        #AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        #player.update(states = States, \n",
    "        #              rewards = Rewards, \n",
    "        #              afterstates = AfterStates, \n",
    "        #              done = Dones)\n",
    "        \n",
    "        wins.append(int(reward == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Þjálfa AC á PG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(100):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(new_board)\n",
    "                afterstates.append(new_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        new_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                            \n",
    "        afterstates.append(new_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        Dones = np.zeros(len(states))\n",
    "        Dones[-1] = 1\n",
    "        States = np.vstack(states)\n",
    "        CumulativeRewards = AC.get_cumulative_rewards(rewards)\n",
    "        AfterStates = np.vstack(afterstates)\n",
    "        \n",
    "        \n",
    "        AC.update(states = States, \n",
    "                      rewards = CumulativeRewards,\n",
    "                      afterstates = AfterStates, \n",
    "                      done = Dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    print(\"Example policy: \", AC.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prófa batch training (Virkar illa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    States = []\n",
    "    AfterStates = []\n",
    "    Rewards = []\n",
    "    Dones = []\n",
    "    \n",
    "    for _ in range(50):\n",
    "        \n",
    "        env = backgammon()\n",
    "        done = False\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        rewards = []\n",
    "        \n",
    "        afterstates.append([])\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = player.sample_action(possible_boards)\n",
    "                old_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                states.append(old_board)\n",
    "                afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                \n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        old_state, reward, done = env.make_move(dice)\n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "        afterstates.append(old_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        dones = np.zeros(len(rewards))\n",
    "        dones[-1] = 1\n",
    "        rewards = player.get_cumulative_rewards(rewards)\n",
    "        \n",
    "        States.append(states)\n",
    "        AfterStates.append(afterstates)\n",
    "        Rewards.append(rewards)\n",
    "        Dones.append(dones)\n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    #Rewards = np.concatenate(Rewards).flatten()\n",
    "    #States = np.vstack(States)\n",
    "    #AfterStates = np.vstack(AfterStates)\n",
    "    #Dones = np.concatenate(Dones).flatten()\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    \n",
    "    for r, s, a, d in zip(Rewards, States, AfterStates, Dones):\n",
    "        player.update(states = np.vstack(s), \n",
    "                      rewards = r, \n",
    "                      afterstates = np.vstack(a), \n",
    "                      done = d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Agent (Virkar illa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvActorCritic:\n",
    "    def __init__(self, gamma = 0.99, learning_rate = 1e-3, entropy = 0.1):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._states2D = tf.expand_dims(self._states, 2)\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._afterstates2D = tf.expand_dims(self._afterstates, 2)\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.network = keras.models.Sequential()\n",
    "        self.network.add(L.InputLayer(input_shape = (29, 1)))\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 2))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 4))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 8))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5,filters = 16))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 32))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Conv1D(kernel_size = 5, filters = 8))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Flatten())\n",
    "        self.network.add(L.Dense(128))\n",
    "        self.network.add(L.LeakyReLU())\n",
    "        self.network.add(L.Dense(1))\n",
    "                         \n",
    "        \n",
    "        # Predictions\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = self.network(self._states2D)\n",
    "        self._afterstate_values = self.network(self._afterstates2D) * (1 - self._done)\n",
    "        self._target_state_values = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values - self._state_values\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.network(self._states2D)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_entropy = -tf.reduce_sum(self._actor_policy * self._actor_log_policy)\n",
    "        \n",
    "        # Losses\n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values)))\n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_loss -= entropy * self._actor_entropy\n",
    "        \n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        self._update = self._optimizer.minimize(self._critic_loss + self._actor_loss)\n",
    "        \n",
    "        self._s = tf.InteractiveSession()\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        \n",
    "        return np.random.choice(np.arange(len(probs)), p = probs)\n",
    "    \n",
    "    def update(self, states, rewards, afterstates, done):\n",
    "        self._s.run(self._update, \n",
    "                    ({self._states: states, \n",
    "                      self._afterstates: afterstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_pct = []\n",
    "\n",
    "PG = PolicyGradient(sess = s, entropy = 0.1, learning_rate=1e-4, gamma = 0.9)\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    wins = []\n",
    "    \n",
    "    for _ in range(10):\n",
    "        \n",
    "        env = backgammon()\n",
    "        \n",
    "        states = []\n",
    "        afterstates = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        reward_vector = []\n",
    "        afterstates.append([])\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            dice = B.roll_dice()\n",
    "            for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                \n",
    "                possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                n_actions = len(possible_moves)\n",
    "                \n",
    "                if n_actions == 0:\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "                action = AC.sample_action(possible_boards)\n",
    "                new, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                \n",
    "                rewards.append(reward)\n",
    "                reward_vector.append(np.zeros(len(possible_boards)))\n",
    "                states.append(possible_boards)\n",
    "                actions.append(action)\n",
    "                afterstates.append(old_board)\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            if not done:\n",
    "                dice = B.roll_dice()\n",
    "                env.swap_player()\n",
    "                for _ in range(1 + int(dice[0] == dice[1])):\n",
    "                        possible_moves, possible_boards = env.legal_moves(dice, 1)\n",
    "                        n_actions = len(possible_moves)\n",
    "                        \n",
    "                        if n_actions == 0:\n",
    "                            break\n",
    "                        \n",
    "                        action = PG.sample_action(possible_boards)\n",
    "                        \n",
    "                        old_board, reward, done = env.step(possible_moves[action], player = 1)\n",
    "                        \n",
    "                        if done:\n",
    "                            rewards[-1] = -1\n",
    "                            break\n",
    "                            \n",
    "                env.swap_player()\n",
    "                                     \n",
    "                            \n",
    "        afterstates.append(old_board)\n",
    "        afterstates = afterstates[2:]\n",
    "        \n",
    "        CumulativeRewards = PG.get_cumulative_rewards(rewards)\n",
    "        \n",
    "        for States, Reward, Reward_vector, Action in zip(states, CumulativeRewards, reward_vector, actions):\n",
    "            Reward_vector[Action] = Reward\n",
    "            \n",
    "            States = np.vstack(States)\n",
    "            Reward_vector = np.array(Reward_vector)\n",
    "            \n",
    "            PG.update(rewards = Reward_vector, states = States, afterstates = 0, done = 0)\n",
    "        \n",
    "        \n",
    "        wins.append(int(rewards[-1] == 1))\n",
    "    \n",
    "    win_pct.append(np.mean(wins))\n",
    "    \n",
    "    clear_output(True)\n",
    "    print(\"Win percentage: \", win_pct[-1])\n",
    "    plt.plot(win_pct)\n",
    "    plt.show()\n",
    "    print(\"Example policy: \\n\", PG.ExamplePolicy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sér network fyrir Actor og Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, gamma = 0.99):\n",
    "        \n",
    "        self._gamma = gamma\n",
    "        \n",
    "        self._states = tf.placeholder(\"float32\", (None, 29), name = \"states\")\n",
    "        self._afterstates = tf.placeholder(\"float32\", (None, 29), name = \"afterstates\")\n",
    "        self._done = tf.placeholder(\"float32\", (None, ), name = \"dones\")\n",
    "        self._cumulative_rewards = tf.placeholder(\"float32\", (None, ), name = \"rewards\")\n",
    "        \n",
    "        # Actor\n",
    "        self.actor = keras.models.Sequential()\n",
    "        self.actor.add(L.Dense(32))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(64))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(32))\n",
    "        self.actor.add(L.LeakyReLU())\n",
    "        self.actor.add(L.Dense(1))\n",
    "        \n",
    "        # Critic\n",
    "        \n",
    "        self.critic = keras.models.Sequential()\n",
    "        self.critic.add(L.Dense(32))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(64))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(32))\n",
    "        self.critic.add(L.LeakyReLU())\n",
    "        self.critic.add(L.Dense(1))\n",
    "        \n",
    "        # Losses and logits\n",
    "        \n",
    "        ## Critic\n",
    "        self._state_values = self.critic(self._states)\n",
    "        self._afterstate_values = self.critic(self._afterstates) * (1 - self._done)\n",
    "        self._advantage = self._cumulative_rewards + self._gamma * self._afterstate_values - self._state_values\n",
    "        \n",
    "    \n",
    "        self._target_state_values = self._cumulative_rewards + self._gamma * self._afterstate_values * (1 - self._done)\n",
    "        \n",
    "        self._critic_loss = tf.reduce_mean((self._state_values - tf.stop_gradient(self._target_state_values)))\n",
    "        self._critic_optimizer = tf.train.AdamOptimizer()\n",
    "        self._critic_update = self._critic_optimizer.minimize(self._critic_loss)\n",
    "        \n",
    "        ## Actor\n",
    "        self._actor_logits = self.actor(self._states)\n",
    "        self._actor_policy = tf.nn.softmax(self._actor_logits, axis = 0)\n",
    "        self._actor_log_policy = tf.nn.log_softmax(self._actor_logits, axis = 0)\n",
    "        \n",
    "        self._actor_loss = -tf.reduce_sum(self._actor_log_policy * tf.stop_gradient(self._advantage))\n",
    "        self._actor_optimizer = tf.train.AdamOptimizer()\n",
    "        self._actor_update = self._actor_optimizer.minimize(self._actor_loss)\n",
    "        \n",
    "        self._s = tf.InteractiveSession()\n",
    "        self._s.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def sample_action(self, states):\n",
    "        probs = self._s.run(self._actor_policy, ({self._states: states})).flatten()\n",
    "        \n",
    "        return np.random.choice(np.arange(len(probs)), p = probs)\n",
    "    \n",
    "    def update(self, boards, rewards, afterstates, done):\n",
    "        self._s.run([self._actor_update, self._critic_update], \n",
    "                    ({self._states: boards, \n",
    "                      self._afterstates: afterstates,\n",
    "                      self._done: done,\n",
    "                      self._cumulative_rewards: rewards}))\n",
    "        \n",
    "    def get_cumulative_rewards(self, rewards):\n",
    "        rewards = np.array(rewards)\n",
    "        R = np.zeros_like(rewards, dtype= \"float32\")\n",
    "        r = 0.\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            r += reward\n",
    "            R[-(i + 1)] = r\n",
    "            r *= self._gamma\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
